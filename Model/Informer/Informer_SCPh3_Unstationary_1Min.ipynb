{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Informer_SCPh4_1Min",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdHD9XzHqUOx",
        "outputId": "365d80da-8308-4822-fac2-e2192a5c8bf6"
      },
      "source": [
        "pip install pmdarima"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pmdarima\n",
            "  Downloading pmdarima-1.8.2-cp37-cp37m-manylinux1_x86_64.whl (1.5 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 29.7 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 21.6 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 17.0 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 133 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 174 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 184 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 194 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 204 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 215 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████                           | 225 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 235 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 245 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 256 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 266 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 276 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 286 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 296 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 307 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 317 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 327 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 337 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 348 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 358 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 368 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 378 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 389 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 399 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 409 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 419 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 430 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 440 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 450 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 460 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 471 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 481 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 491 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 501 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 512 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 522 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 532 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 542 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 552 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 563 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 573 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 583 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 593 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 604 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 614 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 624 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 634 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 645 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 655 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 665 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 675 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 686 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 696 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 706 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 716 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 727 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 737 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 747 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 757 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 768 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 778 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 788 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 798 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 808 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 819 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 829 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 839 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 849 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 860 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 870 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 880 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 890 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 901 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 911 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 921 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 931 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 942 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 952 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 962 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 972 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 983 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 993 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.0 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.0 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.0 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.0 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.1 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.1 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.2 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.2 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.2 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.2 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.2 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.3 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.3 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.3 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.3 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.4 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.4 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.4 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.4 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.4 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.4 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5 MB 6.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5 MB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.19.0 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.19.5)\n",
            "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (0.29.23)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.4.1)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (57.2.0)\n",
            "Collecting statsmodels!=0.12.0,>=0.11\n",
            "  Downloading statsmodels-0.12.2-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5 MB 42.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.24.3)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.1.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->pmdarima) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->pmdarima) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19->pmdarima) (1.15.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels!=0.12.0,>=0.11->pmdarima) (0.5.1)\n",
            "Installing collected packages: statsmodels, pmdarima\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "Successfully installed pmdarima-1.8.2 statsmodels-0.12.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je6LmrjHqjAK",
        "outputId": "58c1ec5f-74aa-4ad1-9f8a-91aa59046dff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpR1AAcdqoXB"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YfQ-mPA4qxx1",
        "outputId": "2e20a90d-8d62-49b2-ae9d-2fcc7d4a55d0"
      },
      "source": [
        "raw_csv_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/SCPh4_005930.csv',sep=',')\n",
        "\n",
        "df_comp = raw_csv_data.copy()\n",
        "\n",
        "df_comp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-07-18 13:31</td>\n",
              "      <td>46000</td>\n",
              "      <td>46100</td>\n",
              "      <td>46000</td>\n",
              "      <td>46100</td>\n",
              "      <td>17515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-07-18 13:32</td>\n",
              "      <td>46100</td>\n",
              "      <td>46100</td>\n",
              "      <td>46050</td>\n",
              "      <td>46050</td>\n",
              "      <td>3888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-07-18 13:33</td>\n",
              "      <td>46100</td>\n",
              "      <td>46100</td>\n",
              "      <td>46050</td>\n",
              "      <td>46100</td>\n",
              "      <td>2703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-07-18 13:34</td>\n",
              "      <td>46050</td>\n",
              "      <td>46100</td>\n",
              "      <td>46050</td>\n",
              "      <td>46050</td>\n",
              "      <td>14405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-07-18 13:35</td>\n",
              "      <td>46050</td>\n",
              "      <td>46100</td>\n",
              "      <td>46050</td>\n",
              "      <td>46100</td>\n",
              "      <td>3568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188140</th>\n",
              "      <td>2021-07-16 15:17</td>\n",
              "      <td>79600</td>\n",
              "      <td>79700</td>\n",
              "      <td>79600</td>\n",
              "      <td>79700</td>\n",
              "      <td>24989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188141</th>\n",
              "      <td>2021-07-16 15:18</td>\n",
              "      <td>79700</td>\n",
              "      <td>79700</td>\n",
              "      <td>79600</td>\n",
              "      <td>79700</td>\n",
              "      <td>41225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188142</th>\n",
              "      <td>2021-07-16 15:19</td>\n",
              "      <td>79600</td>\n",
              "      <td>79700</td>\n",
              "      <td>79600</td>\n",
              "      <td>79700</td>\n",
              "      <td>29508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188143</th>\n",
              "      <td>2021-07-16 15:20</td>\n",
              "      <td>79700</td>\n",
              "      <td>79700</td>\n",
              "      <td>79600</td>\n",
              "      <td>79700</td>\n",
              "      <td>230917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188144</th>\n",
              "      <td>2021-07-16 15:30</td>\n",
              "      <td>79800</td>\n",
              "      <td>79800</td>\n",
              "      <td>79800</td>\n",
              "      <td>79800</td>\n",
              "      <td>1399482</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>188145 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Date   Open   High    Low  Close   Volume\n",
              "0       2019-07-18 13:31  46000  46100  46000  46100    17515\n",
              "1       2019-07-18 13:32  46100  46100  46050  46050     3888\n",
              "2       2019-07-18 13:33  46100  46100  46050  46100     2703\n",
              "3       2019-07-18 13:34  46050  46100  46050  46050    14405\n",
              "4       2019-07-18 13:35  46050  46100  46050  46100     3568\n",
              "...                  ...    ...    ...    ...    ...      ...\n",
              "188140  2021-07-16 15:17  79600  79700  79600  79700    24989\n",
              "188141  2021-07-16 15:18  79700  79700  79600  79700    41225\n",
              "188142  2021-07-16 15:19  79600  79700  79600  79700    29508\n",
              "188143  2021-07-16 15:20  79700  79700  79600  79700   230917\n",
              "188144  2021-07-16 15:30  79800  79800  79800  79800  1399482\n",
              "\n",
              "[188145 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjTEpQiyrJ8Z",
        "outputId": "90ca817c-e76c-4f30-a64e-91c681ce6cf6"
      },
      "source": [
        "df_comp.Date.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count               188145\n",
              "unique              188145\n",
              "top       2020-08-10 15:08\n",
              "freq                     1\n",
              "Name: Date, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "d8IPJNCNrM-L",
        "outputId": "f10d27c1-2f1b-4c68-8549-a4768661fa0c"
      },
      "source": [
        "# Date가 더 이상 텍스트가 아닌 실제 시간으로 저장된다.\n",
        "\n",
        "df_comp.Date = pd.to_datetime(df_comp.Date, dayfirst = True)\n",
        "\n",
        "df_comp.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-07-18 13:31:00</td>\n",
              "      <td>46000</td>\n",
              "      <td>46100</td>\n",
              "      <td>46000</td>\n",
              "      <td>46100</td>\n",
              "      <td>17515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-07-18 13:32:00</td>\n",
              "      <td>46100</td>\n",
              "      <td>46100</td>\n",
              "      <td>46050</td>\n",
              "      <td>46050</td>\n",
              "      <td>3888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-07-18 13:33:00</td>\n",
              "      <td>46100</td>\n",
              "      <td>46100</td>\n",
              "      <td>46050</td>\n",
              "      <td>46100</td>\n",
              "      <td>2703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-07-18 13:34:00</td>\n",
              "      <td>46050</td>\n",
              "      <td>46100</td>\n",
              "      <td>46050</td>\n",
              "      <td>46050</td>\n",
              "      <td>14405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-07-18 13:35:00</td>\n",
              "      <td>46050</td>\n",
              "      <td>46100</td>\n",
              "      <td>46050</td>\n",
              "      <td>46100</td>\n",
              "      <td>3568</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Date   Open   High    Low  Close  Volume\n",
              "0 2019-07-18 13:31:00  46000  46100  46000  46100   17515\n",
              "1 2019-07-18 13:32:00  46100  46100  46050  46050    3888\n",
              "2 2019-07-18 13:33:00  46100  46100  46050  46100    2703\n",
              "3 2019-07-18 13:34:00  46050  46100  46050  46050   14405\n",
              "4 2019-07-18 13:35:00  46050  46100  46050  46100    3568"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BfwffT7rSvy",
        "outputId": "8fd7c81a-9e92-4919-a14b-93602ea9c127"
      },
      "source": [
        "df_comp.Date.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count                  188145\n",
              "unique                 188145\n",
              "top       2020-07-03 13:08:00\n",
              "freq                        1\n",
              "first     2019-07-18 13:31:00\n",
              "last      2021-07-16 15:30:00\n",
              "Name: Date, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "iKLY7lYZrXo_",
        "outputId": "e96a3a69-e526-43a6-c0ca-5228ffb2041a"
      },
      "source": [
        "df_comp.set_index('Date', inplace=True)\n",
        "\n",
        "df_comp.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:31:00</th>\n",
              "      <td>46000</td>\n",
              "      <td>46100</td>\n",
              "      <td>46000</td>\n",
              "      <td>46100</td>\n",
              "      <td>17515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:32:00</th>\n",
              "      <td>46100</td>\n",
              "      <td>46100</td>\n",
              "      <td>46050</td>\n",
              "      <td>46050</td>\n",
              "      <td>3888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:33:00</th>\n",
              "      <td>46100</td>\n",
              "      <td>46100</td>\n",
              "      <td>46050</td>\n",
              "      <td>46100</td>\n",
              "      <td>2703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:34:00</th>\n",
              "      <td>46050</td>\n",
              "      <td>46100</td>\n",
              "      <td>46050</td>\n",
              "      <td>46050</td>\n",
              "      <td>14405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:35:00</th>\n",
              "      <td>46050</td>\n",
              "      <td>46100</td>\n",
              "      <td>46050</td>\n",
              "      <td>46100</td>\n",
              "      <td>3568</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Open   High    Low  Close  Volume\n",
              "Date                                                   \n",
              "2019-07-18 13:31:00  46000  46100  46000  46100   17515\n",
              "2019-07-18 13:32:00  46100  46100  46050  46050    3888\n",
              "2019-07-18 13:33:00  46100  46100  46050  46100    2703\n",
              "2019-07-18 13:34:00  46050  46100  46050  46050   14405\n",
              "2019-07-18 13:35:00  46050  46100  46050  46100    3568"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "bdm2H5j-ra38",
        "outputId": "b03a0451-a6bf-4a9b-e36c-d745e4255112"
      },
      "source": [
        "#business day(휴일을 제외한 평일)을 기준으로 시계열 데이터를 만든다 \n",
        "\n",
        "df_comp = df_comp.asfreq('t')\n",
        "\n",
        "df_comp.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:31:00</th>\n",
              "      <td>46000.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46000.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>17515.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:32:00</th>\n",
              "      <td>46100.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>3888.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:33:00</th>\n",
              "      <td>46100.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>2703.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:34:00</th>\n",
              "      <td>46050.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>14405.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:35:00</th>\n",
              "      <td>46050.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>3568.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Open     High      Low    Close   Volume\n",
              "Date                                                            \n",
              "2019-07-18 13:31:00  46000.0  46100.0  46000.0  46100.0  17515.0\n",
              "2019-07-18 13:32:00  46100.0  46100.0  46050.0  46050.0   3888.0\n",
              "2019-07-18 13:33:00  46100.0  46100.0  46050.0  46100.0   2703.0\n",
              "2019-07-18 13:34:00  46050.0  46100.0  46050.0  46050.0  14405.0\n",
              "2019-07-18 13:35:00  46050.0  46100.0  46050.0  46100.0   3568.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "Jy0NwEPdry5b",
        "outputId": "9c9eafa3-545b-4cd5-d299-d44247b771d0"
      },
      "source": [
        "# isna()는 누락된 데이터가 있는지 여부에 따라 집합의 모든 항목에 대해 'True'와 'False'가 표시된다.\n",
        "\n",
        "df_comp.isna()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:31:00</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:32:00</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:33:00</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:34:00</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:35:00</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-16 15:26:00</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-16 15:27:00</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-16 15:28:00</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-16 15:29:00</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-16 15:30:00</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1049880 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Open   High    Low  Close  Volume\n",
              "Date                                                   \n",
              "2019-07-18 13:31:00  False  False  False  False   False\n",
              "2019-07-18 13:32:00  False  False  False  False   False\n",
              "2019-07-18 13:33:00  False  False  False  False   False\n",
              "2019-07-18 13:34:00  False  False  False  False   False\n",
              "2019-07-18 13:35:00  False  False  False  False   False\n",
              "...                    ...    ...    ...    ...     ...\n",
              "2021-07-16 15:26:00   True   True   True   True    True\n",
              "2021-07-16 15:27:00   True   True   True   True    True\n",
              "2021-07-16 15:28:00   True   True   True   True    True\n",
              "2021-07-16 15:29:00   True   True   True   True    True\n",
              "2021-07-16 15:30:00  False  False  False  False   False\n",
              "\n",
              "[1049880 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-2-pIyMr1-r",
        "outputId": "b14bb7f8-3b0b-41a8-8fdc-d46fa0dad459"
      },
      "source": [
        "#누락된 요소를 바로 직전 데이터의 값을 가져와서 채운다\n",
        "\n",
        "df_comp.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Open      861735\n",
              "High      861735\n",
              "Low       861735\n",
              "Close     861735\n",
              "Volume    861735\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ6ycUBisAmc",
        "outputId": "1c6bfcdd-1297-4f81-b236-63c45e51a90a"
      },
      "source": [
        "df_comp=df_comp.fillna(method='ffill')\n",
        "\n",
        "df_comp.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Open      0\n",
              "High      0\n",
              "Low       0\n",
              "Close     0\n",
              "Volume    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "YgD63cUCsDAN",
        "outputId": "f38a9513-2729-4c8e-ce37-5c086d4b66c5"
      },
      "source": [
        "df_comp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:31:00</th>\n",
              "      <td>46000.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46000.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>17515.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:32:00</th>\n",
              "      <td>46100.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>3888.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:33:00</th>\n",
              "      <td>46100.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>2703.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:34:00</th>\n",
              "      <td>46050.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>14405.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-07-18 13:35:00</th>\n",
              "      <td>46050.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>3568.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-16 15:26:00</th>\n",
              "      <td>79700.0</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>79600.0</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>230917.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-16 15:27:00</th>\n",
              "      <td>79700.0</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>79600.0</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>230917.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-16 15:28:00</th>\n",
              "      <td>79700.0</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>79600.0</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>230917.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-16 15:29:00</th>\n",
              "      <td>79700.0</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>79600.0</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>230917.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-07-16 15:30:00</th>\n",
              "      <td>79800.0</td>\n",
              "      <td>79800.0</td>\n",
              "      <td>79800.0</td>\n",
              "      <td>79800.0</td>\n",
              "      <td>1399482.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1049880 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Open     High      Low    Close     Volume\n",
              "Date                                                              \n",
              "2019-07-18 13:31:00  46000.0  46100.0  46000.0  46100.0    17515.0\n",
              "2019-07-18 13:32:00  46100.0  46100.0  46050.0  46050.0     3888.0\n",
              "2019-07-18 13:33:00  46100.0  46100.0  46050.0  46100.0     2703.0\n",
              "2019-07-18 13:34:00  46050.0  46100.0  46050.0  46050.0    14405.0\n",
              "2019-07-18 13:35:00  46050.0  46100.0  46050.0  46100.0     3568.0\n",
              "...                      ...      ...      ...      ...        ...\n",
              "2021-07-16 15:26:00  79700.0  79700.0  79600.0  79700.0   230917.0\n",
              "2021-07-16 15:27:00  79700.0  79700.0  79600.0  79700.0   230917.0\n",
              "2021-07-16 15:28:00  79700.0  79700.0  79600.0  79700.0   230917.0\n",
              "2021-07-16 15:29:00  79700.0  79700.0  79600.0  79700.0   230917.0\n",
              "2021-07-16 15:30:00  79800.0  79800.0  79800.0  79800.0  1399482.0\n",
              "\n",
              "[1049880 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "IRlvAM3XsE96",
        "outputId": "d45051ab-4b7d-4c80-fb91-2cf3c9737474"
      },
      "source": [
        "## Plotting\n",
        "df_comp.Close.plot(title = \"Samsung Price\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f60ee97d390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "dvZb4oLosIHZ",
        "outputId": "4457c3f2-a660-4fc7-ba18-e06d80143a9f"
      },
      "source": [
        "scipy.stats.probplot(df_comp.Close, plot = plt)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4MAbuSIsKZR",
        "outputId": "3c7e65f2-f0c7-42f7-c0b3-6deb14c8a634"
      },
      "source": [
        "df_comp.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1049880 entries, 2019-07-18 13:31:00 to 2021-07-16 15:30:00\n",
            "Freq: T\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count    Dtype  \n",
            "---  ------  --------------    -----  \n",
            " 0   Open    1049880 non-null  float64\n",
            " 1   High    1049880 non-null  float64\n",
            " 2   Low     1049880 non-null  float64\n",
            " 3   Close   1049880 non-null  float64\n",
            " 4   Volume  1049880 non-null  float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 48.1 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tdaA9PFksMbU",
        "outputId": "b091140f-252b-4dba-968d-789468349160"
      },
      "source": [
        "# reset_index()를 쓰면 인덱스를 보통의 자료열로 바꿀 수도 있다. 데이터 프레임의 인덱스는 정수로 된 디폴트 인덱스로 바뀐다.\n",
        "\n",
        "df_pre=df_comp.reset_index()\n",
        "\n",
        "df_pre"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-07-18 13:31:00</td>\n",
              "      <td>46000.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46000.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>17515.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-07-18 13:32:00</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>3888.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-07-18 13:33:00</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>2703.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-07-18 13:34:00</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>14405.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-07-18 13:35:00</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>46050.0</td>\n",
              "      <td>46100.0</td>\n",
              "      <td>3568.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1049875</th>\n",
              "      <td>2021-07-16 15:26:00</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>79600.0</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>230917.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1049876</th>\n",
              "      <td>2021-07-16 15:27:00</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>79600.0</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>230917.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1049877</th>\n",
              "      <td>2021-07-16 15:28:00</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>79600.0</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>230917.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1049878</th>\n",
              "      <td>2021-07-16 15:29:00</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>79600.0</td>\n",
              "      <td>79700.0</td>\n",
              "      <td>230917.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1049879</th>\n",
              "      <td>2021-07-16 15:30:00</td>\n",
              "      <td>79800.0</td>\n",
              "      <td>79800.0</td>\n",
              "      <td>79800.0</td>\n",
              "      <td>79800.0</td>\n",
              "      <td>1399482.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1049880 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Date     Open     High      Low    Close     Volume\n",
              "0       2019-07-18 13:31:00  46000.0  46100.0  46000.0  46100.0    17515.0\n",
              "1       2019-07-18 13:32:00  46100.0  46100.0  46050.0  46050.0     3888.0\n",
              "2       2019-07-18 13:33:00  46100.0  46100.0  46050.0  46100.0     2703.0\n",
              "3       2019-07-18 13:34:00  46050.0  46100.0  46050.0  46050.0    14405.0\n",
              "4       2019-07-18 13:35:00  46050.0  46100.0  46050.0  46100.0     3568.0\n",
              "...                     ...      ...      ...      ...      ...        ...\n",
              "1049875 2021-07-16 15:26:00  79700.0  79700.0  79600.0  79700.0   230917.0\n",
              "1049876 2021-07-16 15:27:00  79700.0  79700.0  79600.0  79700.0   230917.0\n",
              "1049877 2021-07-16 15:28:00  79700.0  79700.0  79600.0  79700.0   230917.0\n",
              "1049878 2021-07-16 15:29:00  79700.0  79700.0  79600.0  79700.0   230917.0\n",
              "1049879 2021-07-16 15:30:00  79800.0  79800.0  79800.0  79800.0  1399482.0\n",
              "\n",
              "[1049880 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWnTkyupsP7U",
        "outputId": "24f429fb-a79c-4570-e446-6f4c1917d83f"
      },
      "source": [
        "#일단 데이터타임인덱스를 없애는데 성공했고, \n",
        "#인포머처럼 바꾸려면 date를 object로, float64를 int64로 변형시켜주어야 한다.\n",
        "\n",
        "df_pre.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1049880 entries, 0 to 1049879\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count    Dtype         \n",
            "---  ------  --------------    -----         \n",
            " 0   Date    1049880 non-null  datetime64[ns]\n",
            " 1   Open    1049880 non-null  float64       \n",
            " 2   High    1049880 non-null  float64       \n",
            " 3   Low     1049880 non-null  float64       \n",
            " 4   Close   1049880 non-null  float64       \n",
            " 5   Volume  1049880 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(5)\n",
            "memory usage: 48.1 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZF6VjDfsWwD",
        "outputId": "8c55163b-ec23-406d-a743-eae893e92762"
      },
      "source": [
        "#datetime64를 object로 변환시킨다.\n",
        "\n",
        "from datetime import datetime\n",
        "def convert_datetime(dt):\n",
        "    return datetime.strftime(dt, '%Y-%m-%d %H:%M-%S')\n",
        "\n",
        "df_pre['Date']= df_pre['Date'].apply(convert_datetime)\n",
        "\n",
        "df_pre.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1049880 entries, 0 to 1049879\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count    Dtype  \n",
            "---  ------  --------------    -----  \n",
            " 0   Date    1049880 non-null  object \n",
            " 1   Open    1049880 non-null  float64\n",
            " 2   High    1049880 non-null  float64\n",
            " 3   Low     1049880 non-null  float64\n",
            " 4   Close   1049880 non-null  float64\n",
            " 5   Volume  1049880 non-null  float64\n",
            "dtypes: float64(5), object(1)\n",
            "memory usage: 48.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "j_Uf7Cm8saXD",
        "outputId": "72fcb7b1-bfc5-4a6f-a3c8-ece8c33107a0"
      },
      "source": [
        "# open, high, low, close, volume을 int64로 변환시켜주어야 한다.\n",
        "\n",
        "df_pre[['Open','High','Low','Close','Volume']]=df_pre[['Open','High','Low','Close','Volume']].astype('int64')\n",
        "\n",
        "df_pre"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-07-18 13:31-00</td>\n",
              "      <td>46000</td>\n",
              "      <td>46100</td>\n",
              "      <td>46000</td>\n",
              "      <td>46100</td>\n",
              "      <td>17515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-07-18 13:32-00</td>\n",
              "      <td>46100</td>\n",
              "      <td>46100</td>\n",
              "      <td>46050</td>\n",
              "      <td>46050</td>\n",
              "      <td>3888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-07-18 13:33-00</td>\n",
              "      <td>46100</td>\n",
              "      <td>46100</td>\n",
              "      <td>46050</td>\n",
              "      <td>46100</td>\n",
              "      <td>2703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-07-18 13:34-00</td>\n",
              "      <td>46050</td>\n",
              "      <td>46100</td>\n",
              "      <td>46050</td>\n",
              "      <td>46050</td>\n",
              "      <td>14405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-07-18 13:35-00</td>\n",
              "      <td>46050</td>\n",
              "      <td>46100</td>\n",
              "      <td>46050</td>\n",
              "      <td>46100</td>\n",
              "      <td>3568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1049875</th>\n",
              "      <td>2021-07-16 15:26-00</td>\n",
              "      <td>79700</td>\n",
              "      <td>79700</td>\n",
              "      <td>79600</td>\n",
              "      <td>79700</td>\n",
              "      <td>230917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1049876</th>\n",
              "      <td>2021-07-16 15:27-00</td>\n",
              "      <td>79700</td>\n",
              "      <td>79700</td>\n",
              "      <td>79600</td>\n",
              "      <td>79700</td>\n",
              "      <td>230917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1049877</th>\n",
              "      <td>2021-07-16 15:28-00</td>\n",
              "      <td>79700</td>\n",
              "      <td>79700</td>\n",
              "      <td>79600</td>\n",
              "      <td>79700</td>\n",
              "      <td>230917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1049878</th>\n",
              "      <td>2021-07-16 15:29-00</td>\n",
              "      <td>79700</td>\n",
              "      <td>79700</td>\n",
              "      <td>79600</td>\n",
              "      <td>79700</td>\n",
              "      <td>230917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1049879</th>\n",
              "      <td>2021-07-16 15:30-00</td>\n",
              "      <td>79800</td>\n",
              "      <td>79800</td>\n",
              "      <td>79800</td>\n",
              "      <td>79800</td>\n",
              "      <td>1399482</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1049880 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Date   Open   High    Low  Close   Volume\n",
              "0        2019-07-18 13:31-00  46000  46100  46000  46100    17515\n",
              "1        2019-07-18 13:32-00  46100  46100  46050  46050     3888\n",
              "2        2019-07-18 13:33-00  46100  46100  46050  46100     2703\n",
              "3        2019-07-18 13:34-00  46050  46100  46050  46050    14405\n",
              "4        2019-07-18 13:35-00  46050  46100  46050  46100     3568\n",
              "...                      ...    ...    ...    ...    ...      ...\n",
              "1049875  2021-07-16 15:26-00  79700  79700  79600  79700   230917\n",
              "1049876  2021-07-16 15:27-00  79700  79700  79600  79700   230917\n",
              "1049877  2021-07-16 15:28-00  79700  79700  79600  79700   230917\n",
              "1049878  2021-07-16 15:29-00  79700  79700  79600  79700   230917\n",
              "1049879  2021-07-16 15:30-00  79800  79800  79800  79800  1399482\n",
              "\n",
              "[1049880 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4P3BejlsjJS",
        "outputId": "3cf9f22b-81db-4e49-f6a1-cb29cd8b3acb"
      },
      "source": [
        "df_pre.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1049880 entries, 0 to 1049879\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count    Dtype \n",
            "---  ------  --------------    ----- \n",
            " 0   Date    1049880 non-null  object\n",
            " 1   Open    1049880 non-null  int64 \n",
            " 2   High    1049880 non-null  int64 \n",
            " 3   Low     1049880 non-null  int64 \n",
            " 4   Close   1049880 non-null  int64 \n",
            " 5   Volume  1049880 non-null  int64 \n",
            "dtypes: int64(5), object(1)\n",
            "memory usage: 48.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPLEA-dDsmCF"
      },
      "source": [
        "df_pre.to_csv('/content/drive/MyDrive/Colab Notebooks/bETTm2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5Ia1Pf5sptG",
        "outputId": "07ad2796-4df5-4838-b24e-1e5882b8bd36"
      },
      "source": [
        "!git clone https://github.com/zhouhaoyi/Informer2020.git\n",
        "!git clone https://github.com/Muiiya/research.git\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Informer2020'...\n",
            "remote: Enumerating objects: 525, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 525 (delta 1), reused 3 (delta 1), pack-reused 517\u001b[K\n",
            "Receiving objects: 100% (525/525), 6.47 MiB | 10.01 MiB/s, done.\n",
            "Resolving deltas: 100% (298/298), done.\n",
            "Cloning into 'research'...\n",
            "remote: Enumerating objects: 501, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 501 (delta 2), reused 0 (delta 0), pack-reused 491\u001b[K\n",
            "Receiving objects: 100% (501/501), 66.61 MiB | 29.04 MiB/s, done.\n",
            "Resolving deltas: 100% (184/184), done.\n",
            "drive  Informer2020  research  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X43NfkFsspS"
      },
      "source": [
        "import sys\n",
        "if not 'Informer2020' in sys.path:\n",
        "    sys.path += ['Informer2020']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJjQdv5MsxMZ"
      },
      "source": [
        "from utils.tools import dotdict\n",
        "from exp.exp_informer import Exp_Informer\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKCB7CdzszMG"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aB2zKxMs03V"
      },
      "source": [
        "args = dotdict()\n",
        "\n",
        "args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
        "\n",
        "args.data = 'ETTm2' # data\n",
        "args.root_path = '/content/drive/MyDrive/Colab Notebooks/' # root path of data file\n",
        "args.data_path = 'ETTm2.csv' # data file\n",
        "args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
        "args.target = 'Close' # target feature in S or MS task\n",
        "args.freq = 't' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
        "args.checkpoints = './informer_checkpoints' # location of model checkpoints\n",
        "\n",
        "args.seq_len = 96 # input sequence length of Informer encoder\n",
        "args.label_len = 48 # start token length of Informer decoder\n",
        "args.pred_len = 24 # prediction sequence length\n",
        "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
        "\n",
        "args.enc_in = 5 # encoder input size\n",
        "args.dec_in = 5 # decoder input size\n",
        "args.c_out = 1 # output size\n",
        "args.factor = 5 # probsparse attn factor\n",
        "args.d_model = 512 # dimension of model\n",
        "args.n_heads = 8 # num of heads\n",
        "args.e_layers = 2 # num of encoder layers\n",
        "args.d_layers = 1 # num of decoder layers\n",
        "args.d_ff = 2048 # dimension of fcn in model\n",
        "args.dropout = 0.05 # dropout\n",
        "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
        "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
        "args.activation = 'gelu' # activation\n",
        "args.distil = True # whether to use distilling in encoder\n",
        "args.output_attention = False # whether to output attention in ecoder\n",
        "args.mix = True\n",
        "args.padding = 0\n",
        "args.freq = 't'\n",
        "\n",
        "args.batch_size = 16 # 배치사이즈\n",
        "args.learning_rate = 0.0001\n",
        "args.loss = 'mse'\n",
        "args.lradj = 'type1'\n",
        "args.use_amp = False # whether to use automatic mixed precision training\n",
        "\n",
        "args.num_workers = 0\n",
        "args.itr = 1\n",
        "args.train_epochs = 50 # 에포크 수\n",
        "args.patience = 50  # early stopping 횟수\n",
        "args.des = 'exp'\n",
        "\n",
        "args.use_gpu = True if torch.cuda.is_available() else False\n",
        "args.gpu = 0\n",
        "\n",
        "args.use_multi_gpu = False\n",
        "args.devices = '0,1,2,3'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA7Mgoknw97r",
        "outputId": "06922a61-a402-47f5-9a84-19c4b01e90af"
      },
      "source": [
        "setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_{}_{}'\\\n",
        "          .format(args.model, args.data, args.features, args.seq_len, args.label_len, args.pred_len, \n",
        "                  args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, \n",
        "                  args.attn, args.factor, args.embed, args.distil, args.des, \"electr1day\")\n",
        "\n",
        "exp = Exp_Informer(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use GPU: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urFHWH69xBZN",
        "outputId": "7920900f-4d96-4ae8-d6be-895fc9979f76"
      },
      "source": [
        "print('>>>>>>>Initiating model training : {}>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "exp.train(setting)\n",
        "\n",
        "print('>>>>>>>Initiating model testing : {}<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "exp.test(setting)\n",
        "\n",
        "# train/val/test = 0.6:0.2:0.2\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>>>>>>Initiating model training : informer_ETTm2_ftMS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_exp_electr1day>>>>>>>>>>>>>>>>>>>\n",
            "train 34441\n",
            "val 11497\n",
            "test 11497\n",
            "\titers: 100, epoch: 1 | loss: 0.0611685\n",
            "\tspeed: 0.0425s/iter; left time: 4574.1218s\n",
            "\titers: 200, epoch: 1 | loss: 1.5935748\n",
            "\tspeed: 0.0387s/iter; left time: 4154.7347s\n",
            "\titers: 300, epoch: 1 | loss: 0.0502503\n",
            "\tspeed: 0.0385s/iter; left time: 4130.8425s\n",
            "\titers: 400, epoch: 1 | loss: 0.0178541\n",
            "\tspeed: 0.0387s/iter; left time: 4147.7781s\n",
            "\titers: 500, epoch: 1 | loss: 0.0206634\n",
            "\tspeed: 0.0389s/iter; left time: 4169.1109s\n",
            "\titers: 600, epoch: 1 | loss: 0.0560545\n",
            "\tspeed: 0.0389s/iter; left time: 4164.4120s\n",
            "\titers: 700, epoch: 1 | loss: 0.0170413\n",
            "\tspeed: 0.0390s/iter; left time: 4172.5026s\n",
            "\titers: 800, epoch: 1 | loss: 1.6484389\n",
            "\tspeed: 0.0387s/iter; left time: 4129.4183s\n",
            "\titers: 900, epoch: 1 | loss: 0.0148901\n",
            "\tspeed: 0.0387s/iter; left time: 4124.0964s\n",
            "\titers: 1000, epoch: 1 | loss: 0.0090718\n",
            "\tspeed: 0.0388s/iter; left time: 4138.9309s\n",
            "\titers: 1100, epoch: 1 | loss: 0.0344603\n",
            "\tspeed: 0.0390s/iter; left time: 4154.1513s\n",
            "\titers: 1200, epoch: 1 | loss: 0.0282124\n",
            "\tspeed: 0.0390s/iter; left time: 4150.7720s\n",
            "\titers: 1300, epoch: 1 | loss: 0.0112787\n",
            "\tspeed: 0.0389s/iter; left time: 4140.2232s\n",
            "\titers: 1400, epoch: 1 | loss: 0.0050629\n",
            "\tspeed: 0.0390s/iter; left time: 4139.4922s\n",
            "\titers: 1500, epoch: 1 | loss: 0.0216554\n",
            "\tspeed: 0.0391s/iter; left time: 4146.5996s\n",
            "\titers: 1600, epoch: 1 | loss: 0.0076694\n",
            "\tspeed: 0.0391s/iter; left time: 4148.9858s\n",
            "\titers: 1700, epoch: 1 | loss: 0.0117146\n",
            "\tspeed: 0.0392s/iter; left time: 4146.8179s\n",
            "\titers: 1800, epoch: 1 | loss: 0.0207467\n",
            "\tspeed: 0.0396s/iter; left time: 4191.2228s\n",
            "\titers: 1900, epoch: 1 | loss: 0.0461715\n",
            "\tspeed: 0.0403s/iter; left time: 4263.4659s\n",
            "\titers: 2000, epoch: 1 | loss: 0.0034205\n",
            "\tspeed: 0.0402s/iter; left time: 4248.0775s\n",
            "\titers: 2100, epoch: 1 | loss: 0.0872376\n",
            "\tspeed: 0.0404s/iter; left time: 4259.4109s\n",
            "Epoch: 1 cost time: 84.66421175003052\n",
            "Epoch: 1, Steps: 2152 | Train Loss: 0.1085607 Vali Loss: 0.0129809 Test Loss: 1.1326646\n",
            "Validation loss decreased (inf --> 0.012981).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 0.4016318\n",
            "\tspeed: 0.2693s/iter; left time: 28374.5316s\n",
            "\titers: 200, epoch: 2 | loss: 0.0074851\n",
            "\tspeed: 0.0405s/iter; left time: 4260.1522s\n",
            "\titers: 300, epoch: 2 | loss: 0.0040053\n",
            "\tspeed: 0.0404s/iter; left time: 4250.9763s\n",
            "\titers: 400, epoch: 2 | loss: 0.0147471\n",
            "\tspeed: 0.0407s/iter; left time: 4275.6881s\n",
            "\titers: 500, epoch: 2 | loss: 0.0424042\n",
            "\tspeed: 0.0404s/iter; left time: 4244.2676s\n",
            "\titers: 600, epoch: 2 | loss: 0.0335156\n",
            "\tspeed: 0.0405s/iter; left time: 4247.2749s\n",
            "\titers: 700, epoch: 2 | loss: 0.2489798\n",
            "\tspeed: 0.0405s/iter; left time: 4244.8551s\n",
            "\titers: 800, epoch: 2 | loss: 0.0119627\n",
            "\tspeed: 0.0405s/iter; left time: 4242.3039s\n",
            "\titers: 900, epoch: 2 | loss: 0.0078007\n",
            "\tspeed: 0.0407s/iter; left time: 4257.9332s\n",
            "\titers: 1000, epoch: 2 | loss: 0.0096954\n",
            "\tspeed: 0.0407s/iter; left time: 4254.5315s\n",
            "\titers: 1100, epoch: 2 | loss: 0.0248025\n",
            "\tspeed: 0.0406s/iter; left time: 4233.6700s\n",
            "\titers: 1200, epoch: 2 | loss: 0.0327843\n",
            "\tspeed: 0.0405s/iter; left time: 4221.7325s\n",
            "\titers: 1300, epoch: 2 | loss: 0.0158303\n",
            "\tspeed: 0.0406s/iter; left time: 4224.5558s\n",
            "\titers: 1400, epoch: 2 | loss: 0.0073661\n",
            "\tspeed: 0.0405s/iter; left time: 4212.6764s\n",
            "\titers: 1500, epoch: 2 | loss: 0.0268046\n",
            "\tspeed: 0.0407s/iter; left time: 4233.7188s\n",
            "\titers: 1600, epoch: 2 | loss: 0.1561455\n",
            "\tspeed: 0.0405s/iter; left time: 4205.2996s\n",
            "\titers: 1700, epoch: 2 | loss: 0.0188629\n",
            "\tspeed: 0.0405s/iter; left time: 4200.9022s\n",
            "\titers: 1800, epoch: 2 | loss: 0.0040314\n",
            "\tspeed: 0.0405s/iter; left time: 4200.1195s\n",
            "\titers: 1900, epoch: 2 | loss: 0.0189653\n",
            "\tspeed: 0.0405s/iter; left time: 4198.5145s\n",
            "\titers: 2000, epoch: 2 | loss: 0.0122811\n",
            "\tspeed: 0.0405s/iter; left time: 4190.9633s\n",
            "\titers: 2100, epoch: 2 | loss: 0.0040084\n",
            "\tspeed: 0.0406s/iter; left time: 4197.6740s\n",
            "Epoch: 2 cost time: 87.23986434936523\n",
            "Epoch: 2, Steps: 2152 | Train Loss: 0.0677923 Vali Loss: 0.0201539 Test Loss: 1.3634804\n",
            "EarlyStopping counter: 1 out of 50\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 0.0092932\n",
            "\tspeed: 0.2757s/iter; left time: 28447.8425s\n",
            "\titers: 200, epoch: 3 | loss: 0.0449282\n",
            "\tspeed: 0.0408s/iter; left time: 4201.7448s\n",
            "\titers: 300, epoch: 3 | loss: 0.0042713\n",
            "\tspeed: 0.0412s/iter; left time: 4240.5543s\n",
            "\titers: 400, epoch: 3 | loss: 0.0099147\n",
            "\tspeed: 0.0405s/iter; left time: 4167.7691s\n",
            "\titers: 500, epoch: 3 | loss: 0.0260082\n",
            "\tspeed: 0.0405s/iter; left time: 4167.6376s\n",
            "\titers: 600, epoch: 3 | loss: 0.0027576\n",
            "\tspeed: 0.0411s/iter; left time: 4223.7784s\n",
            "\titers: 700, epoch: 3 | loss: 0.0521434\n",
            "\tspeed: 0.0411s/iter; left time: 4220.8390s\n",
            "\titers: 800, epoch: 3 | loss: 0.0125431\n",
            "\tspeed: 0.0414s/iter; left time: 4245.6637s\n",
            "\titers: 900, epoch: 3 | loss: 0.0938718\n",
            "\tspeed: 0.0408s/iter; left time: 4180.0592s\n",
            "\titers: 1000, epoch: 3 | loss: 0.0067876\n",
            "\tspeed: 0.0414s/iter; left time: 4236.5727s\n",
            "\titers: 1100, epoch: 3 | loss: 0.0035953\n",
            "\tspeed: 0.0414s/iter; left time: 4228.2350s\n",
            "\titers: 1200, epoch: 3 | loss: 0.0164020\n",
            "\tspeed: 0.0409s/iter; left time: 4174.2497s\n",
            "\titers: 1300, epoch: 3 | loss: 0.0034944\n",
            "\tspeed: 0.0411s/iter; left time: 4189.1125s\n",
            "\titers: 1400, epoch: 3 | loss: 0.0151269\n",
            "\tspeed: 0.0409s/iter; left time: 4171.7687s\n",
            "\titers: 1500, epoch: 3 | loss: 0.0022816\n",
            "\tspeed: 0.0412s/iter; left time: 4189.4482s\n",
            "\titers: 1600, epoch: 3 | loss: 0.0160985\n",
            "\tspeed: 0.0412s/iter; left time: 4189.6091s\n",
            "\titers: 1700, epoch: 3 | loss: 0.0106258\n",
            "\tspeed: 0.0412s/iter; left time: 4183.4067s\n",
            "\titers: 1800, epoch: 3 | loss: 0.0127199\n",
            "\tspeed: 0.0410s/iter; left time: 4161.8410s\n",
            "\titers: 1900, epoch: 3 | loss: 0.0467311\n",
            "\tspeed: 0.0411s/iter; left time: 4165.0288s\n",
            "\titers: 2000, epoch: 3 | loss: 0.0194100\n",
            "\tspeed: 0.0412s/iter; left time: 4169.2139s\n",
            "\titers: 2100, epoch: 3 | loss: 0.0048167\n",
            "\tspeed: 0.0411s/iter; left time: 4161.9751s\n",
            "Epoch: 3 cost time: 88.35994505882263\n",
            "Epoch: 3, Steps: 2152 | Train Loss: 0.0539140 Vali Loss: 0.0249931 Test Loss: 1.0933015\n",
            "EarlyStopping counter: 2 out of 50\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 0.0023365\n",
            "\tspeed: 0.2788s/iter; left time: 28176.2094s\n",
            "\titers: 200, epoch: 4 | loss: 0.0021631\n",
            "\tspeed: 0.0410s/iter; left time: 4134.5514s\n",
            "\titers: 300, epoch: 4 | loss: 0.1076064\n",
            "\tspeed: 0.0409s/iter; left time: 4128.3073s\n",
            "\titers: 400, epoch: 4 | loss: 0.0044391\n",
            "\tspeed: 0.0410s/iter; left time: 4131.3375s\n",
            "\titers: 500, epoch: 4 | loss: 0.0026153\n",
            "\tspeed: 0.0411s/iter; left time: 4133.1450s\n",
            "\titers: 600, epoch: 4 | loss: 0.0628268\n",
            "\tspeed: 0.0410s/iter; left time: 4125.1978s\n",
            "\titers: 700, epoch: 4 | loss: 0.0036270\n",
            "\tspeed: 0.0412s/iter; left time: 4142.1703s\n",
            "\titers: 800, epoch: 4 | loss: 0.0070607\n",
            "\tspeed: 0.0412s/iter; left time: 4130.2420s\n",
            "\titers: 900, epoch: 4 | loss: 0.0041192\n",
            "\tspeed: 0.0413s/iter; left time: 4140.0555s\n",
            "\titers: 1000, epoch: 4 | loss: 0.0068369\n",
            "\tspeed: 0.0411s/iter; left time: 4111.8679s\n",
            "\titers: 1100, epoch: 4 | loss: 0.0603956\n",
            "\tspeed: 0.0413s/iter; left time: 4129.1816s\n",
            "\titers: 1200, epoch: 4 | loss: 0.0055508\n",
            "\tspeed: 0.0413s/iter; left time: 4131.1140s\n",
            "\titers: 1300, epoch: 4 | loss: 0.0068634\n",
            "\tspeed: 0.0414s/iter; left time: 4132.8352s\n",
            "\titers: 1400, epoch: 4 | loss: 0.0016657\n",
            "\tspeed: 0.0414s/iter; left time: 4129.5118s\n",
            "\titers: 1500, epoch: 4 | loss: 0.0042982\n",
            "\tspeed: 0.0415s/iter; left time: 4130.5934s\n",
            "\titers: 1600, epoch: 4 | loss: 0.0047730\n",
            "\tspeed: 0.0414s/iter; left time: 4118.0846s\n",
            "\titers: 1700, epoch: 4 | loss: 0.0166998\n",
            "\tspeed: 0.0410s/iter; left time: 4078.5200s\n",
            "\titers: 1800, epoch: 4 | loss: 0.0444094\n",
            "\tspeed: 0.0411s/iter; left time: 4080.4905s\n",
            "\titers: 1900, epoch: 4 | loss: 0.0026697\n",
            "\tspeed: 0.0410s/iter; left time: 4065.5642s\n",
            "\titers: 2000, epoch: 4 | loss: 0.0016004\n",
            "\tspeed: 0.0408s/iter; left time: 4046.3184s\n",
            "\titers: 2100, epoch: 4 | loss: 0.0019371\n",
            "\tspeed: 0.0411s/iter; left time: 4069.7578s\n",
            "Epoch: 4 cost time: 88.52882122993469\n",
            "Epoch: 4, Steps: 2152 | Train Loss: 0.0412360 Vali Loss: 0.0114789 Test Loss: 1.0892510\n",
            "Validation loss decreased (0.012981 --> 0.011479).  Saving model ...\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 5 | loss: 0.0018348\n",
            "\tspeed: 0.2790s/iter; left time: 27587.1334s\n",
            "\titers: 200, epoch: 5 | loss: 0.0015635\n",
            "\tspeed: 0.0417s/iter; left time: 4119.5134s\n",
            "\titers: 300, epoch: 5 | loss: 0.0214261\n",
            "\tspeed: 0.0414s/iter; left time: 4084.6792s\n",
            "\titers: 400, epoch: 5 | loss: 0.0071833\n",
            "\tspeed: 0.0414s/iter; left time: 4086.5701s\n",
            "\titers: 500, epoch: 5 | loss: 0.0020878\n",
            "\tspeed: 0.0417s/iter; left time: 4107.5494s\n",
            "\titers: 600, epoch: 5 | loss: 0.0019242\n",
            "\tspeed: 0.0415s/iter; left time: 4079.9588s\n",
            "\titers: 700, epoch: 5 | loss: 0.0286164\n",
            "\tspeed: 0.0411s/iter; left time: 4041.6992s\n",
            "\titers: 800, epoch: 5 | loss: 0.0070141\n",
            "\tspeed: 0.0411s/iter; left time: 4036.3296s\n",
            "\titers: 900, epoch: 5 | loss: 0.0037490\n",
            "\tspeed: 0.0409s/iter; left time: 4013.8220s\n",
            "\titers: 1000, epoch: 5 | loss: 0.0032340\n",
            "\tspeed: 0.0412s/iter; left time: 4034.6752s\n",
            "\titers: 1100, epoch: 5 | loss: 0.0020951\n",
            "\tspeed: 0.0407s/iter; left time: 3983.4769s\n",
            "\titers: 1200, epoch: 5 | loss: 0.0989309\n",
            "\tspeed: 0.0412s/iter; left time: 4032.1051s\n",
            "\titers: 1300, epoch: 5 | loss: 0.0298526\n",
            "\tspeed: 0.0410s/iter; left time: 4005.3148s\n",
            "\titers: 1400, epoch: 5 | loss: 0.0020048\n",
            "\tspeed: 0.0410s/iter; left time: 3997.3906s\n",
            "\titers: 1500, epoch: 5 | loss: 0.0739400\n",
            "\tspeed: 0.0409s/iter; left time: 3986.5253s\n",
            "\titers: 1600, epoch: 5 | loss: 0.0018839\n",
            "\tspeed: 0.0409s/iter; left time: 3987.8003s\n",
            "\titers: 1700, epoch: 5 | loss: 0.0071521\n",
            "\tspeed: 0.0416s/iter; left time: 4043.0688s\n",
            "\titers: 1800, epoch: 5 | loss: 0.0024150\n",
            "\tspeed: 0.0414s/iter; left time: 4020.8075s\n",
            "\titers: 1900, epoch: 5 | loss: 0.0027545\n",
            "\tspeed: 0.0417s/iter; left time: 4044.7498s\n",
            "\titers: 2000, epoch: 5 | loss: 0.0033556\n",
            "\tspeed: 0.0415s/iter; left time: 4025.4947s\n",
            "\titers: 2100, epoch: 5 | loss: 0.0022884\n",
            "\tspeed: 0.0414s/iter; left time: 4011.4671s\n",
            "Epoch: 5 cost time: 88.85013246536255\n",
            "Epoch: 5, Steps: 2152 | Train Loss: 0.0390386 Vali Loss: 0.0138845 Test Loss: 1.0666732\n",
            "EarlyStopping counter: 1 out of 50\n",
            "Updating learning rate to 6.25e-06\n",
            "\titers: 100, epoch: 6 | loss: 0.0016701\n",
            "\tspeed: 0.2783s/iter; left time: 26923.2423s\n",
            "\titers: 200, epoch: 6 | loss: 0.0281637\n",
            "\tspeed: 0.0413s/iter; left time: 3987.7041s\n",
            "\titers: 300, epoch: 6 | loss: 0.0351779\n",
            "\tspeed: 0.0414s/iter; left time: 3994.4562s\n",
            "\titers: 400, epoch: 6 | loss: 0.0046831\n",
            "\tspeed: 0.0407s/iter; left time: 3927.8809s\n",
            "\titers: 500, epoch: 6 | loss: 0.0031545\n",
            "\tspeed: 0.0408s/iter; left time: 3933.4339s\n",
            "\titers: 600, epoch: 6 | loss: 0.0190640\n",
            "\tspeed: 0.0406s/iter; left time: 3903.3450s\n",
            "\titers: 700, epoch: 6 | loss: 0.0323349\n",
            "\tspeed: 0.0407s/iter; left time: 3917.1883s\n",
            "\titers: 800, epoch: 6 | loss: 0.0240180\n",
            "\tspeed: 0.0407s/iter; left time: 3908.1366s\n",
            "\titers: 900, epoch: 6 | loss: 0.0035218\n",
            "\tspeed: 0.0406s/iter; left time: 3892.1833s\n",
            "\titers: 1000, epoch: 6 | loss: 0.0017358\n",
            "\tspeed: 0.0408s/iter; left time: 3911.2270s\n",
            "\titers: 1100, epoch: 6 | loss: 0.0593294\n",
            "\tspeed: 0.0406s/iter; left time: 3889.2517s\n",
            "\titers: 1200, epoch: 6 | loss: 0.0312753\n",
            "\tspeed: 0.0406s/iter; left time: 3881.9863s\n",
            "\titers: 1300, epoch: 6 | loss: 0.0066827\n",
            "\tspeed: 0.0409s/iter; left time: 3912.1117s\n",
            "\titers: 1400, epoch: 6 | loss: 0.0350916\n",
            "\tspeed: 0.0413s/iter; left time: 3944.7237s\n",
            "\titers: 1500, epoch: 6 | loss: 0.0025804\n",
            "\tspeed: 0.0413s/iter; left time: 3934.8557s\n",
            "\titers: 1600, epoch: 6 | loss: 0.0036731\n",
            "\tspeed: 0.0413s/iter; left time: 3936.8002s\n",
            "\titers: 1700, epoch: 6 | loss: 0.0028603\n",
            "\tspeed: 0.0412s/iter; left time: 3922.0064s\n",
            "\titers: 1800, epoch: 6 | loss: 0.0205879\n",
            "\tspeed: 0.0413s/iter; left time: 3923.3056s\n",
            "\titers: 1900, epoch: 6 | loss: 0.0328064\n",
            "\tspeed: 0.0415s/iter; left time: 3942.4659s\n",
            "\titers: 2000, epoch: 6 | loss: 0.0013422\n",
            "\tspeed: 0.0408s/iter; left time: 3871.7160s\n",
            "\titers: 2100, epoch: 6 | loss: 0.0027993\n",
            "\tspeed: 0.0406s/iter; left time: 3849.5515s\n",
            "Epoch: 6 cost time: 88.15784692764282\n",
            "Epoch: 6, Steps: 2152 | Train Loss: 0.0345580 Vali Loss: 0.0139856 Test Loss: 1.0892617\n",
            "EarlyStopping counter: 2 out of 50\n",
            "Updating learning rate to 3.125e-06\n",
            "\titers: 100, epoch: 7 | loss: 0.0051099\n",
            "\tspeed: 0.2762s/iter; left time: 26127.3641s\n",
            "\titers: 200, epoch: 7 | loss: 0.1269588\n",
            "\tspeed: 0.0411s/iter; left time: 3882.3239s\n",
            "\titers: 300, epoch: 7 | loss: 0.0044742\n",
            "\tspeed: 0.0413s/iter; left time: 3901.4787s\n",
            "\titers: 400, epoch: 7 | loss: 0.0017419\n",
            "\tspeed: 0.0413s/iter; left time: 3892.7901s\n",
            "\titers: 500, epoch: 7 | loss: 0.0170315\n",
            "\tspeed: 0.0413s/iter; left time: 3893.6682s\n",
            "\titers: 600, epoch: 7 | loss: 0.0101686\n",
            "\tspeed: 0.0412s/iter; left time: 3872.7707s\n",
            "\titers: 700, epoch: 7 | loss: 0.0037657\n",
            "\tspeed: 0.0414s/iter; left time: 3895.7445s\n",
            "\titers: 800, epoch: 7 | loss: 0.0020211\n",
            "\tspeed: 0.0414s/iter; left time: 3882.6667s\n",
            "\titers: 900, epoch: 7 | loss: 0.0026356\n",
            "\tspeed: 0.0410s/iter; left time: 3847.3008s\n",
            "\titers: 1000, epoch: 7 | loss: 0.0023905\n",
            "\tspeed: 0.0409s/iter; left time: 3834.3519s\n",
            "\titers: 1100, epoch: 7 | loss: 0.0416227\n",
            "\tspeed: 0.0409s/iter; left time: 3830.5247s\n",
            "\titers: 1200, epoch: 7 | loss: 0.0027059\n",
            "\tspeed: 0.0407s/iter; left time: 3807.3117s\n",
            "\titers: 1300, epoch: 7 | loss: 0.0376766\n",
            "\tspeed: 0.0407s/iter; left time: 3802.4151s\n",
            "\titers: 1400, epoch: 7 | loss: 0.0031563\n",
            "\tspeed: 0.0407s/iter; left time: 3798.3611s\n",
            "\titers: 1500, epoch: 7 | loss: 0.0037323\n",
            "\tspeed: 0.0409s/iter; left time: 3810.7744s\n",
            "\titers: 1600, epoch: 7 | loss: 0.0144895\n",
            "\tspeed: 0.0407s/iter; left time: 3784.4390s\n",
            "\titers: 1700, epoch: 7 | loss: 0.0018336\n",
            "\tspeed: 0.0410s/iter; left time: 3810.1556s\n",
            "\titers: 1800, epoch: 7 | loss: 0.0274975\n",
            "\tspeed: 0.0408s/iter; left time: 3788.9160s\n",
            "\titers: 1900, epoch: 7 | loss: 0.0130809\n",
            "\tspeed: 0.0410s/iter; left time: 3801.8225s\n",
            "\titers: 2000, epoch: 7 | loss: 0.0263750\n",
            "\tspeed: 0.0414s/iter; left time: 3835.4748s\n",
            "\titers: 2100, epoch: 7 | loss: 0.0021053\n",
            "\tspeed: 0.0415s/iter; left time: 3842.3975s\n",
            "Epoch: 7 cost time: 88.36893081665039\n",
            "Epoch: 7, Steps: 2152 | Train Loss: 0.0323399 Vali Loss: 0.0627069 Test Loss: 1.1268686\n",
            "EarlyStopping counter: 3 out of 50\n",
            "Updating learning rate to 1.5625e-06\n",
            "\titers: 100, epoch: 8 | loss: 0.0011812\n",
            "\tspeed: 0.2785s/iter; left time: 25739.2570s\n",
            "\titers: 200, epoch: 8 | loss: 0.0026789\n",
            "\tspeed: 0.0409s/iter; left time: 3780.0191s\n",
            "\titers: 300, epoch: 8 | loss: 0.0517447\n",
            "\tspeed: 0.0407s/iter; left time: 3754.7269s\n",
            "\titers: 400, epoch: 8 | loss: 0.0015861\n",
            "\tspeed: 0.0409s/iter; left time: 3767.3499s\n",
            "\titers: 500, epoch: 8 | loss: 0.0036496\n",
            "\tspeed: 0.0409s/iter; left time: 3768.5920s\n",
            "\titers: 600, epoch: 8 | loss: 0.0642465\n",
            "\tspeed: 0.0408s/iter; left time: 3749.6032s\n",
            "\titers: 700, epoch: 8 | loss: 0.0032742\n",
            "\tspeed: 0.0408s/iter; left time: 3745.7253s\n",
            "\titers: 800, epoch: 8 | loss: 0.0091571\n",
            "\tspeed: 0.0408s/iter; left time: 3739.8742s\n",
            "\titers: 900, epoch: 8 | loss: 0.0182901\n",
            "\tspeed: 0.0414s/iter; left time: 3793.3308s\n",
            "\titers: 1000, epoch: 8 | loss: 0.0331002\n",
            "\tspeed: 0.0413s/iter; left time: 3783.0111s\n",
            "\titers: 1100, epoch: 8 | loss: 0.0025320\n",
            "\tspeed: 0.0412s/iter; left time: 3764.8128s\n",
            "\titers: 1200, epoch: 8 | loss: 0.0016388\n",
            "\tspeed: 0.0413s/iter; left time: 3771.6043s\n",
            "\titers: 1300, epoch: 8 | loss: 0.0013071\n",
            "\tspeed: 0.0412s/iter; left time: 3755.0419s\n",
            "\titers: 1400, epoch: 8 | loss: 0.0018526\n",
            "\tspeed: 0.0414s/iter; left time: 3771.0774s\n",
            "\titers: 1500, epoch: 8 | loss: 0.0015992\n",
            "\tspeed: 0.0409s/iter; left time: 3723.8213s\n",
            "\titers: 1600, epoch: 8 | loss: 0.0013970\n",
            "\tspeed: 0.0410s/iter; left time: 3726.9747s\n",
            "\titers: 1700, epoch: 8 | loss: 0.0021517\n",
            "\tspeed: 0.0409s/iter; left time: 3715.8784s\n",
            "\titers: 1800, epoch: 8 | loss: 0.0013608\n",
            "\tspeed: 0.0412s/iter; left time: 3737.7419s\n",
            "\titers: 1900, epoch: 8 | loss: 0.0022033\n",
            "\tspeed: 0.0408s/iter; left time: 3697.4305s\n",
            "\titers: 2000, epoch: 8 | loss: 0.0021975\n",
            "\tspeed: 0.0412s/iter; left time: 3734.1168s\n",
            "\titers: 2100, epoch: 8 | loss: 0.0013505\n",
            "\tspeed: 0.0408s/iter; left time: 3688.4713s\n",
            "Epoch: 8 cost time: 88.22911310195923\n",
            "Epoch: 8, Steps: 2152 | Train Loss: 0.0316448 Vali Loss: 0.0149396 Test Loss: 1.0949862\n",
            "EarlyStopping counter: 4 out of 50\n",
            "Updating learning rate to 7.8125e-07\n",
            "\titers: 100, epoch: 9 | loss: 0.0033045\n",
            "\tspeed: 0.2780s/iter; left time: 25103.5095s\n",
            "\titers: 200, epoch: 9 | loss: 0.0027563\n",
            "\tspeed: 0.0412s/iter; left time: 3711.3224s\n",
            "\titers: 300, epoch: 9 | loss: 0.0219501\n",
            "\tspeed: 0.0413s/iter; left time: 3721.5875s\n",
            "\titers: 400, epoch: 9 | loss: 0.0207088\n",
            "\tspeed: 0.0412s/iter; left time: 3703.3901s\n",
            "\titers: 500, epoch: 9 | loss: 0.0065701\n",
            "\tspeed: 0.0409s/iter; left time: 3678.2781s\n",
            "\titers: 600, epoch: 9 | loss: 0.0025717\n",
            "\tspeed: 0.0412s/iter; left time: 3698.2026s\n",
            "\titers: 700, epoch: 9 | loss: 0.0064969\n",
            "\tspeed: 0.0416s/iter; left time: 3733.9063s\n",
            "\titers: 800, epoch: 9 | loss: 0.0023685\n",
            "\tspeed: 0.0412s/iter; left time: 3690.5725s\n",
            "\titers: 900, epoch: 9 | loss: 0.0041597\n",
            "\tspeed: 0.0415s/iter; left time: 3716.3928s\n",
            "\titers: 1000, epoch: 9 | loss: 0.0020070\n",
            "\tspeed: 0.0416s/iter; left time: 3719.0769s\n",
            "\titers: 1100, epoch: 9 | loss: 0.0483729\n",
            "\tspeed: 0.0415s/iter; left time: 3707.1368s\n",
            "\titers: 1200, epoch: 9 | loss: 0.1532490\n",
            "\tspeed: 0.0411s/iter; left time: 3668.7299s\n",
            "\titers: 1300, epoch: 9 | loss: 0.0042470\n",
            "\tspeed: 0.0408s/iter; left time: 3636.9512s\n",
            "\titers: 1400, epoch: 9 | loss: 0.0017767\n",
            "\tspeed: 0.0408s/iter; left time: 3629.7542s\n",
            "\titers: 1500, epoch: 9 | loss: 0.0016818\n",
            "\tspeed: 0.0410s/iter; left time: 3644.6602s\n",
            "\titers: 1600, epoch: 9 | loss: 0.0477831\n",
            "\tspeed: 0.0411s/iter; left time: 3648.4263s\n",
            "\titers: 1700, epoch: 9 | loss: 0.0022101\n",
            "\tspeed: 0.0408s/iter; left time: 3614.0859s\n",
            "\titers: 1800, epoch: 9 | loss: 0.0072249\n",
            "\tspeed: 0.0412s/iter; left time: 3646.4817s\n",
            "\titers: 1900, epoch: 9 | loss: 0.0527321\n",
            "\tspeed: 0.0409s/iter; left time: 3620.8526s\n",
            "\titers: 2000, epoch: 9 | loss: 0.0021246\n",
            "\tspeed: 0.0409s/iter; left time: 3613.5493s\n",
            "\titers: 2100, epoch: 9 | loss: 0.0008106\n",
            "\tspeed: 0.0410s/iter; left time: 3616.8907s\n",
            "Epoch: 9 cost time: 88.58212542533875\n",
            "Epoch: 9, Steps: 2152 | Train Loss: 0.0311840 Vali Loss: 0.0142476 Test Loss: 1.0980684\n",
            "EarlyStopping counter: 5 out of 50\n",
            "Updating learning rate to 3.90625e-07\n",
            "\titers: 100, epoch: 10 | loss: 0.0031213\n",
            "\tspeed: 0.2794s/iter; left time: 24624.7303s\n",
            "\titers: 200, epoch: 10 | loss: 0.0014175\n",
            "\tspeed: 0.0408s/iter; left time: 3592.3445s\n",
            "\titers: 300, epoch: 10 | loss: 0.0015350\n",
            "\tspeed: 0.0410s/iter; left time: 3608.0303s\n",
            "\titers: 400, epoch: 10 | loss: 0.0071270\n",
            "\tspeed: 0.0408s/iter; left time: 3583.1573s\n",
            "\titers: 500, epoch: 10 | loss: 0.0104202\n",
            "\tspeed: 0.0406s/iter; left time: 3560.5014s\n",
            "\titers: 600, epoch: 10 | loss: 0.0029439\n",
            "\tspeed: 0.0411s/iter; left time: 3602.8373s\n",
            "\titers: 700, epoch: 10 | loss: 0.0056995\n",
            "\tspeed: 0.0410s/iter; left time: 3584.7285s\n",
            "\titers: 800, epoch: 10 | loss: 0.0092251\n",
            "\tspeed: 0.0408s/iter; left time: 3563.6965s\n",
            "\titers: 900, epoch: 10 | loss: 0.0355563\n",
            "\tspeed: 0.0409s/iter; left time: 3571.8149s\n",
            "\titers: 1000, epoch: 10 | loss: 0.0027547\n",
            "\tspeed: 0.0409s/iter; left time: 3571.4693s\n",
            "\titers: 1100, epoch: 10 | loss: 0.0032268\n",
            "\tspeed: 0.0411s/iter; left time: 3584.7994s\n",
            "\titers: 1200, epoch: 10 | loss: 0.0019619\n",
            "\tspeed: 0.0414s/iter; left time: 3602.0678s\n",
            "\titers: 1300, epoch: 10 | loss: 0.0016841\n",
            "\tspeed: 0.0415s/iter; left time: 3611.8736s\n",
            "\titers: 1400, epoch: 10 | loss: 0.0107836\n",
            "\tspeed: 0.0415s/iter; left time: 3603.4098s\n",
            "\titers: 1500, epoch: 10 | loss: 0.0013532\n",
            "\tspeed: 0.0413s/iter; left time: 3580.3916s\n",
            "\titers: 1600, epoch: 10 | loss: 0.0060708\n",
            "\tspeed: 0.0415s/iter; left time: 3599.5212s\n",
            "\titers: 1700, epoch: 10 | loss: 0.0012245\n",
            "\tspeed: 0.0412s/iter; left time: 3568.8962s\n",
            "\titers: 1800, epoch: 10 | loss: 0.0021916\n",
            "\tspeed: 0.0406s/iter; left time: 3505.8350s\n",
            "\titers: 1900, epoch: 10 | loss: 0.0015185\n",
            "\tspeed: 0.0410s/iter; left time: 3538.6725s\n",
            "\titers: 2000, epoch: 10 | loss: 0.0079003\n",
            "\tspeed: 0.0409s/iter; left time: 3530.5382s\n",
            "\titers: 2100, epoch: 10 | loss: 0.0346890\n",
            "\tspeed: 0.0408s/iter; left time: 3516.1039s\n",
            "Epoch: 10 cost time: 88.35042667388916\n",
            "Epoch: 10, Steps: 2152 | Train Loss: 0.0313713 Vali Loss: 0.0135647 Test Loss: 1.0978284\n",
            "EarlyStopping counter: 6 out of 50\n",
            "Updating learning rate to 1.953125e-07\n",
            "\titers: 100, epoch: 11 | loss: 0.0032517\n",
            "\tspeed: 0.2780s/iter; left time: 23903.6121s\n",
            "\titers: 200, epoch: 11 | loss: 0.1123386\n",
            "\tspeed: 0.0413s/iter; left time: 3545.8868s\n",
            "\titers: 300, epoch: 11 | loss: 0.0034020\n",
            "\tspeed: 0.0416s/iter; left time: 3565.6336s\n",
            "\titers: 400, epoch: 11 | loss: 0.0252748\n",
            "\tspeed: 0.0415s/iter; left time: 3557.0541s\n",
            "\titers: 500, epoch: 11 | loss: 0.0014114\n",
            "\tspeed: 0.0414s/iter; left time: 3540.4534s\n",
            "\titers: 600, epoch: 11 | loss: 0.0027894\n",
            "\tspeed: 0.0415s/iter; left time: 3547.0843s\n",
            "\titers: 700, epoch: 11 | loss: 0.0128251\n",
            "\tspeed: 0.0408s/iter; left time: 3482.1741s\n",
            "\titers: 800, epoch: 11 | loss: 0.0024051\n",
            "\tspeed: 0.0408s/iter; left time: 3476.6666s\n",
            "\titers: 900, epoch: 11 | loss: 0.0185194\n",
            "\tspeed: 0.0406s/iter; left time: 3459.2580s\n",
            "\titers: 1000, epoch: 11 | loss: 0.0316994\n",
            "\tspeed: 0.0408s/iter; left time: 3472.4563s\n",
            "\titers: 1100, epoch: 11 | loss: 0.0023042\n",
            "\tspeed: 0.0406s/iter; left time: 3446.2037s\n",
            "\titers: 1200, epoch: 11 | loss: 0.0029979\n",
            "\tspeed: 0.0409s/iter; left time: 3473.1626s\n",
            "\titers: 1300, epoch: 11 | loss: 0.4443309\n",
            "\tspeed: 0.0409s/iter; left time: 3468.1296s\n",
            "\titers: 1400, epoch: 11 | loss: 0.0015808\n",
            "\tspeed: 0.0410s/iter; left time: 3468.0700s\n",
            "\titers: 1500, epoch: 11 | loss: 0.0052847\n",
            "\tspeed: 0.0407s/iter; left time: 3440.1461s\n",
            "\titers: 1600, epoch: 11 | loss: 0.0018081\n",
            "\tspeed: 0.0407s/iter; left time: 3441.3868s\n",
            "\titers: 1700, epoch: 11 | loss: 0.0093831\n",
            "\tspeed: 0.0415s/iter; left time: 3501.4943s\n",
            "\titers: 1800, epoch: 11 | loss: 0.0070036\n",
            "\tspeed: 0.0415s/iter; left time: 3494.6593s\n",
            "\titers: 1900, epoch: 11 | loss: 0.0034529\n",
            "\tspeed: 0.0415s/iter; left time: 3496.7154s\n",
            "\titers: 2000, epoch: 11 | loss: 0.5610703\n",
            "\tspeed: 0.0414s/iter; left time: 3480.4451s\n",
            "\titers: 2100, epoch: 11 | loss: 0.0012491\n",
            "\tspeed: 0.0414s/iter; left time: 3479.2721s\n",
            "Epoch: 11 cost time: 88.54661726951599\n",
            "Epoch: 11, Steps: 2152 | Train Loss: 0.0298028 Vali Loss: 0.0143848 Test Loss: 1.0984453\n",
            "EarlyStopping counter: 7 out of 50\n",
            "Updating learning rate to 9.765625e-08\n",
            "\titers: 100, epoch: 12 | loss: 0.0026949\n",
            "\tspeed: 0.2797s/iter; left time: 23444.6745s\n",
            "\titers: 200, epoch: 12 | loss: 0.0012155\n",
            "\tspeed: 0.0413s/iter; left time: 3460.5508s\n",
            "\titers: 300, epoch: 12 | loss: 0.0121561\n",
            "\tspeed: 0.0414s/iter; left time: 3464.5476s\n",
            "\titers: 400, epoch: 12 | loss: 0.0360815\n",
            "\tspeed: 0.0411s/iter; left time: 3428.8810s\n",
            "\titers: 500, epoch: 12 | loss: 0.0017690\n",
            "\tspeed: 0.0411s/iter; left time: 3426.9674s\n",
            "\titers: 600, epoch: 12 | loss: 0.0015970\n",
            "\tspeed: 0.0407s/iter; left time: 3390.8978s\n",
            "\titers: 700, epoch: 12 | loss: 0.0022873\n",
            "\tspeed: 0.0406s/iter; left time: 3382.6771s\n",
            "\titers: 800, epoch: 12 | loss: 0.4008176\n",
            "\tspeed: 0.0408s/iter; left time: 3395.2861s\n",
            "\titers: 900, epoch: 12 | loss: 0.0011584\n",
            "\tspeed: 0.0407s/iter; left time: 3380.3304s\n",
            "\titers: 1000, epoch: 12 | loss: 0.0020765\n",
            "\tspeed: 0.0411s/iter; left time: 3408.4297s\n",
            "\titers: 1100, epoch: 12 | loss: 0.0023986\n",
            "\tspeed: 0.0407s/iter; left time: 3374.8341s\n",
            "\titers: 1200, epoch: 12 | loss: 0.0029301\n",
            "\tspeed: 0.0409s/iter; left time: 3384.4663s\n",
            "\titers: 1300, epoch: 12 | loss: 0.0041643\n",
            "\tspeed: 0.0410s/iter; left time: 3384.3766s\n",
            "\titers: 1400, epoch: 12 | loss: 0.0063010\n",
            "\tspeed: 0.0412s/iter; left time: 3402.4841s\n",
            "\titers: 1500, epoch: 12 | loss: 0.0038792\n",
            "\tspeed: 0.0415s/iter; left time: 3416.7772s\n",
            "\titers: 1600, epoch: 12 | loss: 0.0243761\n",
            "\tspeed: 0.0412s/iter; left time: 3394.0183s\n",
            "\titers: 1700, epoch: 12 | loss: 0.0021864\n",
            "\tspeed: 0.0416s/iter; left time: 3420.7625s\n",
            "\titers: 1800, epoch: 12 | loss: 0.0016994\n",
            "\tspeed: 0.0415s/iter; left time: 3408.1110s\n",
            "\titers: 1900, epoch: 12 | loss: 0.0011450\n",
            "\tspeed: 0.0415s/iter; left time: 3400.1730s\n",
            "\titers: 2000, epoch: 12 | loss: 0.0015224\n",
            "\tspeed: 0.0415s/iter; left time: 3397.2312s\n",
            "\titers: 2100, epoch: 12 | loss: 0.0027413\n",
            "\tspeed: 0.0409s/iter; left time: 3348.8978s\n",
            "Epoch: 12 cost time: 88.53412580490112\n",
            "Epoch: 12, Steps: 2152 | Train Loss: 0.0309407 Vali Loss: 0.0138475 Test Loss: 1.0967867\n",
            "EarlyStopping counter: 8 out of 50\n",
            "Updating learning rate to 4.8828125e-08\n",
            "\titers: 100, epoch: 13 | loss: 0.0014934\n",
            "\tspeed: 0.2773s/iter; left time: 22652.4801s\n",
            "\titers: 200, epoch: 13 | loss: 0.0057107\n",
            "\tspeed: 0.0410s/iter; left time: 3341.8480s\n",
            "\titers: 300, epoch: 13 | loss: 0.0028164\n",
            "\tspeed: 0.0414s/iter; left time: 3371.9726s\n",
            "\titers: 400, epoch: 13 | loss: 0.0017537\n",
            "\tspeed: 0.0414s/iter; left time: 3368.0797s\n",
            "\titers: 500, epoch: 13 | loss: 0.0075214\n",
            "\tspeed: 0.0418s/iter; left time: 3394.8510s\n",
            "\titers: 600, epoch: 13 | loss: 0.0018428\n",
            "\tspeed: 0.0417s/iter; left time: 3383.7424s\n",
            "\titers: 700, epoch: 13 | loss: 0.0026930\n",
            "\tspeed: 0.0415s/iter; left time: 3367.3131s\n",
            "\titers: 800, epoch: 13 | loss: 0.0012430\n",
            "\tspeed: 0.0416s/iter; left time: 3364.8650s\n",
            "\titers: 900, epoch: 13 | loss: 0.0048037\n",
            "\tspeed: 0.0415s/iter; left time: 3357.6038s\n",
            "\titers: 1000, epoch: 13 | loss: 0.0011615\n",
            "\tspeed: 0.0414s/iter; left time: 3340.3468s\n",
            "\titers: 1100, epoch: 13 | loss: 0.0018951\n",
            "\tspeed: 0.0411s/iter; left time: 3315.2905s\n",
            "\titers: 1200, epoch: 13 | loss: 0.0036688\n",
            "\tspeed: 0.0408s/iter; left time: 3287.1410s\n",
            "\titers: 1300, epoch: 13 | loss: 0.0016323\n",
            "\tspeed: 0.0409s/iter; left time: 3288.9748s\n",
            "\titers: 1400, epoch: 13 | loss: 0.0141573\n",
            "\tspeed: 0.0405s/iter; left time: 3256.3119s\n",
            "\titers: 1500, epoch: 13 | loss: 0.0020449\n",
            "\tspeed: 0.0409s/iter; left time: 3286.7334s\n",
            "\titers: 1600, epoch: 13 | loss: 0.0523803\n",
            "\tspeed: 0.0409s/iter; left time: 3281.8793s\n",
            "\titers: 1700, epoch: 13 | loss: 0.0015084\n",
            "\tspeed: 0.0411s/iter; left time: 3287.9053s\n",
            "\titers: 1800, epoch: 13 | loss: 0.0118177\n",
            "\tspeed: 0.0411s/iter; left time: 3289.3758s\n",
            "\titers: 1900, epoch: 13 | loss: 0.0041858\n",
            "\tspeed: 0.0412s/iter; left time: 3292.4836s\n",
            "\titers: 2000, epoch: 13 | loss: 0.0193125\n",
            "\tspeed: 0.0414s/iter; left time: 3306.5145s\n",
            "\titers: 2100, epoch: 13 | loss: 0.0024407\n",
            "\tspeed: 0.0416s/iter; left time: 3313.5551s\n",
            "Epoch: 13 cost time: 88.73081922531128\n",
            "Epoch: 13, Steps: 2152 | Train Loss: 0.0297295 Vali Loss: 0.0137320 Test Loss: 1.0985485\n",
            "EarlyStopping counter: 9 out of 50\n",
            "Updating learning rate to 2.44140625e-08\n",
            "\titers: 100, epoch: 14 | loss: 0.0020441\n",
            "\tspeed: 0.2780s/iter; left time: 22111.1552s\n",
            "\titers: 200, epoch: 14 | loss: 0.0300002\n",
            "\tspeed: 0.0413s/iter; left time: 3279.1007s\n",
            "\titers: 300, epoch: 14 | loss: 0.0169739\n",
            "\tspeed: 0.0409s/iter; left time: 3247.3770s\n",
            "\titers: 400, epoch: 14 | loss: 0.0032003\n",
            "\tspeed: 0.0411s/iter; left time: 3256.0407s\n",
            "\titers: 500, epoch: 14 | loss: 0.0061819\n",
            "\tspeed: 0.0411s/iter; left time: 3251.2100s\n",
            "\titers: 600, epoch: 14 | loss: 0.0013153\n",
            "\tspeed: 0.0413s/iter; left time: 3261.9203s\n",
            "\titers: 700, epoch: 14 | loss: 0.0014815\n",
            "\tspeed: 0.0412s/iter; left time: 3255.6335s\n",
            "\titers: 800, epoch: 14 | loss: 0.0020698\n",
            "\tspeed: 0.0413s/iter; left time: 3256.9195s\n",
            "\titers: 900, epoch: 14 | loss: 0.0171347\n",
            "\tspeed: 0.0418s/iter; left time: 3292.0000s\n",
            "\titers: 1000, epoch: 14 | loss: 0.0165706\n",
            "\tspeed: 0.0415s/iter; left time: 3263.7508s\n",
            "\titers: 1100, epoch: 14 | loss: 0.0444554\n",
            "\tspeed: 0.0416s/iter; left time: 3264.4120s\n",
            "\titers: 1200, epoch: 14 | loss: 0.0861645\n",
            "\tspeed: 0.0417s/iter; left time: 3268.4900s\n",
            "\titers: 1300, epoch: 14 | loss: 0.0024812\n",
            "\tspeed: 0.0415s/iter; left time: 3250.3158s\n",
            "\titers: 1400, epoch: 14 | loss: 0.0031586\n",
            "\tspeed: 0.0416s/iter; left time: 3255.7647s\n",
            "\titers: 1500, epoch: 14 | loss: 0.0290686\n",
            "\tspeed: 0.0411s/iter; left time: 3209.7001s\n",
            "\titers: 1600, epoch: 14 | loss: 0.0009875\n",
            "\tspeed: 0.0409s/iter; left time: 3188.1013s\n",
            "\titers: 1700, epoch: 14 | loss: 0.0121908\n",
            "\tspeed: 0.0411s/iter; left time: 3205.8654s\n",
            "\titers: 1800, epoch: 14 | loss: 0.0136916\n",
            "\tspeed: 0.0409s/iter; left time: 3184.6949s\n",
            "\titers: 1900, epoch: 14 | loss: 0.0032965\n",
            "\tspeed: 0.0410s/iter; left time: 3187.4717s\n",
            "\titers: 2000, epoch: 14 | loss: 0.0014813\n",
            "\tspeed: 0.0409s/iter; left time: 3172.7896s\n",
            "\titers: 2100, epoch: 14 | loss: 0.0029632\n",
            "\tspeed: 0.0411s/iter; left time: 3188.3433s\n",
            "Epoch: 14 cost time: 88.71430230140686\n",
            "Epoch: 14, Steps: 2152 | Train Loss: 0.0300437 Vali Loss: 0.0135136 Test Loss: 1.0971029\n",
            "EarlyStopping counter: 10 out of 50\n",
            "Updating learning rate to 1.220703125e-08\n",
            "\titers: 100, epoch: 15 | loss: 0.0014270\n",
            "\tspeed: 0.2788s/iter; left time: 21569.7469s\n",
            "\titers: 200, epoch: 15 | loss: 0.0067971\n",
            "\tspeed: 0.0416s/iter; left time: 3215.8559s\n",
            "\titers: 300, epoch: 15 | loss: 0.0025920\n",
            "\tspeed: 0.0418s/iter; left time: 3225.8616s\n",
            "\titers: 400, epoch: 15 | loss: 0.0038243\n",
            "\tspeed: 0.0413s/iter; left time: 3180.9423s\n",
            "\titers: 500, epoch: 15 | loss: 0.0064604\n",
            "\tspeed: 0.0413s/iter; left time: 3180.1004s\n",
            "\titers: 600, epoch: 15 | loss: 0.0258407\n",
            "\tspeed: 0.0415s/iter; left time: 3191.3628s\n",
            "\titers: 700, epoch: 15 | loss: 0.0017581\n",
            "\tspeed: 0.0416s/iter; left time: 3193.5002s\n",
            "\titers: 800, epoch: 15 | loss: 0.0084581\n",
            "\tspeed: 0.0418s/iter; left time: 3202.1530s\n",
            "\titers: 900, epoch: 15 | loss: 0.0017502\n",
            "\tspeed: 0.0417s/iter; left time: 3191.3268s\n",
            "\titers: 1000, epoch: 15 | loss: 0.0015358\n",
            "\tspeed: 0.0413s/iter; left time: 3160.4644s\n",
            "\titers: 1100, epoch: 15 | loss: 0.0012503\n",
            "\tspeed: 0.0416s/iter; left time: 3174.7838s\n",
            "\titers: 1200, epoch: 15 | loss: 0.0010071\n",
            "\tspeed: 0.0411s/iter; left time: 3132.4982s\n",
            "\titers: 1300, epoch: 15 | loss: 0.0009711\n",
            "\tspeed: 0.0410s/iter; left time: 3124.8358s\n",
            "\titers: 1400, epoch: 15 | loss: 0.0029400\n",
            "\tspeed: 0.0405s/iter; left time: 3082.1666s\n",
            "\titers: 1500, epoch: 15 | loss: 0.0066239\n",
            "\tspeed: 0.0409s/iter; left time: 3104.0532s\n",
            "\titers: 1600, epoch: 15 | loss: 0.0122914\n",
            "\tspeed: 0.0409s/iter; left time: 3102.5910s\n",
            "\titers: 1700, epoch: 15 | loss: 0.1788462\n",
            "\tspeed: 0.0410s/iter; left time: 3103.9468s\n",
            "\titers: 1800, epoch: 15 | loss: 0.0022394\n",
            "\tspeed: 0.0410s/iter; left time: 3100.9464s\n",
            "\titers: 1900, epoch: 15 | loss: 0.0304986\n",
            "\tspeed: 0.0409s/iter; left time: 3089.6248s\n",
            "\titers: 2000, epoch: 15 | loss: 0.0017757\n",
            "\tspeed: 0.0410s/iter; left time: 3092.5183s\n",
            "\titers: 2100, epoch: 15 | loss: 0.0016074\n",
            "\tspeed: 0.0409s/iter; left time: 3083.5833s\n",
            "Epoch: 15 cost time: 88.77032423019409\n",
            "Epoch: 15, Steps: 2152 | Train Loss: 0.0307422 Vali Loss: 0.0132427 Test Loss: 1.0965394\n",
            "EarlyStopping counter: 11 out of 50\n",
            "Updating learning rate to 6.103515625e-09\n",
            "\titers: 100, epoch: 16 | loss: 0.0020460\n",
            "\tspeed: 0.2800s/iter; left time: 21059.5930s\n",
            "\titers: 200, epoch: 16 | loss: 0.0017089\n",
            "\tspeed: 0.0410s/iter; left time: 3077.4838s\n",
            "\titers: 300, epoch: 16 | loss: 0.0019402\n",
            "\tspeed: 0.0412s/iter; left time: 3089.5217s\n",
            "\titers: 400, epoch: 16 | loss: 0.0157596\n",
            "\tspeed: 0.0409s/iter; left time: 3066.9784s\n",
            "\titers: 500, epoch: 16 | loss: 0.0016658\n",
            "\tspeed: 0.0408s/iter; left time: 3051.1485s\n",
            "\titers: 600, epoch: 16 | loss: 0.0014484\n",
            "\tspeed: 0.0412s/iter; left time: 3078.6590s\n",
            "\titers: 700, epoch: 16 | loss: 0.0150568\n",
            "\tspeed: 0.0410s/iter; left time: 3060.4117s\n",
            "\titers: 800, epoch: 16 | loss: 0.0015313\n",
            "\tspeed: 0.0410s/iter; left time: 3057.0604s\n",
            "\titers: 900, epoch: 16 | loss: 0.0134142\n",
            "\tspeed: 0.0410s/iter; left time: 3054.6283s\n",
            "\titers: 1000, epoch: 16 | loss: 0.0309846\n",
            "\tspeed: 0.0410s/iter; left time: 3049.7951s\n",
            "\titers: 1100, epoch: 16 | loss: 0.4682554\n",
            "\tspeed: 0.0416s/iter; left time: 3085.8418s\n",
            "\titers: 1200, epoch: 16 | loss: 0.0010693\n",
            "\tspeed: 0.0416s/iter; left time: 3085.7298s\n",
            "\titers: 1300, epoch: 16 | loss: 0.0018340\n",
            "\tspeed: 0.0414s/iter; left time: 3061.7856s\n",
            "\titers: 1400, epoch: 16 | loss: 0.0166293\n",
            "\tspeed: 0.0416s/iter; left time: 3073.6828s\n",
            "\titers: 1500, epoch: 16 | loss: 0.0144755\n",
            "\tspeed: 0.0416s/iter; left time: 3067.2754s\n",
            "\titers: 1600, epoch: 16 | loss: 0.0557930\n",
            "\tspeed: 0.0413s/iter; left time: 3047.7875s\n",
            "\titers: 1700, epoch: 16 | loss: 0.0026173\n",
            "\tspeed: 0.0409s/iter; left time: 3014.7659s\n",
            "\titers: 1800, epoch: 16 | loss: 0.0016523\n",
            "\tspeed: 0.0407s/iter; left time: 2995.6973s\n",
            "\titers: 1900, epoch: 16 | loss: 1.8476002\n",
            "\tspeed: 0.0410s/iter; left time: 3009.9387s\n",
            "\titers: 2000, epoch: 16 | loss: 0.0017065\n",
            "\tspeed: 0.0411s/iter; left time: 3012.7887s\n",
            "\titers: 2100, epoch: 16 | loss: 0.0028053\n",
            "\tspeed: 0.0410s/iter; left time: 3001.2251s\n",
            "Epoch: 16 cost time: 88.59237766265869\n",
            "Epoch: 16, Steps: 2152 | Train Loss: 0.0311623 Vali Loss: 0.0142149 Test Loss: 1.0960712\n",
            "EarlyStopping counter: 12 out of 50\n",
            "Updating learning rate to 3.0517578125e-09\n",
            "\titers: 100, epoch: 17 | loss: 0.0084733\n",
            "\tspeed: 0.2784s/iter; left time: 20344.1386s\n",
            "\titers: 200, epoch: 17 | loss: 0.0017662\n",
            "\tspeed: 0.0418s/iter; left time: 3048.5655s\n",
            "\titers: 300, epoch: 17 | loss: 0.0017570\n",
            "\tspeed: 0.0417s/iter; left time: 3036.4902s\n",
            "\titers: 400, epoch: 17 | loss: 0.0059495\n",
            "\tspeed: 0.0416s/iter; left time: 3026.8653s\n",
            "\titers: 500, epoch: 17 | loss: 0.1673128\n",
            "\tspeed: 0.0417s/iter; left time: 3026.7366s\n",
            "\titers: 600, epoch: 17 | loss: 0.0190859\n",
            "\tspeed: 0.0414s/iter; left time: 3006.6286s\n",
            "\titers: 700, epoch: 17 | loss: 0.0018762\n",
            "\tspeed: 0.0411s/iter; left time: 2976.2338s\n",
            "\titers: 800, epoch: 17 | loss: 0.0016792\n",
            "\tspeed: 0.0411s/iter; left time: 2975.0505s\n",
            "\titers: 900, epoch: 17 | loss: 0.0016610\n",
            "\tspeed: 0.0411s/iter; left time: 2967.6229s\n",
            "\titers: 1000, epoch: 17 | loss: 0.0023689\n",
            "\tspeed: 0.0409s/iter; left time: 2949.4552s\n",
            "\titers: 1100, epoch: 17 | loss: 0.0375548\n",
            "\tspeed: 0.0408s/iter; left time: 2937.5654s\n",
            "\titers: 1200, epoch: 17 | loss: 0.0030072\n",
            "\tspeed: 0.0407s/iter; left time: 2927.3205s\n",
            "\titers: 1300, epoch: 17 | loss: 0.0050188\n",
            "\tspeed: 0.0411s/iter; left time: 2953.1344s\n",
            "\titers: 1400, epoch: 17 | loss: 0.0013787\n",
            "\tspeed: 0.0409s/iter; left time: 2932.2074s\n",
            "\titers: 1500, epoch: 17 | loss: 0.0621429\n",
            "\tspeed: 0.0409s/iter; left time: 2930.7152s\n",
            "\titers: 1600, epoch: 17 | loss: 0.0124000\n",
            "\tspeed: 0.0413s/iter; left time: 2957.3973s\n",
            "\titers: 1700, epoch: 17 | loss: 0.0200248\n",
            "\tspeed: 0.0414s/iter; left time: 2956.6394s\n",
            "\titers: 1800, epoch: 17 | loss: 0.0013471\n",
            "\tspeed: 0.0415s/iter; left time: 2962.5885s\n",
            "\titers: 1900, epoch: 17 | loss: 0.0016364\n",
            "\tspeed: 0.0415s/iter; left time: 2955.6249s\n",
            "\titers: 2000, epoch: 17 | loss: 0.0022200\n",
            "\tspeed: 0.0415s/iter; left time: 2956.8424s\n",
            "\titers: 2100, epoch: 17 | loss: 0.0162698\n",
            "\tspeed: 0.0414s/iter; left time: 2940.7536s\n",
            "Epoch: 17 cost time: 88.84220504760742\n",
            "Epoch: 17, Steps: 2152 | Train Loss: 0.0306033 Vali Loss: 0.0130332 Test Loss: 1.0967588\n",
            "EarlyStopping counter: 13 out of 50\n",
            "Updating learning rate to 1.52587890625e-09\n",
            "\titers: 100, epoch: 18 | loss: 0.0487565\n",
            "\tspeed: 0.2800s/iter; left time: 19853.8439s\n",
            "\titers: 200, epoch: 18 | loss: 0.0010991\n",
            "\tspeed: 0.0417s/iter; left time: 2949.5983s\n",
            "\titers: 300, epoch: 18 | loss: 0.0011137\n",
            "\tspeed: 0.0414s/iter; left time: 2929.8454s\n",
            "\titers: 400, epoch: 18 | loss: 0.0013027\n",
            "\tspeed: 0.0411s/iter; left time: 2903.6503s\n",
            "\titers: 500, epoch: 18 | loss: 0.0009609\n",
            "\tspeed: 0.0410s/iter; left time: 2890.3109s\n",
            "\titers: 600, epoch: 18 | loss: 0.0272444\n",
            "\tspeed: 0.0411s/iter; left time: 2895.2929s\n",
            "\titers: 700, epoch: 18 | loss: 0.0112172\n",
            "\tspeed: 0.0412s/iter; left time: 2894.4872s\n",
            "\titers: 800, epoch: 18 | loss: 0.0040944\n",
            "\tspeed: 0.0412s/iter; left time: 2893.4749s\n",
            "\titers: 900, epoch: 18 | loss: 0.0081809\n",
            "\tspeed: 0.0412s/iter; left time: 2888.3369s\n",
            "\titers: 1000, epoch: 18 | loss: 0.0269159\n",
            "\tspeed: 0.0412s/iter; left time: 2882.9986s\n",
            "\titers: 1100, epoch: 18 | loss: 0.0012945\n",
            "\tspeed: 0.0408s/iter; left time: 2851.4098s\n",
            "\titers: 1200, epoch: 18 | loss: 0.1219727\n",
            "\tspeed: 0.0410s/iter; left time: 2864.5936s\n",
            "\titers: 1300, epoch: 18 | loss: 0.0032078\n",
            "\tspeed: 0.0412s/iter; left time: 2871.9908s\n",
            "\titers: 1400, epoch: 18 | loss: 0.0073499\n",
            "\tspeed: 0.0416s/iter; left time: 2894.2085s\n",
            "\titers: 1500, epoch: 18 | loss: 0.0012051\n",
            "\tspeed: 0.0415s/iter; left time: 2881.7392s\n",
            "\titers: 1600, epoch: 18 | loss: 0.0028622\n",
            "\tspeed: 0.0414s/iter; left time: 2872.2486s\n",
            "\titers: 1700, epoch: 18 | loss: 0.0327016\n",
            "\tspeed: 0.0414s/iter; left time: 2866.2887s\n",
            "\titers: 1800, epoch: 18 | loss: 0.0013279\n",
            "\tspeed: 0.0414s/iter; left time: 2866.6055s\n",
            "\titers: 1900, epoch: 18 | loss: 0.0013437\n",
            "\tspeed: 0.0415s/iter; left time: 2865.4055s\n",
            "\titers: 2000, epoch: 18 | loss: 0.0057547\n",
            "\tspeed: 0.0408s/iter; left time: 2815.2131s\n",
            "\titers: 2100, epoch: 18 | loss: 0.0033660\n",
            "\tspeed: 0.0408s/iter; left time: 2808.3725s\n",
            "Epoch: 18 cost time: 88.72705364227295\n",
            "Epoch: 18, Steps: 2152 | Train Loss: 0.0300352 Vali Loss: 0.0140133 Test Loss: 1.0993266\n",
            "EarlyStopping counter: 14 out of 50\n",
            "Updating learning rate to 7.62939453125e-10\n",
            "\titers: 100, epoch: 19 | loss: 0.0010388\n",
            "\tspeed: 0.2779s/iter; left time: 19112.2120s\n",
            "\titers: 200, epoch: 19 | loss: 0.0024358\n",
            "\tspeed: 0.0409s/iter; left time: 2811.3289s\n",
            "\titers: 300, epoch: 19 | loss: 0.0018820\n",
            "\tspeed: 0.0412s/iter; left time: 2822.4335s\n",
            "\titers: 400, epoch: 19 | loss: 0.0013730\n",
            "\tspeed: 0.0415s/iter; left time: 2842.6625s\n",
            "\titers: 500, epoch: 19 | loss: 0.0018834\n",
            "\tspeed: 0.0415s/iter; left time: 2836.5442s\n",
            "\titers: 600, epoch: 19 | loss: 0.0016558\n",
            "\tspeed: 0.0415s/iter; left time: 2830.2118s\n",
            "\titers: 700, epoch: 19 | loss: 0.0276026\n",
            "\tspeed: 0.0416s/iter; left time: 2833.3802s\n",
            "\titers: 800, epoch: 19 | loss: 0.0025098\n",
            "\tspeed: 0.0414s/iter; left time: 2817.1975s\n",
            "\titers: 900, epoch: 19 | loss: 0.0021064\n",
            "\tspeed: 0.0414s/iter; left time: 2811.1928s\n",
            "\titers: 1000, epoch: 19 | loss: 0.0023381\n",
            "\tspeed: 0.0406s/iter; left time: 2757.6670s\n",
            "\titers: 1100, epoch: 19 | loss: 0.0491560\n",
            "\tspeed: 0.0412s/iter; left time: 2793.8037s\n",
            "\titers: 1200, epoch: 19 | loss: 0.0098275\n",
            "\tspeed: 0.0408s/iter; left time: 2762.8713s\n",
            "\titers: 1300, epoch: 19 | loss: 0.0012273\n",
            "\tspeed: 0.0411s/iter; left time: 2780.2403s\n",
            "\titers: 1400, epoch: 19 | loss: 0.0027960\n",
            "\tspeed: 0.0409s/iter; left time: 2761.9449s\n",
            "\titers: 1500, epoch: 19 | loss: 0.0014293\n",
            "\tspeed: 0.0410s/iter; left time: 2759.6833s\n",
            "\titers: 1600, epoch: 19 | loss: 0.0013897\n",
            "\tspeed: 0.0409s/iter; left time: 2751.8927s\n",
            "\titers: 1700, epoch: 19 | loss: 0.0803723\n",
            "\tspeed: 0.0407s/iter; left time: 2736.8783s\n",
            "\titers: 1800, epoch: 19 | loss: 0.0016402\n",
            "\tspeed: 0.0409s/iter; left time: 2741.5806s\n",
            "\titers: 1900, epoch: 19 | loss: 0.0036750\n",
            "\tspeed: 0.0414s/iter; left time: 2770.2760s\n",
            "\titers: 2000, epoch: 19 | loss: 0.0019620\n",
            "\tspeed: 0.0415s/iter; left time: 2776.2861s\n",
            "\titers: 2100, epoch: 19 | loss: 0.0013989\n",
            "\tspeed: 0.0415s/iter; left time: 2771.1019s\n",
            "Epoch: 19 cost time: 88.61078572273254\n",
            "Epoch: 19, Steps: 2152 | Train Loss: 0.0308186 Vali Loss: 0.0132553 Test Loss: 1.1022656\n",
            "EarlyStopping counter: 15 out of 50\n",
            "Updating learning rate to 3.814697265625e-10\n",
            "\titers: 100, epoch: 20 | loss: 0.0022265\n",
            "\tspeed: 0.2783s/iter; left time: 18535.4376s\n",
            "\titers: 200, epoch: 20 | loss: 0.0545539\n",
            "\tspeed: 0.0411s/iter; left time: 2733.4124s\n",
            "\titers: 300, epoch: 20 | loss: 0.0016597\n",
            "\tspeed: 0.0407s/iter; left time: 2702.7123s\n",
            "\titers: 400, epoch: 20 | loss: 0.0010339\n",
            "\tspeed: 0.0411s/iter; left time: 2726.1019s\n",
            "\titers: 500, epoch: 20 | loss: 0.0060505\n",
            "\tspeed: 0.0409s/iter; left time: 2707.5148s\n",
            "\titers: 600, epoch: 20 | loss: 0.0016090\n",
            "\tspeed: 0.0412s/iter; left time: 2721.3248s\n",
            "\titers: 700, epoch: 20 | loss: 0.0023768\n",
            "\tspeed: 0.0411s/iter; left time: 2712.0955s\n",
            "\titers: 800, epoch: 20 | loss: 0.0303529\n",
            "\tspeed: 0.0414s/iter; left time: 2726.4888s\n",
            "\titers: 900, epoch: 20 | loss: 0.0040942\n",
            "\tspeed: 0.0416s/iter; left time: 2735.4515s\n",
            "\titers: 1000, epoch: 20 | loss: 0.0038696\n",
            "\tspeed: 0.0416s/iter; left time: 2731.1497s\n",
            "\titers: 1100, epoch: 20 | loss: 0.0012239\n",
            "\tspeed: 0.0416s/iter; left time: 2729.9742s\n",
            "\titers: 1200, epoch: 20 | loss: 0.0029802\n",
            "\tspeed: 0.0417s/iter; left time: 2732.3751s\n",
            "\titers: 1300, epoch: 20 | loss: 0.0011763\n",
            "\tspeed: 0.0418s/iter; left time: 2731.3818s\n",
            "\titers: 1400, epoch: 20 | loss: 0.0135697\n",
            "\tspeed: 0.0414s/iter; left time: 2705.0444s\n",
            "\titers: 1500, epoch: 20 | loss: 0.0012944\n",
            "\tspeed: 0.0414s/iter; left time: 2696.6563s\n",
            "\titers: 1600, epoch: 20 | loss: 0.0022616\n",
            "\tspeed: 0.0412s/iter; left time: 2680.3688s\n",
            "\titers: 1700, epoch: 20 | loss: 0.0015324\n",
            "\tspeed: 0.0410s/iter; left time: 2664.3411s\n",
            "\titers: 1800, epoch: 20 | loss: 0.0024218\n",
            "\tspeed: 0.0412s/iter; left time: 2671.5244s\n",
            "\titers: 1900, epoch: 20 | loss: 0.0019754\n",
            "\tspeed: 0.0411s/iter; left time: 2664.5845s\n",
            "\titers: 2000, epoch: 20 | loss: 0.0292600\n",
            "\tspeed: 0.0413s/iter; left time: 2670.5659s\n",
            "\titers: 2100, epoch: 20 | loss: 0.0021614\n",
            "\tspeed: 0.0412s/iter; left time: 2662.8322s\n",
            "Epoch: 20 cost time: 88.73001909255981\n",
            "Epoch: 20, Steps: 2152 | Train Loss: 0.0305823 Vali Loss: 0.0138133 Test Loss: 1.0990125\n",
            "EarlyStopping counter: 16 out of 50\n",
            "Updating learning rate to 1.9073486328125e-10\n",
            "\titers: 100, epoch: 21 | loss: 0.0020169\n",
            "\tspeed: 0.2788s/iter; left time: 17968.9508s\n",
            "\titers: 200, epoch: 21 | loss: 0.0016916\n",
            "\tspeed: 0.0414s/iter; left time: 2665.9214s\n",
            "\titers: 300, epoch: 21 | loss: 0.0954324\n",
            "\tspeed: 0.0413s/iter; left time: 2656.1452s\n",
            "\titers: 400, epoch: 21 | loss: 0.0015750\n",
            "\tspeed: 0.0410s/iter; left time: 2632.4118s\n",
            "\titers: 500, epoch: 21 | loss: 0.0016599\n",
            "\tspeed: 0.0412s/iter; left time: 2640.1970s\n",
            "\titers: 600, epoch: 21 | loss: 0.0016597\n",
            "\tspeed: 0.0418s/iter; left time: 2670.7116s\n",
            "\titers: 700, epoch: 21 | loss: 0.1274304\n",
            "\tspeed: 0.0418s/iter; left time: 2670.1740s\n",
            "\titers: 800, epoch: 21 | loss: 0.0537722\n",
            "\tspeed: 0.0416s/iter; left time: 2655.6377s\n",
            "\titers: 900, epoch: 21 | loss: 0.0017951\n",
            "\tspeed: 0.0417s/iter; left time: 2653.5283s\n",
            "\titers: 1000, epoch: 21 | loss: 0.0019167\n",
            "\tspeed: 0.0417s/iter; left time: 2648.0580s\n",
            "\titers: 1100, epoch: 21 | loss: 0.0020253\n",
            "\tspeed: 0.0415s/iter; left time: 2631.7901s\n",
            "\titers: 1200, epoch: 21 | loss: 0.0146710\n",
            "\tspeed: 0.0413s/iter; left time: 2617.5425s\n",
            "\titers: 1300, epoch: 21 | loss: 0.0026138\n",
            "\tspeed: 0.0409s/iter; left time: 2589.2523s\n",
            "\titers: 1400, epoch: 21 | loss: 0.0011535\n",
            "\tspeed: 0.0412s/iter; left time: 2600.7711s\n",
            "\titers: 1500, epoch: 21 | loss: 0.0013321\n",
            "\tspeed: 0.0411s/iter; left time: 2593.6329s\n",
            "\titers: 1600, epoch: 21 | loss: 0.0035329\n",
            "\tspeed: 0.0411s/iter; left time: 2588.0911s\n",
            "\titers: 1700, epoch: 21 | loss: 0.0098968\n",
            "\tspeed: 0.0410s/iter; left time: 2577.1643s\n",
            "\titers: 1800, epoch: 21 | loss: 0.0015578\n",
            "\tspeed: 0.0409s/iter; left time: 2569.3670s\n",
            "\titers: 1900, epoch: 21 | loss: 0.0075624\n",
            "\tspeed: 0.0410s/iter; left time: 2568.7394s\n",
            "\titers: 2000, epoch: 21 | loss: 0.0035108\n",
            "\tspeed: 0.0408s/iter; left time: 2552.6634s\n",
            "\titers: 2100, epoch: 21 | loss: 0.0016411\n",
            "\tspeed: 0.0410s/iter; left time: 2562.5684s\n",
            "Epoch: 21 cost time: 88.86012673377991\n",
            "Epoch: 21, Steps: 2152 | Train Loss: 0.0302529 Vali Loss: 0.0135760 Test Loss: 1.1007706\n",
            "EarlyStopping counter: 17 out of 50\n",
            "Updating learning rate to 9.5367431640625e-11\n",
            "\titers: 100, epoch: 22 | loss: 0.0131068\n",
            "\tspeed: 0.2795s/iter; left time: 17415.5616s\n",
            "\titers: 200, epoch: 22 | loss: 0.0154361\n",
            "\tspeed: 0.0411s/iter; left time: 2556.8053s\n",
            "\titers: 300, epoch: 22 | loss: 0.0020974\n",
            "\tspeed: 0.0409s/iter; left time: 2537.9036s\n",
            "\titers: 400, epoch: 22 | loss: 0.0466516\n",
            "\tspeed: 0.0414s/iter; left time: 2568.0976s\n",
            "\titers: 500, epoch: 22 | loss: 0.0041542\n",
            "\tspeed: 0.0413s/iter; left time: 2555.0818s\n",
            "\titers: 600, epoch: 22 | loss: 0.0013239\n",
            "\tspeed: 0.0411s/iter; left time: 2542.8939s\n",
            "\titers: 700, epoch: 22 | loss: 0.0027307\n",
            "\tspeed: 0.0411s/iter; left time: 2534.6192s\n",
            "\titers: 800, epoch: 22 | loss: 0.0015121\n",
            "\tspeed: 0.0409s/iter; left time: 2521.6889s\n",
            "\titers: 900, epoch: 22 | loss: 0.0559190\n",
            "\tspeed: 0.0410s/iter; left time: 2519.3101s\n",
            "\titers: 1000, epoch: 22 | loss: 0.0970681\n",
            "\tspeed: 0.0409s/iter; left time: 2512.5163s\n",
            "\titers: 1100, epoch: 22 | loss: 0.0012916\n",
            "\tspeed: 0.0413s/iter; left time: 2535.0906s\n",
            "\titers: 1200, epoch: 22 | loss: 0.0083094\n",
            "\tspeed: 0.0416s/iter; left time: 2545.4081s\n",
            "\titers: 1300, epoch: 22 | loss: 0.0088338\n",
            "\tspeed: 0.0413s/iter; left time: 2525.4561s\n",
            "\titers: 1400, epoch: 22 | loss: 0.0011833\n",
            "\tspeed: 0.0412s/iter; left time: 2513.2157s\n",
            "\titers: 1500, epoch: 22 | loss: 0.0824124\n",
            "\tspeed: 0.0414s/iter; left time: 2519.8289s\n",
            "\titers: 1600, epoch: 22 | loss: 0.0020647\n",
            "\tspeed: 0.0415s/iter; left time: 2524.2003s\n",
            "\titers: 1700, epoch: 22 | loss: 0.0012628\n",
            "\tspeed: 0.0411s/iter; left time: 2492.6273s\n",
            "\titers: 1800, epoch: 22 | loss: 0.0274988\n",
            "\tspeed: 0.0410s/iter; left time: 2482.8408s\n",
            "\titers: 1900, epoch: 22 | loss: 0.0028281\n",
            "\tspeed: 0.0407s/iter; left time: 2463.1998s\n",
            "\titers: 2000, epoch: 22 | loss: 0.1278621\n",
            "\tspeed: 0.0410s/iter; left time: 2474.3505s\n",
            "\titers: 2100, epoch: 22 | loss: 0.0815406\n",
            "\tspeed: 0.0409s/iter; left time: 2466.0955s\n",
            "Epoch: 22 cost time: 88.49081063270569\n",
            "Epoch: 22, Steps: 2152 | Train Loss: 0.0311585 Vali Loss: 0.0142260 Test Loss: 1.0991771\n",
            "EarlyStopping counter: 18 out of 50\n",
            "Updating learning rate to 4.76837158203125e-11\n",
            "\titers: 100, epoch: 23 | loss: 0.0064773\n",
            "\tspeed: 0.2784s/iter; left time: 16748.2694s\n",
            "\titers: 200, epoch: 23 | loss: 0.0023785\n",
            "\tspeed: 0.0415s/iter; left time: 2493.8135s\n",
            "\titers: 300, epoch: 23 | loss: 0.0019829\n",
            "\tspeed: 0.0416s/iter; left time: 2493.6962s\n",
            "\titers: 400, epoch: 23 | loss: 0.0007924\n",
            "\tspeed: 0.0416s/iter; left time: 2490.9024s\n",
            "\titers: 500, epoch: 23 | loss: 0.0008462\n",
            "\tspeed: 0.0417s/iter; left time: 2489.9349s\n",
            "\titers: 600, epoch: 23 | loss: 0.0021385\n",
            "\tspeed: 0.0415s/iter; left time: 2476.3709s\n",
            "\titers: 700, epoch: 23 | loss: 0.0965462\n",
            "\tspeed: 0.0410s/iter; left time: 2440.7814s\n",
            "\titers: 800, epoch: 23 | loss: 0.0025132\n",
            "\tspeed: 0.0411s/iter; left time: 2445.2232s\n",
            "\titers: 900, epoch: 23 | loss: 0.0019929\n",
            "\tspeed: 0.0410s/iter; left time: 2434.8199s\n",
            "\titers: 1000, epoch: 23 | loss: 0.0020126\n",
            "\tspeed: 0.0411s/iter; left time: 2435.9854s\n",
            "\titers: 1100, epoch: 23 | loss: 0.0014780\n",
            "\tspeed: 0.0412s/iter; left time: 2436.1542s\n",
            "\titers: 1200, epoch: 23 | loss: 0.0020156\n",
            "\tspeed: 0.0409s/iter; left time: 2416.2889s\n",
            "\titers: 1300, epoch: 23 | loss: 0.0022116\n",
            "\tspeed: 0.0411s/iter; left time: 2425.1731s\n",
            "\titers: 1400, epoch: 23 | loss: 0.1185119\n",
            "\tspeed: 0.0408s/iter; left time: 2400.0760s\n",
            "\titers: 1500, epoch: 23 | loss: 0.0050812\n",
            "\tspeed: 0.0409s/iter; left time: 2400.7610s\n",
            "\titers: 1600, epoch: 23 | loss: 0.0035132\n",
            "\tspeed: 0.0414s/iter; left time: 2427.2176s\n",
            "\titers: 1700, epoch: 23 | loss: 0.0012940\n",
            "\tspeed: 0.0418s/iter; left time: 2444.8818s\n",
            "\titers: 1800, epoch: 23 | loss: 0.0014645\n",
            "\tspeed: 0.0412s/iter; left time: 2409.8149s\n",
            "\titers: 1900, epoch: 23 | loss: 0.0008963\n",
            "\tspeed: 0.0415s/iter; left time: 2418.9235s\n",
            "\titers: 2000, epoch: 23 | loss: 0.0150243\n",
            "\tspeed: 0.0414s/iter; left time: 2412.9687s\n",
            "\titers: 2100, epoch: 23 | loss: 0.0022122\n",
            "\tspeed: 0.0415s/iter; left time: 2412.1036s\n",
            "Epoch: 23 cost time: 88.89096665382385\n",
            "Epoch: 23, Steps: 2152 | Train Loss: 0.0306202 Vali Loss: 0.0140429 Test Loss: 1.0985577\n",
            "EarlyStopping counter: 19 out of 50\n",
            "Updating learning rate to 2.384185791015625e-11\n",
            "\titers: 100, epoch: 24 | loss: 0.0022743\n",
            "\tspeed: 0.2789s/iter; left time: 16180.3463s\n",
            "\titers: 200, epoch: 24 | loss: 0.0013885\n",
            "\tspeed: 0.0416s/iter; left time: 2411.0639s\n",
            "\titers: 300, epoch: 24 | loss: 0.0102752\n",
            "\tspeed: 0.0412s/iter; left time: 2383.9751s\n",
            "\titers: 400, epoch: 24 | loss: 0.0017092\n",
            "\tspeed: 0.0410s/iter; left time: 2366.4522s\n",
            "\titers: 500, epoch: 24 | loss: 0.0015017\n",
            "\tspeed: 0.0411s/iter; left time: 2369.7898s\n",
            "\titers: 600, epoch: 24 | loss: 0.0036451\n",
            "\tspeed: 0.0412s/iter; left time: 2367.2495s\n",
            "\titers: 700, epoch: 24 | loss: 0.0017346\n",
            "\tspeed: 0.0413s/iter; left time: 2368.4516s\n",
            "\titers: 800, epoch: 24 | loss: 0.0289752\n",
            "\tspeed: 0.0411s/iter; left time: 2353.7950s\n",
            "\titers: 900, epoch: 24 | loss: 0.1509929\n",
            "\tspeed: 0.0414s/iter; left time: 2365.5871s\n",
            "\titers: 1000, epoch: 24 | loss: 0.0027214\n",
            "\tspeed: 0.0411s/iter; left time: 2347.4307s\n",
            "\titers: 1100, epoch: 24 | loss: 0.0028616\n",
            "\tspeed: 0.0412s/iter; left time: 2348.8965s\n",
            "\titers: 1200, epoch: 24 | loss: 0.0027164\n",
            "\tspeed: 0.0411s/iter; left time: 2339.3174s\n",
            "\titers: 1300, epoch: 24 | loss: 0.0014865\n",
            "\tspeed: 0.0414s/iter; left time: 2350.1602s\n",
            "\titers: 1400, epoch: 24 | loss: 0.0017685\n",
            "\tspeed: 0.0415s/iter; left time: 2353.4716s\n",
            "\titers: 1500, epoch: 24 | loss: 0.0036922\n",
            "\tspeed: 0.0415s/iter; left time: 2350.3836s\n",
            "\titers: 1600, epoch: 24 | loss: 0.0024782\n",
            "\tspeed: 0.0417s/iter; left time: 2358.5951s\n",
            "\titers: 1700, epoch: 24 | loss: 0.0020047\n",
            "\tspeed: 0.0416s/iter; left time: 2345.1878s\n",
            "\titers: 1800, epoch: 24 | loss: 0.0343045\n",
            "\tspeed: 0.0417s/iter; left time: 2346.7735s\n",
            "\titers: 1900, epoch: 24 | loss: 0.0287960\n",
            "\tspeed: 0.0415s/iter; left time: 2335.0564s\n",
            "\titers: 2000, epoch: 24 | loss: 0.0040785\n",
            "\tspeed: 0.0412s/iter; left time: 2309.8317s\n",
            "\titers: 2100, epoch: 24 | loss: 0.0015515\n",
            "\tspeed: 0.0410s/iter; left time: 2297.5311s\n",
            "Epoch: 24 cost time: 88.94371366500854\n",
            "Epoch: 24, Steps: 2152 | Train Loss: 0.0306809 Vali Loss: 0.0143130 Test Loss: 1.0968471\n",
            "EarlyStopping counter: 20 out of 50\n",
            "Updating learning rate to 1.1920928955078126e-11\n",
            "\titers: 100, epoch: 25 | loss: 0.0060206\n",
            "\tspeed: 0.2772s/iter; left time: 15483.4123s\n",
            "\titers: 200, epoch: 25 | loss: 0.2040654\n",
            "\tspeed: 0.0409s/iter; left time: 2282.2523s\n",
            "\titers: 300, epoch: 25 | loss: 0.0029146\n",
            "\tspeed: 0.0415s/iter; left time: 2311.5810s\n",
            "\titers: 400, epoch: 25 | loss: 0.0009321\n",
            "\tspeed: 0.0418s/iter; left time: 2323.4427s\n",
            "\titers: 500, epoch: 25 | loss: 0.0121291\n",
            "\tspeed: 0.0416s/iter; left time: 2308.2838s\n",
            "\titers: 600, epoch: 25 | loss: 0.0018972\n",
            "\tspeed: 0.0416s/iter; left time: 2302.9766s\n",
            "\titers: 700, epoch: 25 | loss: 0.0065283\n",
            "\tspeed: 0.0415s/iter; left time: 2292.8208s\n",
            "\titers: 800, epoch: 25 | loss: 0.0013162\n",
            "\tspeed: 0.0415s/iter; left time: 2288.6247s\n",
            "\titers: 900, epoch: 25 | loss: 0.0039189\n",
            "\tspeed: 0.0412s/iter; left time: 2270.0518s\n",
            "\titers: 1000, epoch: 25 | loss: 0.0287826\n",
            "\tspeed: 0.0410s/iter; left time: 2251.5905s\n",
            "\titers: 1100, epoch: 25 | loss: 0.0138993\n",
            "\tspeed: 0.0411s/iter; left time: 2253.4361s\n",
            "\titers: 1200, epoch: 25 | loss: 0.0885886\n",
            "\tspeed: 0.0411s/iter; left time: 2252.2962s\n",
            "\titers: 1300, epoch: 25 | loss: 0.0218534\n",
            "\tspeed: 0.0412s/iter; left time: 2251.8973s\n",
            "\titers: 1400, epoch: 25 | loss: 0.0217406\n",
            "\tspeed: 0.0411s/iter; left time: 2239.6038s\n",
            "\titers: 1500, epoch: 25 | loss: 0.0541857\n",
            "\tspeed: 0.0411s/iter; left time: 2238.8948s\n",
            "\titers: 1600, epoch: 25 | loss: 0.0290662\n",
            "\tspeed: 0.0411s/iter; left time: 2235.4177s\n",
            "\titers: 1700, epoch: 25 | loss: 0.0022234\n",
            "\tspeed: 0.0410s/iter; left time: 2222.9398s\n",
            "\titers: 1800, epoch: 25 | loss: 0.0031452\n",
            "\tspeed: 0.0410s/iter; left time: 2220.9735s\n",
            "\titers: 1900, epoch: 25 | loss: 0.0017196\n",
            "\tspeed: 0.0418s/iter; left time: 2260.6743s\n",
            "\titers: 2000, epoch: 25 | loss: 0.0042034\n",
            "\tspeed: 0.0418s/iter; left time: 2253.1952s\n",
            "\titers: 2100, epoch: 25 | loss: 0.0321829\n",
            "\tspeed: 0.0415s/iter; left time: 2237.0717s\n",
            "Epoch: 25 cost time: 88.90153074264526\n",
            "Epoch: 25, Steps: 2152 | Train Loss: 0.0302019 Vali Loss: 0.0132765 Test Loss: 1.0978976\n",
            "EarlyStopping counter: 21 out of 50\n",
            "Updating learning rate to 5.960464477539063e-12\n",
            "\titers: 100, epoch: 26 | loss: 0.0016004\n",
            "\tspeed: 0.2793s/iter; left time: 14998.6810s\n",
            "\titers: 200, epoch: 26 | loss: 0.0443004\n",
            "\tspeed: 0.0410s/iter; left time: 2200.1218s\n",
            "\titers: 300, epoch: 26 | loss: 0.0308371\n",
            "\tspeed: 0.0410s/iter; left time: 2191.4405s\n",
            "\titers: 400, epoch: 26 | loss: 0.0027988\n",
            "\tspeed: 0.0411s/iter; left time: 2193.3907s\n",
            "\titers: 500, epoch: 26 | loss: 0.0013207\n",
            "\tspeed: 0.0411s/iter; left time: 2188.8872s\n",
            "\titers: 600, epoch: 26 | loss: 0.0019003\n",
            "\tspeed: 0.0412s/iter; left time: 2190.5260s\n",
            "\titers: 700, epoch: 26 | loss: 0.0042359\n",
            "\tspeed: 0.0411s/iter; left time: 2184.1035s\n",
            "\titers: 800, epoch: 26 | loss: 0.0024908\n",
            "\tspeed: 0.0419s/iter; left time: 2219.6427s\n",
            "\titers: 900, epoch: 26 | loss: 0.0012940\n",
            "\tspeed: 0.0417s/iter; left time: 2205.9348s\n",
            "\titers: 1000, epoch: 26 | loss: 0.0154552\n",
            "\tspeed: 0.0417s/iter; left time: 2201.4574s\n",
            "\titers: 1100, epoch: 26 | loss: 0.0014891\n",
            "\tspeed: 0.0416s/iter; left time: 2190.8277s\n",
            "\titers: 1200, epoch: 26 | loss: 0.0022957\n",
            "\tspeed: 0.0416s/iter; left time: 2187.2379s\n",
            "\titers: 1300, epoch: 26 | loss: 0.0054731\n",
            "\tspeed: 0.0417s/iter; left time: 2186.9714s\n",
            "\titers: 1400, epoch: 26 | loss: 0.0015844\n",
            "\tspeed: 0.0415s/iter; left time: 2177.0676s\n",
            "\titers: 1500, epoch: 26 | loss: 0.0014773\n",
            "\tspeed: 0.0413s/iter; left time: 2160.7699s\n",
            "\titers: 1600, epoch: 26 | loss: 0.0067515\n",
            "\tspeed: 0.0414s/iter; left time: 2162.2816s\n",
            "\titers: 1700, epoch: 26 | loss: 0.0125972\n",
            "\tspeed: 0.0415s/iter; left time: 2162.8238s\n",
            "\titers: 1800, epoch: 26 | loss: 0.0035775\n",
            "\tspeed: 0.0415s/iter; left time: 2159.6847s\n",
            "\titers: 1900, epoch: 26 | loss: 0.0017224\n",
            "\tspeed: 0.0416s/iter; left time: 2156.9310s\n",
            "\titers: 2000, epoch: 26 | loss: 0.0020192\n",
            "\tspeed: 0.0417s/iter; left time: 2160.8403s\n",
            "\titers: 2100, epoch: 26 | loss: 0.0031527\n",
            "\tspeed: 0.0415s/iter; left time: 2145.8382s\n",
            "Epoch: 26 cost time: 89.14344835281372\n",
            "Epoch: 26, Steps: 2152 | Train Loss: 0.0303196 Vali Loss: 0.0136213 Test Loss: 1.0979439\n",
            "EarlyStopping counter: 22 out of 50\n",
            "Updating learning rate to 2.9802322387695314e-12\n",
            "\titers: 100, epoch: 27 | loss: 0.0015297\n",
            "\tspeed: 0.2784s/iter; left time: 14350.9821s\n",
            "\titers: 200, epoch: 27 | loss: 0.0016796\n",
            "\tspeed: 0.0410s/iter; left time: 2108.7792s\n",
            "\titers: 300, epoch: 27 | loss: 0.0019629\n",
            "\tspeed: 0.0412s/iter; left time: 2115.9487s\n",
            "\titers: 400, epoch: 27 | loss: 0.0145812\n",
            "\tspeed: 0.0412s/iter; left time: 2110.5059s\n",
            "\titers: 500, epoch: 27 | loss: 0.0028855\n",
            "\tspeed: 0.0414s/iter; left time: 2116.8435s\n",
            "\titers: 600, epoch: 27 | loss: 0.0575659\n",
            "\tspeed: 0.0416s/iter; left time: 2125.3948s\n",
            "\titers: 700, epoch: 27 | loss: 0.0014235\n",
            "\tspeed: 0.0416s/iter; left time: 2118.5058s\n",
            "\titers: 800, epoch: 27 | loss: 0.0040032\n",
            "\tspeed: 0.0418s/iter; left time: 2126.8138s\n",
            "\titers: 900, epoch: 27 | loss: 0.0015518\n",
            "\tspeed: 0.0416s/iter; left time: 2110.3262s\n",
            "\titers: 1000, epoch: 27 | loss: 0.0015214\n",
            "\tspeed: 0.0416s/iter; left time: 2107.7940s\n",
            "\titers: 1100, epoch: 27 | loss: 0.0027788\n",
            "\tspeed: 0.0418s/iter; left time: 2111.0647s\n",
            "\titers: 1200, epoch: 27 | loss: 0.0172897\n",
            "\tspeed: 0.0410s/iter; left time: 2066.6532s\n",
            "\titers: 1300, epoch: 27 | loss: 0.0024112\n",
            "\tspeed: 0.0413s/iter; left time: 2077.0463s\n",
            "\titers: 1400, epoch: 27 | loss: 0.0145961\n",
            "\tspeed: 0.0412s/iter; left time: 2071.0893s\n",
            "\titers: 1500, epoch: 27 | loss: 0.0019590\n",
            "\tspeed: 0.0408s/iter; left time: 2047.3598s\n",
            "\titers: 1600, epoch: 27 | loss: 0.0019246\n",
            "\tspeed: 0.0407s/iter; left time: 2038.2280s\n",
            "\titers: 1700, epoch: 27 | loss: 0.0019940\n",
            "\tspeed: 0.0413s/iter; left time: 2061.2384s\n",
            "\titers: 1800, epoch: 27 | loss: 0.0256765\n",
            "\tspeed: 0.0412s/iter; left time: 2053.5646s\n",
            "\titers: 1900, epoch: 27 | loss: 0.0637185\n",
            "\tspeed: 0.0411s/iter; left time: 2046.5101s\n",
            "\titers: 2000, epoch: 27 | loss: 0.0089664\n",
            "\tspeed: 0.0411s/iter; left time: 2041.7559s\n",
            "\titers: 2100, epoch: 27 | loss: 0.0018892\n",
            "\tspeed: 0.0417s/iter; left time: 2064.2201s\n",
            "Epoch: 27 cost time: 88.93016362190247\n",
            "Epoch: 27, Steps: 2152 | Train Loss: 0.0300383 Vali Loss: 0.0139472 Test Loss: 1.1004385\n",
            "EarlyStopping counter: 23 out of 50\n",
            "Updating learning rate to 1.4901161193847657e-12\n",
            "\titers: 100, epoch: 28 | loss: 0.0020071\n",
            "\tspeed: 0.2798s/iter; left time: 13819.1472s\n",
            "\titers: 200, epoch: 28 | loss: 0.0009835\n",
            "\tspeed: 0.0407s/iter; left time: 2008.1379s\n",
            "\titers: 300, epoch: 28 | loss: 0.0017550\n",
            "\tspeed: 0.0408s/iter; left time: 2005.9284s\n",
            "\titers: 400, epoch: 28 | loss: 0.0028322\n",
            "\tspeed: 0.0411s/iter; left time: 2018.6835s\n",
            "\titers: 500, epoch: 28 | loss: 0.0556044\n",
            "\tspeed: 0.0411s/iter; left time: 2014.1297s\n",
            "\titers: 600, epoch: 28 | loss: 0.0010804\n",
            "\tspeed: 0.0408s/iter; left time: 1994.5310s\n",
            "\titers: 700, epoch: 28 | loss: 0.0121547\n",
            "\tspeed: 0.0413s/iter; left time: 2013.8767s\n",
            "\titers: 800, epoch: 28 | loss: 0.0026396\n",
            "\tspeed: 0.0410s/iter; left time: 1994.4180s\n",
            "\titers: 900, epoch: 28 | loss: 0.0013551\n",
            "\tspeed: 0.0409s/iter; left time: 1988.4964s\n",
            "\titers: 1000, epoch: 28 | loss: 0.0135260\n",
            "\tspeed: 0.0412s/iter; left time: 1997.0417s\n",
            "\titers: 1100, epoch: 28 | loss: 0.0006646\n",
            "\tspeed: 0.0415s/iter; left time: 2010.7577s\n",
            "\titers: 1200, epoch: 28 | loss: 0.0017178\n",
            "\tspeed: 0.0415s/iter; left time: 2002.3756s\n",
            "\titers: 1300, epoch: 28 | loss: 0.0236366\n",
            "\tspeed: 0.0416s/iter; left time: 2002.6672s\n",
            "\titers: 1400, epoch: 28 | loss: 0.0882763\n",
            "\tspeed: 0.0417s/iter; left time: 2003.6244s\n",
            "\titers: 1500, epoch: 28 | loss: 0.0020983\n",
            "\tspeed: 0.0416s/iter; left time: 1997.6546s\n",
            "\titers: 1600, epoch: 28 | loss: 0.0016373\n",
            "\tspeed: 0.0413s/iter; left time: 1977.9665s\n",
            "\titers: 1700, epoch: 28 | loss: 0.0057433\n",
            "\tspeed: 0.0411s/iter; left time: 1966.3584s\n",
            "\titers: 1800, epoch: 28 | loss: 0.0044232\n",
            "\tspeed: 0.0410s/iter; left time: 1957.0329s\n",
            "\titers: 1900, epoch: 28 | loss: 0.0018162\n",
            "\tspeed: 0.0412s/iter; left time: 1959.2287s\n",
            "\titers: 2000, epoch: 28 | loss: 0.0018553\n",
            "\tspeed: 0.0412s/iter; left time: 1956.9943s\n",
            "\titers: 2100, epoch: 28 | loss: 0.0226417\n",
            "\tspeed: 0.0411s/iter; left time: 1950.1529s\n",
            "Epoch: 28 cost time: 88.62067317962646\n",
            "Epoch: 28, Steps: 2152 | Train Loss: 0.0301733 Vali Loss: 0.0139484 Test Loss: 1.0987093\n",
            "EarlyStopping counter: 24 out of 50\n",
            "Updating learning rate to 7.450580596923828e-13\n",
            "\titers: 100, epoch: 29 | loss: 0.0025553\n",
            "\tspeed: 0.2790s/iter; left time: 13180.6995s\n",
            "\titers: 200, epoch: 29 | loss: 0.0016343\n",
            "\tspeed: 0.0414s/iter; left time: 1952.4087s\n",
            "\titers: 300, epoch: 29 | loss: 0.0026735\n",
            "\tspeed: 0.0417s/iter; left time: 1960.7326s\n",
            "\titers: 400, epoch: 29 | loss: 0.0020426\n",
            "\tspeed: 0.0416s/iter; left time: 1951.5823s\n",
            "\titers: 500, epoch: 29 | loss: 0.0012188\n",
            "\tspeed: 0.0415s/iter; left time: 1946.3620s\n",
            "\titers: 600, epoch: 29 | loss: 0.0030955\n",
            "\tspeed: 0.0410s/iter; left time: 1916.5211s\n",
            "\titers: 700, epoch: 29 | loss: 0.0026648\n",
            "\tspeed: 0.0413s/iter; left time: 1925.7693s\n",
            "\titers: 800, epoch: 29 | loss: 0.0502797\n",
            "\tspeed: 0.0410s/iter; left time: 1908.8478s\n",
            "\titers: 900, epoch: 29 | loss: 0.0029807\n",
            "\tspeed: 0.0413s/iter; left time: 1919.1717s\n",
            "\titers: 1000, epoch: 29 | loss: 0.0112303\n",
            "\tspeed: 0.0411s/iter; left time: 1903.6649s\n",
            "\titers: 1100, epoch: 29 | loss: 0.0015235\n",
            "\tspeed: 0.0412s/iter; left time: 1904.4775s\n",
            "\titers: 1200, epoch: 29 | loss: 0.0009106\n",
            "\tspeed: 0.0411s/iter; left time: 1897.3450s\n",
            "\titers: 1300, epoch: 29 | loss: 0.0019915\n",
            "\tspeed: 0.0410s/iter; left time: 1886.7113s\n",
            "\titers: 1400, epoch: 29 | loss: 0.0029572\n",
            "\tspeed: 0.0412s/iter; left time: 1891.6513s\n",
            "\titers: 1500, epoch: 29 | loss: 0.0024029\n",
            "\tspeed: 0.0414s/iter; left time: 1898.9287s\n",
            "\titers: 1600, epoch: 29 | loss: 0.0771705\n",
            "\tspeed: 0.0417s/iter; left time: 1907.6311s\n",
            "\titers: 1700, epoch: 29 | loss: 0.3435076\n",
            "\tspeed: 0.0417s/iter; left time: 1904.0818s\n",
            "\titers: 1800, epoch: 29 | loss: 0.0016009\n",
            "\tspeed: 0.0415s/iter; left time: 1891.2142s\n",
            "\titers: 1900, epoch: 29 | loss: 0.0123551\n",
            "\tspeed: 0.0416s/iter; left time: 1892.7099s\n",
            "\titers: 2000, epoch: 29 | loss: 0.0116674\n",
            "\tspeed: 0.0418s/iter; left time: 1895.9419s\n",
            "\titers: 2100, epoch: 29 | loss: 0.0035683\n",
            "\tspeed: 0.0415s/iter; left time: 1877.9717s\n",
            "Epoch: 29 cost time: 89.08710074424744\n",
            "Epoch: 29, Steps: 2152 | Train Loss: 0.0301379 Vali Loss: 0.0147553 Test Loss: 1.1007081\n",
            "EarlyStopping counter: 25 out of 50\n",
            "Updating learning rate to 3.725290298461914e-13\n",
            "\titers: 100, epoch: 30 | loss: 0.0091901\n",
            "\tspeed: 0.2801s/iter; left time: 12632.7123s\n",
            "\titers: 200, epoch: 30 | loss: 0.0479345\n",
            "\tspeed: 0.0418s/iter; left time: 1878.6987s\n",
            "\titers: 300, epoch: 30 | loss: 0.0023644\n",
            "\tspeed: 0.0416s/iter; left time: 1866.3030s\n",
            "\titers: 400, epoch: 30 | loss: 0.0053868\n",
            "\tspeed: 0.0413s/iter; left time: 1848.9858s\n",
            "\titers: 500, epoch: 30 | loss: 0.0109757\n",
            "\tspeed: 0.0406s/iter; left time: 1815.2371s\n",
            "\titers: 600, epoch: 30 | loss: 0.0023711\n",
            "\tspeed: 0.0413s/iter; left time: 1842.9746s\n",
            "\titers: 700, epoch: 30 | loss: 0.0458664\n",
            "\tspeed: 0.0411s/iter; left time: 1830.7973s\n",
            "\titers: 800, epoch: 30 | loss: 0.0271914\n",
            "\tspeed: 0.0409s/iter; left time: 1814.6767s\n",
            "\titers: 900, epoch: 30 | loss: 0.0050936\n",
            "\tspeed: 0.0410s/iter; left time: 1815.7384s\n",
            "\titers: 1000, epoch: 30 | loss: 0.0024974\n",
            "\tspeed: 0.0411s/iter; left time: 1814.8180s\n",
            "\titers: 1100, epoch: 30 | loss: 0.0055026\n",
            "\tspeed: 0.0412s/iter; left time: 1818.6371s\n",
            "\titers: 1200, epoch: 30 | loss: 0.0285845\n",
            "\tspeed: 0.0409s/iter; left time: 1799.8131s\n",
            "\titers: 1300, epoch: 30 | loss: 0.0018518\n",
            "\tspeed: 0.0417s/iter; left time: 1831.0551s\n",
            "\titers: 1400, epoch: 30 | loss: 0.0024094\n",
            "\tspeed: 0.0417s/iter; left time: 1827.5145s\n",
            "\titers: 1500, epoch: 30 | loss: 0.0020307\n",
            "\tspeed: 0.0418s/iter; left time: 1827.2342s\n",
            "\titers: 1600, epoch: 30 | loss: 0.0019248\n",
            "\tspeed: 0.0414s/iter; left time: 1803.1265s\n",
            "\titers: 1700, epoch: 30 | loss: 0.0021746\n",
            "\tspeed: 0.0416s/iter; left time: 1808.3806s\n",
            "\titers: 1800, epoch: 30 | loss: 0.0306590\n",
            "\tspeed: 0.0417s/iter; left time: 1807.4223s\n",
            "\titers: 1900, epoch: 30 | loss: 0.0299452\n",
            "\tspeed: 0.0412s/iter; left time: 1781.5525s\n",
            "\titers: 2000, epoch: 30 | loss: 0.0011366\n",
            "\tspeed: 0.0409s/iter; left time: 1766.6782s\n",
            "\titers: 2100, epoch: 30 | loss: 0.0112638\n",
            "\tspeed: 0.0410s/iter; left time: 1766.4989s\n",
            "Epoch: 30 cost time: 88.88888669013977\n",
            "Epoch: 30, Steps: 2152 | Train Loss: 0.0306280 Vali Loss: 0.0142893 Test Loss: 1.0973271\n",
            "EarlyStopping counter: 26 out of 50\n",
            "Updating learning rate to 1.862645149230957e-13\n",
            "\titers: 100, epoch: 31 | loss: 0.0015758\n",
            "\tspeed: 0.2784s/iter; left time: 11952.8149s\n",
            "\titers: 200, epoch: 31 | loss: 0.0155011\n",
            "\tspeed: 0.0411s/iter; left time: 1761.4563s\n",
            "\titers: 300, epoch: 31 | loss: 0.0013182\n",
            "\tspeed: 0.0415s/iter; left time: 1773.8099s\n",
            "\titers: 400, epoch: 31 | loss: 0.0074543\n",
            "\tspeed: 0.0415s/iter; left time: 1767.7103s\n",
            "\titers: 500, epoch: 31 | loss: 0.0012696\n",
            "\tspeed: 0.0419s/iter; left time: 1781.1460s\n",
            "\titers: 600, epoch: 31 | loss: 0.0912808\n",
            "\tspeed: 0.0414s/iter; left time: 1758.1113s\n",
            "\titers: 700, epoch: 31 | loss: 0.0020490\n",
            "\tspeed: 0.0415s/iter; left time: 1758.2405s\n",
            "\titers: 800, epoch: 31 | loss: 0.0988414\n",
            "\tspeed: 0.0413s/iter; left time: 1745.6742s\n",
            "\titers: 900, epoch: 31 | loss: 0.0059078\n",
            "\tspeed: 0.0414s/iter; left time: 1744.8684s\n",
            "\titers: 1000, epoch: 31 | loss: 0.0471391\n",
            "\tspeed: 0.0410s/iter; left time: 1721.6756s\n",
            "\titers: 1100, epoch: 31 | loss: 0.0020641\n",
            "\tspeed: 0.0413s/iter; left time: 1731.7633s\n",
            "\titers: 1200, epoch: 31 | loss: 0.0018574\n",
            "\tspeed: 0.0410s/iter; left time: 1716.1067s\n",
            "\titers: 1300, epoch: 31 | loss: 0.0047074\n",
            "\tspeed: 0.0412s/iter; left time: 1718.2043s\n",
            "\titers: 1400, epoch: 31 | loss: 0.0653909\n",
            "\tspeed: 0.0410s/iter; left time: 1706.7532s\n",
            "\titers: 1500, epoch: 31 | loss: 0.0020942\n",
            "\tspeed: 0.0410s/iter; left time: 1703.9271s\n",
            "\titers: 1600, epoch: 31 | loss: 0.0014942\n",
            "\tspeed: 0.0412s/iter; left time: 1706.9788s\n",
            "\titers: 1700, epoch: 31 | loss: 0.0010443\n",
            "\tspeed: 0.0409s/iter; left time: 1692.1441s\n",
            "\titers: 1800, epoch: 31 | loss: 0.0017122\n",
            "\tspeed: 0.0417s/iter; left time: 1718.2740s\n",
            "\titers: 1900, epoch: 31 | loss: 0.0015353\n",
            "\tspeed: 0.0416s/iter; left time: 1709.9986s\n",
            "\titers: 2000, epoch: 31 | loss: 0.0009644\n",
            "\tspeed: 0.0416s/iter; left time: 1708.8492s\n",
            "\titers: 2100, epoch: 31 | loss: 0.0013593\n",
            "\tspeed: 0.0415s/iter; left time: 1699.3689s\n",
            "Epoch: 31 cost time: 88.94271874427795\n",
            "Epoch: 31, Steps: 2152 | Train Loss: 0.0304635 Vali Loss: 0.0138693 Test Loss: 1.0984601\n",
            "EarlyStopping counter: 27 out of 50\n",
            "Updating learning rate to 9.313225746154786e-14\n",
            "\titers: 100, epoch: 32 | loss: 0.0625308\n",
            "\tspeed: 0.2791s/iter; left time: 11385.5191s\n",
            "\titers: 200, epoch: 32 | loss: 0.0016057\n",
            "\tspeed: 0.0408s/iter; left time: 1658.4518s\n",
            "\titers: 300, epoch: 32 | loss: 0.0024737\n",
            "\tspeed: 0.0409s/iter; left time: 1658.1356s\n",
            "\titers: 400, epoch: 32 | loss: 0.0021315\n",
            "\tspeed: 0.0411s/iter; left time: 1665.6189s\n",
            "\titers: 500, epoch: 32 | loss: 0.0027867\n",
            "\tspeed: 0.0411s/iter; left time: 1660.6091s\n",
            "\titers: 600, epoch: 32 | loss: 0.0011579\n",
            "\tspeed: 0.0412s/iter; left time: 1659.2772s\n",
            "\titers: 700, epoch: 32 | loss: 0.0019382\n",
            "\tspeed: 0.0415s/iter; left time: 1667.5825s\n",
            "\titers: 800, epoch: 32 | loss: 0.0053008\n",
            "\tspeed: 0.0416s/iter; left time: 1666.3309s\n",
            "\titers: 900, epoch: 32 | loss: 0.0031728\n",
            "\tspeed: 0.0416s/iter; left time: 1661.7794s\n",
            "\titers: 1000, epoch: 32 | loss: 0.0265349\n",
            "\tspeed: 0.0417s/iter; left time: 1664.4441s\n",
            "\titers: 1100, epoch: 32 | loss: 0.0026471\n",
            "\tspeed: 0.0413s/iter; left time: 1644.0268s\n",
            "\titers: 1200, epoch: 32 | loss: 0.0013937\n",
            "\tspeed: 0.0417s/iter; left time: 1655.8880s\n",
            "\titers: 1300, epoch: 32 | loss: 0.0013885\n",
            "\tspeed: 0.0413s/iter; left time: 1636.6733s\n",
            "\titers: 1400, epoch: 32 | loss: 0.0011917\n",
            "\tspeed: 0.0411s/iter; left time: 1624.7782s\n",
            "\titers: 1500, epoch: 32 | loss: 0.0040312\n",
            "\tspeed: 0.0413s/iter; left time: 1628.4828s\n",
            "\titers: 1600, epoch: 32 | loss: 0.0021830\n",
            "\tspeed: 0.0415s/iter; left time: 1631.3309s\n",
            "\titers: 1700, epoch: 32 | loss: 0.0560319\n",
            "\tspeed: 0.0416s/iter; left time: 1631.5775s\n",
            "\titers: 1800, epoch: 32 | loss: 0.0283279\n",
            "\tspeed: 0.0415s/iter; left time: 1621.7100s\n",
            "\titers: 1900, epoch: 32 | loss: 0.0022775\n",
            "\tspeed: 0.0417s/iter; left time: 1624.2634s\n",
            "\titers: 2000, epoch: 32 | loss: 0.0027946\n",
            "\tspeed: 0.0414s/iter; left time: 1611.3382s\n",
            "\titers: 2100, epoch: 32 | loss: 0.0046513\n",
            "\tspeed: 0.0409s/iter; left time: 1585.9244s\n",
            "Epoch: 32 cost time: 88.91635227203369\n",
            "Epoch: 32, Steps: 2152 | Train Loss: 0.0301556 Vali Loss: 0.0133331 Test Loss: 1.0982665\n",
            "EarlyStopping counter: 28 out of 50\n",
            "Updating learning rate to 4.656612873077393e-14\n",
            "\titers: 100, epoch: 33 | loss: 0.0012720\n",
            "\tspeed: 0.2776s/iter; left time: 10724.3500s\n",
            "\titers: 200, epoch: 33 | loss: 0.0016248\n",
            "\tspeed: 0.0411s/iter; left time: 1585.7340s\n",
            "\titers: 300, epoch: 33 | loss: 0.0010217\n",
            "\tspeed: 0.0412s/iter; left time: 1581.9488s\n",
            "\titers: 400, epoch: 33 | loss: 0.0011651\n",
            "\tspeed: 0.0413s/iter; left time: 1583.4868s\n",
            "\titers: 500, epoch: 33 | loss: 0.0018891\n",
            "\tspeed: 0.0418s/iter; left time: 1596.9134s\n",
            "\titers: 600, epoch: 33 | loss: 0.0016223\n",
            "\tspeed: 0.0415s/iter; left time: 1583.3798s\n",
            "\titers: 700, epoch: 33 | loss: 0.0062758\n",
            "\tspeed: 0.0416s/iter; left time: 1583.3310s\n",
            "\titers: 800, epoch: 33 | loss: 0.0019370\n",
            "\tspeed: 0.0417s/iter; left time: 1580.5854s\n",
            "\titers: 900, epoch: 33 | loss: 0.0015818\n",
            "\tspeed: 0.0417s/iter; left time: 1577.2953s\n",
            "\titers: 1000, epoch: 33 | loss: 0.0127365\n",
            "\tspeed: 0.0413s/iter; left time: 1559.3258s\n",
            "\titers: 1100, epoch: 33 | loss: 0.0016772\n",
            "\tspeed: 0.0409s/iter; left time: 1538.4550s\n",
            "\titers: 1200, epoch: 33 | loss: 0.0021296\n",
            "\tspeed: 0.0408s/iter; left time: 1530.2702s\n",
            "\titers: 1300, epoch: 33 | loss: 0.0017656\n",
            "\tspeed: 0.0407s/iter; left time: 1524.2871s\n",
            "\titers: 1400, epoch: 33 | loss: 0.0016592\n",
            "\tspeed: 0.0409s/iter; left time: 1525.2399s\n",
            "\titers: 1500, epoch: 33 | loss: 0.0021958\n",
            "\tspeed: 0.0412s/iter; left time: 1532.4506s\n",
            "\titers: 1600, epoch: 33 | loss: 0.0159292\n",
            "\tspeed: 0.0409s/iter; left time: 1519.1541s\n",
            "\titers: 1700, epoch: 33 | loss: 0.0015536\n",
            "\tspeed: 0.0409s/iter; left time: 1516.5309s\n",
            "\titers: 1800, epoch: 33 | loss: 0.0023699\n",
            "\tspeed: 0.0409s/iter; left time: 1510.7215s\n",
            "\titers: 1900, epoch: 33 | loss: 0.0015071\n",
            "\tspeed: 0.0409s/iter; left time: 1506.8057s\n",
            "\titers: 2000, epoch: 33 | loss: 0.0017263\n",
            "\tspeed: 0.0412s/iter; left time: 1512.9516s\n",
            "\titers: 2100, epoch: 33 | loss: 0.0023999\n",
            "\tspeed: 0.0417s/iter; left time: 1526.2410s\n",
            "Epoch: 33 cost time: 88.67676401138306\n",
            "Epoch: 33, Steps: 2152 | Train Loss: 0.0302745 Vali Loss: 0.0138575 Test Loss: 1.0966585\n",
            "EarlyStopping counter: 29 out of 50\n",
            "Updating learning rate to 2.3283064365386964e-14\n",
            "\titers: 100, epoch: 34 | loss: 0.0031014\n",
            "\tspeed: 0.2787s/iter; left time: 10167.8004s\n",
            "\titers: 200, epoch: 34 | loss: 0.0054763\n",
            "\tspeed: 0.0411s/iter; left time: 1495.6997s\n",
            "\titers: 300, epoch: 34 | loss: 0.0774730\n",
            "\tspeed: 0.0409s/iter; left time: 1485.5534s\n",
            "\titers: 400, epoch: 34 | loss: 0.0981384\n",
            "\tspeed: 0.0409s/iter; left time: 1481.2888s\n",
            "\titers: 500, epoch: 34 | loss: 0.0086004\n",
            "\tspeed: 0.0413s/iter; left time: 1489.6281s\n",
            "\titers: 600, epoch: 34 | loss: 0.0064239\n",
            "\tspeed: 0.0411s/iter; left time: 1480.6852s\n",
            "\titers: 700, epoch: 34 | loss: 0.0457524\n",
            "\tspeed: 0.0411s/iter; left time: 1473.9000s\n",
            "\titers: 800, epoch: 34 | loss: 0.0023540\n",
            "\tspeed: 0.0412s/iter; left time: 1475.7947s\n",
            "\titers: 900, epoch: 34 | loss: 0.0159661\n",
            "\tspeed: 0.0413s/iter; left time: 1474.5315s\n",
            "\titers: 1000, epoch: 34 | loss: 0.0234065\n",
            "\tspeed: 0.0417s/iter; left time: 1483.3235s\n",
            "\titers: 1100, epoch: 34 | loss: 0.0017159\n",
            "\tspeed: 0.0418s/iter; left time: 1482.1921s\n",
            "\titers: 1200, epoch: 34 | loss: 0.0055441\n",
            "\tspeed: 0.0417s/iter; left time: 1476.4625s\n",
            "\titers: 1300, epoch: 34 | loss: 0.0029405\n",
            "\tspeed: 0.0417s/iter; left time: 1471.4876s\n",
            "\titers: 1400, epoch: 34 | loss: 0.0010196\n",
            "\tspeed: 0.0416s/iter; left time: 1463.7110s\n",
            "\titers: 1500, epoch: 34 | loss: 0.0305045\n",
            "\tspeed: 0.0415s/iter; left time: 1457.2844s\n",
            "\titers: 1600, epoch: 34 | loss: 0.0137683\n",
            "\tspeed: 0.0409s/iter; left time: 1431.0382s\n",
            "\titers: 1700, epoch: 34 | loss: 0.0957439\n",
            "\tspeed: 0.0408s/iter; left time: 1423.4118s\n",
            "\titers: 1800, epoch: 34 | loss: 0.0012165\n",
            "\tspeed: 0.0406s/iter; left time: 1411.6870s\n",
            "\titers: 1900, epoch: 34 | loss: 0.0113096\n",
            "\tspeed: 0.0412s/iter; left time: 1427.3536s\n",
            "\titers: 2000, epoch: 34 | loss: 0.0029282\n",
            "\tspeed: 0.0409s/iter; left time: 1416.1501s\n",
            "\titers: 2100, epoch: 34 | loss: 0.0013171\n",
            "\tspeed: 0.0409s/iter; left time: 1410.8949s\n",
            "Epoch: 34 cost time: 88.6620945930481\n",
            "Epoch: 34, Steps: 2152 | Train Loss: 0.0291076 Vali Loss: 0.0138522 Test Loss: 1.1003565\n",
            "EarlyStopping counter: 30 out of 50\n",
            "Updating learning rate to 1.1641532182693482e-14\n",
            "\titers: 100, epoch: 35 | loss: 0.0011442\n",
            "\tspeed: 0.2790s/iter; left time: 9578.3804s\n",
            "\titers: 200, epoch: 35 | loss: 0.0182686\n",
            "\tspeed: 0.0416s/iter; left time: 1423.2189s\n",
            "\titers: 300, epoch: 35 | loss: 0.0027882\n",
            "\tspeed: 0.0414s/iter; left time: 1412.2891s\n",
            "\titers: 400, epoch: 35 | loss: 0.0017900\n",
            "\tspeed: 0.0415s/iter; left time: 1410.6956s\n",
            "\titers: 500, epoch: 35 | loss: 1.9781531\n",
            "\tspeed: 0.0411s/iter; left time: 1394.1109s\n",
            "\titers: 600, epoch: 35 | loss: 0.0410737\n",
            "\tspeed: 0.0409s/iter; left time: 1383.2764s\n",
            "\titers: 700, epoch: 35 | loss: 0.0009754\n",
            "\tspeed: 0.0409s/iter; left time: 1380.8216s\n",
            "\titers: 800, epoch: 35 | loss: 0.0017624\n",
            "\tspeed: 0.0408s/iter; left time: 1371.7311s\n",
            "\titers: 900, epoch: 35 | loss: 0.0020337\n",
            "\tspeed: 0.0409s/iter; left time: 1371.9989s\n",
            "\titers: 1000, epoch: 35 | loss: 0.2226107\n",
            "\tspeed: 0.0406s/iter; left time: 1356.5266s\n",
            "\titers: 1100, epoch: 35 | loss: 0.0135299\n",
            "\tspeed: 0.0409s/iter; left time: 1363.6376s\n",
            "\titers: 1200, epoch: 35 | loss: 0.0013498\n",
            "\tspeed: 0.0409s/iter; left time: 1360.4304s\n",
            "\titers: 1300, epoch: 35 | loss: 0.0370711\n",
            "\tspeed: 0.0409s/iter; left time: 1355.3347s\n",
            "\titers: 1400, epoch: 35 | loss: 0.0525380\n",
            "\tspeed: 0.0409s/iter; left time: 1352.2012s\n",
            "\titers: 1500, epoch: 35 | loss: 0.0027841\n",
            "\tspeed: 0.0412s/iter; left time: 1357.1571s\n",
            "\titers: 1600, epoch: 35 | loss: 0.0137132\n",
            "\tspeed: 0.0416s/iter; left time: 1367.3037s\n",
            "\titers: 1700, epoch: 35 | loss: 0.0031537\n",
            "\tspeed: 0.0420s/iter; left time: 1375.6666s\n",
            "\titers: 1800, epoch: 35 | loss: 0.0013470\n",
            "\tspeed: 0.0418s/iter; left time: 1364.5535s\n",
            "\titers: 1900, epoch: 35 | loss: 0.0023622\n",
            "\tspeed: 0.0418s/iter; left time: 1359.2187s\n",
            "\titers: 2000, epoch: 35 | loss: 0.0014420\n",
            "\tspeed: 0.0416s/iter; left time: 1349.4218s\n",
            "\titers: 2100, epoch: 35 | loss: 0.0417332\n",
            "\tspeed: 0.0415s/iter; left time: 1340.2940s\n",
            "Epoch: 35 cost time: 88.78268074989319\n",
            "Epoch: 35, Steps: 2152 | Train Loss: 0.0302188 Vali Loss: 0.0138157 Test Loss: 1.0997142\n",
            "EarlyStopping counter: 31 out of 50\n",
            "Updating learning rate to 5.820766091346741e-15\n",
            "\titers: 100, epoch: 36 | loss: 0.0008870\n",
            "\tspeed: 0.2806s/iter; left time: 9031.5742s\n",
            "\titers: 200, epoch: 36 | loss: 0.0019347\n",
            "\tspeed: 0.0414s/iter; left time: 1326.7474s\n",
            "\titers: 300, epoch: 36 | loss: 0.0100443\n",
            "\tspeed: 0.0411s/iter; left time: 1315.5206s\n",
            "\titers: 400, epoch: 36 | loss: 0.0014725\n",
            "\tspeed: 0.0411s/iter; left time: 1311.2460s\n",
            "\titers: 500, epoch: 36 | loss: 0.0019401\n",
            "\tspeed: 0.0411s/iter; left time: 1306.0462s\n",
            "\titers: 600, epoch: 36 | loss: 0.0014710\n",
            "\tspeed: 0.0408s/iter; left time: 1293.1656s\n",
            "\titers: 700, epoch: 36 | loss: 0.0022834\n",
            "\tspeed: 0.0411s/iter; left time: 1299.1351s\n",
            "\titers: 800, epoch: 36 | loss: 0.0019648\n",
            "\tspeed: 0.0409s/iter; left time: 1288.1221s\n",
            "\titers: 900, epoch: 36 | loss: 0.0028804\n",
            "\tspeed: 0.0414s/iter; left time: 1297.9835s\n",
            "\titers: 1000, epoch: 36 | loss: 0.0011405\n",
            "\tspeed: 0.0409s/iter; left time: 1280.6837s\n",
            "\titers: 1100, epoch: 36 | loss: 0.0249234\n",
            "\tspeed: 0.0408s/iter; left time: 1270.7327s\n",
            "\titers: 1200, epoch: 36 | loss: 0.0012428\n",
            "\tspeed: 0.0414s/iter; left time: 1286.2204s\n",
            "\titers: 1300, epoch: 36 | loss: 0.0177245\n",
            "\tspeed: 0.0416s/iter; left time: 1288.9888s\n",
            "\titers: 1400, epoch: 36 | loss: 0.0287132\n",
            "\tspeed: 0.0414s/iter; left time: 1277.4193s\n",
            "\titers: 1500, epoch: 36 | loss: 0.0017609\n",
            "\tspeed: 0.0415s/iter; left time: 1278.1983s\n",
            "\titers: 1600, epoch: 36 | loss: 0.0022233\n",
            "\tspeed: 0.0414s/iter; left time: 1268.8461s\n",
            "\titers: 1700, epoch: 36 | loss: 0.0013293\n",
            "\tspeed: 0.0418s/iter; left time: 1277.6745s\n",
            "\titers: 1800, epoch: 36 | loss: 0.0019392\n",
            "\tspeed: 0.0415s/iter; left time: 1265.2556s\n",
            "\titers: 1900, epoch: 36 | loss: 0.0026050\n",
            "\tspeed: 0.0413s/iter; left time: 1253.7000s\n",
            "\titers: 2000, epoch: 36 | loss: 0.0023663\n",
            "\tspeed: 0.0411s/iter; left time: 1245.2593s\n",
            "\titers: 2100, epoch: 36 | loss: 0.0020328\n",
            "\tspeed: 0.0414s/iter; left time: 1248.3369s\n",
            "Epoch: 36 cost time: 88.79904389381409\n",
            "Epoch: 36, Steps: 2152 | Train Loss: 0.0297452 Vali Loss: 0.0138817 Test Loss: 1.0970553\n",
            "EarlyStopping counter: 32 out of 50\n",
            "Updating learning rate to 2.9103830456733705e-15\n",
            "\titers: 100, epoch: 37 | loss: 0.0014744\n",
            "\tspeed: 0.2776s/iter; left time: 8337.4393s\n",
            "\titers: 200, epoch: 37 | loss: 0.0027468\n",
            "\tspeed: 0.0413s/iter; left time: 1237.2159s\n",
            "\titers: 300, epoch: 37 | loss: 0.0016251\n",
            "\tspeed: 0.0416s/iter; left time: 1240.9908s\n",
            "\titers: 400, epoch: 37 | loss: 0.0457686\n",
            "\tspeed: 0.0416s/iter; left time: 1235.4980s\n",
            "\titers: 500, epoch: 37 | loss: 0.0019227\n",
            "\tspeed: 0.0415s/iter; left time: 1230.1215s\n",
            "\titers: 600, epoch: 37 | loss: 0.0019298\n",
            "\tspeed: 0.0413s/iter; left time: 1219.4895s\n",
            "\titers: 700, epoch: 37 | loss: 0.0018752\n",
            "\tspeed: 0.0416s/iter; left time: 1224.2521s\n",
            "\titers: 800, epoch: 37 | loss: 0.0489404\n",
            "\tspeed: 0.0411s/iter; left time: 1205.9574s\n",
            "\titers: 900, epoch: 37 | loss: 0.0027553\n",
            "\tspeed: 0.0412s/iter; left time: 1203.2436s\n",
            "\titers: 1000, epoch: 37 | loss: 0.0609027\n",
            "\tspeed: 0.0413s/iter; left time: 1202.6742s\n",
            "\titers: 1100, epoch: 37 | loss: 0.0022177\n",
            "\tspeed: 0.0412s/iter; left time: 1195.5243s\n",
            "\titers: 1200, epoch: 37 | loss: 0.0020042\n",
            "\tspeed: 0.0408s/iter; left time: 1180.9934s\n",
            "\titers: 1300, epoch: 37 | loss: 0.0018468\n",
            "\tspeed: 0.0410s/iter; left time: 1183.3981s\n",
            "\titers: 1400, epoch: 37 | loss: 0.0023672\n",
            "\tspeed: 0.0410s/iter; left time: 1178.8602s\n",
            "\titers: 1500, epoch: 37 | loss: 0.0017203\n",
            "\tspeed: 0.0414s/iter; left time: 1184.3692s\n",
            "\titers: 1600, epoch: 37 | loss: 0.0180485\n",
            "\tspeed: 0.0410s/iter; left time: 1170.2209s\n",
            "\titers: 1700, epoch: 37 | loss: 0.0029737\n",
            "\tspeed: 0.0410s/iter; left time: 1164.6713s\n",
            "\titers: 1800, epoch: 37 | loss: 0.0025234\n",
            "\tspeed: 0.0416s/iter; left time: 1178.2248s\n",
            "\titers: 1900, epoch: 37 | loss: 0.0011793\n",
            "\tspeed: 0.0415s/iter; left time: 1170.0943s\n",
            "\titers: 2000, epoch: 37 | loss: 0.0020903\n",
            "\tspeed: 0.0415s/iter; left time: 1167.8550s\n",
            "\titers: 2100, epoch: 37 | loss: 0.0014835\n",
            "\tspeed: 0.0416s/iter; left time: 1165.7564s\n",
            "Epoch: 37 cost time: 88.86220073699951\n",
            "Epoch: 37, Steps: 2152 | Train Loss: 0.0301566 Vali Loss: 0.0142988 Test Loss: 1.0997260\n",
            "EarlyStopping counter: 33 out of 50\n",
            "Updating learning rate to 1.4551915228366853e-15\n",
            "\titers: 100, epoch: 38 | loss: 0.0024056\n",
            "\tspeed: 0.2791s/iter; left time: 7781.5984s\n",
            "\titers: 200, epoch: 38 | loss: 0.0014645\n",
            "\tspeed: 0.0411s/iter; left time: 1142.6420s\n",
            "\titers: 300, epoch: 38 | loss: 0.0023976\n",
            "\tspeed: 0.0409s/iter; left time: 1132.4427s\n",
            "\titers: 400, epoch: 38 | loss: 0.0024858\n",
            "\tspeed: 0.0411s/iter; left time: 1134.1624s\n",
            "\titers: 500, epoch: 38 | loss: 0.0023365\n",
            "\tspeed: 0.0409s/iter; left time: 1124.9157s\n",
            "\titers: 600, epoch: 38 | loss: 0.0009616\n",
            "\tspeed: 0.0412s/iter; left time: 1127.2129s\n",
            "\titers: 700, epoch: 38 | loss: 0.0019596\n",
            "\tspeed: 0.0414s/iter; left time: 1129.8530s\n",
            "\titers: 800, epoch: 38 | loss: 0.0016773\n",
            "\tspeed: 0.0417s/iter; left time: 1133.7612s\n",
            "\titers: 900, epoch: 38 | loss: 0.0032661\n",
            "\tspeed: 0.0416s/iter; left time: 1126.8483s\n",
            "\titers: 1000, epoch: 38 | loss: 0.0018359\n",
            "\tspeed: 0.0416s/iter; left time: 1122.0781s\n",
            "\titers: 1100, epoch: 38 | loss: 0.0093585\n",
            "\tspeed: 0.0418s/iter; left time: 1123.1654s\n",
            "\titers: 1200, epoch: 38 | loss: 0.0015410\n",
            "\tspeed: 0.0417s/iter; left time: 1117.6611s\n",
            "\titers: 1300, epoch: 38 | loss: 0.0158992\n",
            "\tspeed: 0.0413s/iter; left time: 1102.5405s\n",
            "\titers: 1400, epoch: 38 | loss: 0.0019237\n",
            "\tspeed: 0.0412s/iter; left time: 1093.9246s\n",
            "\titers: 1500, epoch: 38 | loss: 0.0015487\n",
            "\tspeed: 0.0417s/iter; left time: 1104.3989s\n",
            "\titers: 1600, epoch: 38 | loss: 0.0020139\n",
            "\tspeed: 0.0413s/iter; left time: 1090.6814s\n",
            "\titers: 1700, epoch: 38 | loss: 0.0128957\n",
            "\tspeed: 0.0415s/iter; left time: 1089.7047s\n",
            "\titers: 1800, epoch: 38 | loss: 0.0026041\n",
            "\tspeed: 0.0416s/iter; left time: 1089.1391s\n",
            "\titers: 1900, epoch: 38 | loss: 0.0020958\n",
            "\tspeed: 0.0414s/iter; left time: 1078.7065s\n",
            "\titers: 2000, epoch: 38 | loss: 0.0166295\n",
            "\tspeed: 0.0415s/iter; left time: 1079.0886s\n",
            "\titers: 2100, epoch: 38 | loss: 0.0013233\n",
            "\tspeed: 0.0410s/iter; left time: 1059.7654s\n",
            "Epoch: 38 cost time: 89.04409337043762\n",
            "Epoch: 38, Steps: 2152 | Train Loss: 0.0301368 Vali Loss: 0.0135982 Test Loss: 1.0991615\n",
            "EarlyStopping counter: 34 out of 50\n",
            "Updating learning rate to 7.275957614183426e-16\n",
            "\titers: 100, epoch: 39 | loss: 0.0005864\n",
            "\tspeed: 0.2773s/iter; left time: 7133.4152s\n",
            "\titers: 200, epoch: 39 | loss: 0.0262882\n",
            "\tspeed: 0.0411s/iter; left time: 1053.8094s\n",
            "\titers: 300, epoch: 39 | loss: 0.0110115\n",
            "\tspeed: 0.0410s/iter; left time: 1045.7011s\n",
            "\titers: 400, epoch: 39 | loss: 0.0046808\n",
            "\tspeed: 0.0414s/iter; left time: 1053.0333s\n",
            "\titers: 500, epoch: 39 | loss: 0.0245544\n",
            "\tspeed: 0.0417s/iter; left time: 1056.2786s\n",
            "\titers: 600, epoch: 39 | loss: 0.0083502\n",
            "\tspeed: 0.0417s/iter; left time: 1051.1568s\n",
            "\titers: 700, epoch: 39 | loss: 0.0019949\n",
            "\tspeed: 0.0417s/iter; left time: 1048.4820s\n",
            "\titers: 800, epoch: 39 | loss: 0.0851755\n",
            "\tspeed: 0.0416s/iter; left time: 1040.7370s\n",
            "\titers: 900, epoch: 39 | loss: 0.0019700\n",
            "\tspeed: 0.0417s/iter; left time: 1038.7622s\n",
            "\titers: 1000, epoch: 39 | loss: 0.0013053\n",
            "\tspeed: 0.0412s/iter; left time: 1021.5672s\n",
            "\titers: 1100, epoch: 39 | loss: 0.0022575\n",
            "\tspeed: 0.0410s/iter; left time: 1013.7099s\n",
            "\titers: 1200, epoch: 39 | loss: 1.5872190\n",
            "\tspeed: 0.0407s/iter; left time: 1001.8342s\n",
            "\titers: 1300, epoch: 39 | loss: 0.0015339\n",
            "\tspeed: 0.0411s/iter; left time: 1007.2269s\n",
            "\titers: 1400, epoch: 39 | loss: 0.0048872\n",
            "\tspeed: 0.0410s/iter; left time: 1002.2870s\n",
            "\titers: 1500, epoch: 39 | loss: 0.0020190\n",
            "\tspeed: 0.0412s/iter; left time: 1001.8706s\n",
            "\titers: 1600, epoch: 39 | loss: 0.0010036\n",
            "\tspeed: 0.0409s/iter; left time: 991.9811s\n",
            "\titers: 1700, epoch: 39 | loss: 0.0250692\n",
            "\tspeed: 0.0410s/iter; left time: 990.2729s\n",
            "\titers: 1800, epoch: 39 | loss: 0.0014299\n",
            "\tspeed: 0.0407s/iter; left time: 978.6307s\n",
            "\titers: 1900, epoch: 39 | loss: 0.0016712\n",
            "\tspeed: 0.0407s/iter; left time: 974.9063s\n",
            "\titers: 2000, epoch: 39 | loss: 0.0155469\n",
            "\tspeed: 0.0413s/iter; left time: 984.5474s\n",
            "\titers: 2100, epoch: 39 | loss: 0.0021045\n",
            "\tspeed: 0.0412s/iter; left time: 978.6055s\n",
            "Epoch: 39 cost time: 88.65485429763794\n",
            "Epoch: 39, Steps: 2152 | Train Loss: 0.0303936 Vali Loss: 0.0147370 Test Loss: 1.0979338\n",
            "EarlyStopping counter: 35 out of 50\n",
            "Updating learning rate to 3.637978807091713e-16\n",
            "\titers: 100, epoch: 40 | loss: 0.0024964\n",
            "\tspeed: 0.2799s/iter; left time: 6597.3804s\n",
            "\titers: 200, epoch: 40 | loss: 0.0026332\n",
            "\tspeed: 0.0414s/iter; left time: 970.6662s\n",
            "\titers: 300, epoch: 40 | loss: 0.0015478\n",
            "\tspeed: 0.0412s/iter; left time: 962.9039s\n",
            "\titers: 400, epoch: 40 | loss: 0.0015301\n",
            "\tspeed: 0.0410s/iter; left time: 954.5530s\n",
            "\titers: 500, epoch: 40 | loss: 0.0011634\n",
            "\tspeed: 0.0410s/iter; left time: 949.4504s\n",
            "\titers: 600, epoch: 40 | loss: 0.0025345\n",
            "\tspeed: 0.0411s/iter; left time: 948.4447s\n",
            "\titers: 700, epoch: 40 | loss: 0.0017594\n",
            "\tspeed: 0.0411s/iter; left time: 943.0827s\n",
            "\titers: 800, epoch: 40 | loss: 0.0018707\n",
            "\tspeed: 0.0408s/iter; left time: 934.2911s\n",
            "\titers: 900, epoch: 40 | loss: 0.0013347\n",
            "\tspeed: 0.0412s/iter; left time: 938.9029s\n",
            "\titers: 1000, epoch: 40 | loss: 0.0008010\n",
            "\tspeed: 0.0415s/iter; left time: 940.6934s\n",
            "\titers: 1100, epoch: 40 | loss: 0.0020977\n",
            "\tspeed: 0.0416s/iter; left time: 939.5022s\n",
            "\titers: 1200, epoch: 40 | loss: 0.0020704\n",
            "\tspeed: 0.0417s/iter; left time: 936.7483s\n",
            "\titers: 1300, epoch: 40 | loss: 0.0681052\n",
            "\tspeed: 0.0416s/iter; left time: 931.3798s\n",
            "\titers: 1400, epoch: 40 | loss: 0.0022352\n",
            "\tspeed: 0.0412s/iter; left time: 917.1252s\n",
            "\titers: 1500, epoch: 40 | loss: 0.0132464\n",
            "\tspeed: 0.0411s/iter; left time: 911.7485s\n",
            "\titers: 1600, epoch: 40 | loss: 0.0023848\n",
            "\tspeed: 0.0411s/iter; left time: 907.9450s\n",
            "\titers: 1700, epoch: 40 | loss: 0.0462681\n",
            "\tspeed: 0.0412s/iter; left time: 905.5515s\n",
            "\titers: 1800, epoch: 40 | loss: 0.0021152\n",
            "\tspeed: 0.0410s/iter; left time: 897.2612s\n",
            "\titers: 1900, epoch: 40 | loss: 0.0008960\n",
            "\tspeed: 0.0412s/iter; left time: 897.4808s\n",
            "\titers: 2000, epoch: 40 | loss: 0.0022382\n",
            "\tspeed: 0.0413s/iter; left time: 895.2237s\n",
            "\titers: 2100, epoch: 40 | loss: 0.0035357\n",
            "\tspeed: 0.0408s/iter; left time: 880.7471s\n",
            "Epoch: 40 cost time: 88.65773463249207\n",
            "Epoch: 40, Steps: 2152 | Train Loss: 0.0308412 Vali Loss: 0.0134146 Test Loss: 1.0976181\n",
            "EarlyStopping counter: 36 out of 50\n",
            "Updating learning rate to 1.8189894035458566e-16\n",
            "\titers: 100, epoch: 41 | loss: 0.0013391\n",
            "\tspeed: 0.2791s/iter; left time: 5978.5031s\n",
            "\titers: 200, epoch: 41 | loss: 0.0069252\n",
            "\tspeed: 0.0416s/iter; left time: 886.0204s\n",
            "\titers: 300, epoch: 41 | loss: 0.0064588\n",
            "\tspeed: 0.0417s/iter; left time: 885.8424s\n",
            "\titers: 400, epoch: 41 | loss: 0.0014787\n",
            "\tspeed: 0.0414s/iter; left time: 873.9476s\n",
            "\titers: 500, epoch: 41 | loss: 0.0368780\n",
            "\tspeed: 0.0411s/iter; left time: 864.5500s\n",
            "\titers: 600, epoch: 41 | loss: 0.0015336\n",
            "\tspeed: 0.0410s/iter; left time: 857.1827s\n",
            "\titers: 700, epoch: 41 | loss: 0.2122909\n",
            "\tspeed: 0.0408s/iter; left time: 848.4663s\n",
            "\titers: 800, epoch: 41 | loss: 0.0018619\n",
            "\tspeed: 0.0410s/iter; left time: 849.9315s\n",
            "\titers: 900, epoch: 41 | loss: 0.0628094\n",
            "\tspeed: 0.0410s/iter; left time: 845.5066s\n",
            "\titers: 1000, epoch: 41 | loss: 0.0046743\n",
            "\tspeed: 0.0411s/iter; left time: 844.3400s\n",
            "\titers: 1100, epoch: 41 | loss: 0.0069239\n",
            "\tspeed: 0.0408s/iter; left time: 833.7133s\n",
            "\titers: 1200, epoch: 41 | loss: 0.0010522\n",
            "\tspeed: 0.0409s/iter; left time: 831.3116s\n",
            "\titers: 1300, epoch: 41 | loss: 0.0008708\n",
            "\tspeed: 0.0409s/iter; left time: 827.3938s\n",
            "\titers: 1400, epoch: 41 | loss: 0.0015450\n",
            "\tspeed: 0.0410s/iter; left time: 824.4142s\n",
            "\titers: 1500, epoch: 41 | loss: 0.0019474\n",
            "\tspeed: 0.0413s/iter; left time: 827.6398s\n",
            "\titers: 1600, epoch: 41 | loss: 0.0024738\n",
            "\tspeed: 0.0412s/iter; left time: 820.0098s\n",
            "\titers: 1700, epoch: 41 | loss: 0.0012291\n",
            "\tspeed: 0.0413s/iter; left time: 817.7173s\n",
            "\titers: 1800, epoch: 41 | loss: 0.0021569\n",
            "\tspeed: 0.0413s/iter; left time: 814.7150s\n",
            "\titers: 1900, epoch: 41 | loss: 0.0013897\n",
            "\tspeed: 0.0415s/iter; left time: 814.2005s\n",
            "\titers: 2000, epoch: 41 | loss: 0.0084115\n",
            "\tspeed: 0.0411s/iter; left time: 801.9512s\n",
            "\titers: 2100, epoch: 41 | loss: 0.5261656\n",
            "\tspeed: 0.0409s/iter; left time: 794.9397s\n",
            "Epoch: 41 cost time: 88.58610272407532\n",
            "Epoch: 41, Steps: 2152 | Train Loss: 0.0299269 Vali Loss: 0.0136092 Test Loss: 1.1014093\n",
            "EarlyStopping counter: 37 out of 50\n",
            "Updating learning rate to 9.094947017729283e-17\n",
            "\titers: 100, epoch: 42 | loss: 0.0627301\n",
            "\tspeed: 0.2795s/iter; left time: 5385.7378s\n",
            "\titers: 200, epoch: 42 | loss: 0.0025960\n",
            "\tspeed: 0.0414s/iter; left time: 793.4190s\n",
            "\titers: 300, epoch: 42 | loss: 0.0012552\n",
            "\tspeed: 0.0410s/iter; left time: 782.0995s\n",
            "\titers: 400, epoch: 42 | loss: 0.0010527\n",
            "\tspeed: 0.0409s/iter; left time: 776.1375s\n",
            "\titers: 500, epoch: 42 | loss: 0.1006039\n",
            "\tspeed: 0.0411s/iter; left time: 774.8721s\n",
            "\titers: 600, epoch: 42 | loss: 0.0032388\n",
            "\tspeed: 0.0410s/iter; left time: 770.2093s\n",
            "\titers: 700, epoch: 42 | loss: 0.0035185\n",
            "\tspeed: 0.0412s/iter; left time: 768.9378s\n",
            "\titers: 800, epoch: 42 | loss: 0.0020041\n",
            "\tspeed: 0.0409s/iter; left time: 759.4133s\n",
            "\titers: 900, epoch: 42 | loss: 0.0010694\n",
            "\tspeed: 0.0411s/iter; left time: 758.5102s\n",
            "\titers: 1000, epoch: 42 | loss: 0.0034484\n",
            "\tspeed: 0.0409s/iter; left time: 751.8464s\n",
            "\titers: 1100, epoch: 42 | loss: 0.0065833\n",
            "\tspeed: 0.0407s/iter; left time: 744.4185s\n",
            "\titers: 1200, epoch: 42 | loss: 0.0022147\n",
            "\tspeed: 0.0415s/iter; left time: 754.8331s\n",
            "\titers: 1300, epoch: 42 | loss: 0.0044598\n",
            "\tspeed: 0.0414s/iter; left time: 747.9436s\n",
            "\titers: 1400, epoch: 42 | loss: 0.0017407\n",
            "\tspeed: 0.0414s/iter; left time: 744.3941s\n",
            "\titers: 1500, epoch: 42 | loss: 0.0092880\n",
            "\tspeed: 0.0416s/iter; left time: 744.1716s\n",
            "\titers: 1600, epoch: 42 | loss: 0.0014119\n",
            "\tspeed: 0.0415s/iter; left time: 738.2647s\n",
            "\titers: 1700, epoch: 42 | loss: 0.0012244\n",
            "\tspeed: 0.0416s/iter; left time: 734.1753s\n",
            "\titers: 1800, epoch: 42 | loss: 0.0026985\n",
            "\tspeed: 0.0410s/iter; left time: 720.7012s\n",
            "\titers: 1900, epoch: 42 | loss: 0.0144818\n",
            "\tspeed: 0.0410s/iter; left time: 716.9783s\n",
            "\titers: 2000, epoch: 42 | loss: 0.0033193\n",
            "\tspeed: 0.0411s/iter; left time: 713.4151s\n",
            "\titers: 2100, epoch: 42 | loss: 0.0009321\n",
            "\tspeed: 0.0414s/iter; left time: 714.8194s\n",
            "Epoch: 42 cost time: 88.6844482421875\n",
            "Epoch: 42, Steps: 2152 | Train Loss: 0.0304370 Vali Loss: 0.0143948 Test Loss: 1.0972054\n",
            "EarlyStopping counter: 38 out of 50\n",
            "Updating learning rate to 4.5474735088646414e-17\n",
            "\titers: 100, epoch: 43 | loss: 0.0042892\n",
            "\tspeed: 0.2790s/iter; left time: 4776.4654s\n",
            "\titers: 200, epoch: 43 | loss: 0.0027262\n",
            "\tspeed: 0.0418s/iter; left time: 711.0966s\n",
            "\titers: 300, epoch: 43 | loss: 0.0016003\n",
            "\tspeed: 0.0416s/iter; left time: 703.6763s\n",
            "\titers: 400, epoch: 43 | loss: 0.0020040\n",
            "\tspeed: 0.0416s/iter; left time: 699.1066s\n",
            "\titers: 500, epoch: 43 | loss: 0.0089257\n",
            "\tspeed: 0.0417s/iter; left time: 697.7947s\n",
            "\titers: 600, epoch: 43 | loss: 0.0122836\n",
            "\tspeed: 0.0416s/iter; left time: 690.5798s\n",
            "\titers: 700, epoch: 43 | loss: 0.0026601\n",
            "\tspeed: 0.0415s/iter; left time: 685.3186s\n",
            "\titers: 800, epoch: 43 | loss: 0.0021772\n",
            "\tspeed: 0.0409s/iter; left time: 671.8595s\n",
            "\titers: 900, epoch: 43 | loss: 0.0172985\n",
            "\tspeed: 0.0409s/iter; left time: 667.9491s\n",
            "\titers: 1000, epoch: 43 | loss: 0.0017398\n",
            "\tspeed: 0.0409s/iter; left time: 663.6824s\n",
            "\titers: 1100, epoch: 43 | loss: 0.0113093\n",
            "\tspeed: 0.0411s/iter; left time: 662.9555s\n",
            "\titers: 1200, epoch: 43 | loss: 0.0008324\n",
            "\tspeed: 0.0409s/iter; left time: 655.4185s\n",
            "\titers: 1300, epoch: 43 | loss: 0.0043683\n",
            "\tspeed: 0.0410s/iter; left time: 651.9019s\n",
            "\titers: 1400, epoch: 43 | loss: 0.0033332\n",
            "\tspeed: 0.0407s/iter; left time: 643.9226s\n",
            "\titers: 1500, epoch: 43 | loss: 0.0009178\n",
            "\tspeed: 0.0410s/iter; left time: 644.2362s\n",
            "\titers: 1600, epoch: 43 | loss: 0.0432935\n",
            "\tspeed: 0.0411s/iter; left time: 641.8276s\n",
            "\titers: 1700, epoch: 43 | loss: 0.0018287\n",
            "\tspeed: 0.0414s/iter; left time: 642.4464s\n",
            "\titers: 1800, epoch: 43 | loss: 0.0092559\n",
            "\tspeed: 0.0417s/iter; left time: 642.3181s\n",
            "\titers: 1900, epoch: 43 | loss: 0.0011896\n",
            "\tspeed: 0.0416s/iter; left time: 637.8613s\n",
            "\titers: 2000, epoch: 43 | loss: 0.0020287\n",
            "\tspeed: 0.0418s/iter; left time: 635.8102s\n",
            "\titers: 2100, epoch: 43 | loss: 0.0024222\n",
            "\tspeed: 0.0416s/iter; left time: 629.3082s\n",
            "Epoch: 43 cost time: 88.96207284927368\n",
            "Epoch: 43, Steps: 2152 | Train Loss: 0.0302219 Vali Loss: 0.0136546 Test Loss: 1.0984093\n",
            "EarlyStopping counter: 39 out of 50\n",
            "Updating learning rate to 2.2737367544323207e-17\n",
            "\titers: 100, epoch: 44 | loss: 0.0010507\n",
            "\tspeed: 0.2790s/iter; left time: 4175.5713s\n",
            "\titers: 200, epoch: 44 | loss: 0.0101216\n",
            "\tspeed: 0.0409s/iter; left time: 608.0779s\n",
            "\titers: 300, epoch: 44 | loss: 0.0019038\n",
            "\tspeed: 0.0412s/iter; left time: 609.0015s\n",
            "\titers: 400, epoch: 44 | loss: 0.0017013\n",
            "\tspeed: 0.0413s/iter; left time: 605.9741s\n",
            "\titers: 500, epoch: 44 | loss: 0.0016378\n",
            "\tspeed: 0.0411s/iter; left time: 598.3802s\n",
            "\titers: 600, epoch: 44 | loss: 0.0015621\n",
            "\tspeed: 0.0413s/iter; left time: 596.8393s\n",
            "\titers: 700, epoch: 44 | loss: 0.0023357\n",
            "\tspeed: 0.0415s/iter; left time: 596.0326s\n",
            "\titers: 800, epoch: 44 | loss: 0.0021127\n",
            "\tspeed: 0.0416s/iter; left time: 593.4400s\n",
            "\titers: 900, epoch: 44 | loss: 0.0036487\n",
            "\tspeed: 0.0414s/iter; left time: 586.9677s\n",
            "\titers: 1000, epoch: 44 | loss: 0.0020622\n",
            "\tspeed: 0.0412s/iter; left time: 579.8178s\n",
            "\titers: 1100, epoch: 44 | loss: 0.0039641\n",
            "\tspeed: 0.0412s/iter; left time: 575.8612s\n",
            "\titers: 1200, epoch: 44 | loss: 0.0149025\n",
            "\tspeed: 0.0412s/iter; left time: 570.9157s\n",
            "\titers: 1300, epoch: 44 | loss: 0.0010493\n",
            "\tspeed: 0.0410s/iter; left time: 563.8013s\n",
            "\titers: 1400, epoch: 44 | loss: 0.0011918\n",
            "\tspeed: 0.0412s/iter; left time: 563.0129s\n",
            "\titers: 1500, epoch: 44 | loss: 0.0024788\n",
            "\tspeed: 0.0415s/iter; left time: 562.3363s\n",
            "\titers: 1600, epoch: 44 | loss: 0.0015615\n",
            "\tspeed: 0.0415s/iter; left time: 558.8441s\n",
            "\titers: 1700, epoch: 44 | loss: 0.0038654\n",
            "\tspeed: 0.0415s/iter; left time: 555.1664s\n",
            "\titers: 1800, epoch: 44 | loss: 0.0038721\n",
            "\tspeed: 0.0415s/iter; left time: 550.9000s\n",
            "\titers: 1900, epoch: 44 | loss: 0.0033963\n",
            "\tspeed: 0.0415s/iter; left time: 545.9361s\n",
            "\titers: 2000, epoch: 44 | loss: 0.0014879\n",
            "\tspeed: 0.0416s/iter; left time: 542.9523s\n",
            "\titers: 2100, epoch: 44 | loss: 0.0034374\n",
            "\tspeed: 0.0412s/iter; left time: 534.1582s\n",
            "Epoch: 44 cost time: 88.90687465667725\n",
            "Epoch: 44, Steps: 2152 | Train Loss: 0.0302646 Vali Loss: 0.0137964 Test Loss: 1.0993470\n",
            "EarlyStopping counter: 40 out of 50\n",
            "Updating learning rate to 1.1368683772161604e-17\n",
            "\titers: 100, epoch: 45 | loss: 0.0355810\n",
            "\tspeed: 0.2782s/iter; left time: 3564.0139s\n",
            "\titers: 200, epoch: 45 | loss: 0.0019968\n",
            "\tspeed: 0.0409s/iter; left time: 520.1357s\n",
            "\titers: 300, epoch: 45 | loss: 0.0025905\n",
            "\tspeed: 0.0410s/iter; left time: 516.8527s\n",
            "\titers: 400, epoch: 45 | loss: 0.0019239\n",
            "\tspeed: 0.0417s/iter; left time: 521.8792s\n",
            "\titers: 500, epoch: 45 | loss: 0.0165024\n",
            "\tspeed: 0.0414s/iter; left time: 513.9883s\n",
            "\titers: 600, epoch: 45 | loss: 0.0184924\n",
            "\tspeed: 0.0415s/iter; left time: 511.5199s\n",
            "\titers: 700, epoch: 45 | loss: 0.0021935\n",
            "\tspeed: 0.0416s/iter; left time: 508.4688s\n",
            "\titers: 800, epoch: 45 | loss: 0.0132472\n",
            "\tspeed: 0.0414s/iter; left time: 502.0566s\n",
            "\titers: 900, epoch: 45 | loss: 0.0484221\n",
            "\tspeed: 0.0417s/iter; left time: 501.3950s\n",
            "\titers: 1000, epoch: 45 | loss: 0.0011932\n",
            "\tspeed: 0.0407s/iter; left time: 485.3217s\n",
            "\titers: 1100, epoch: 45 | loss: 0.0026522\n",
            "\tspeed: 0.0410s/iter; left time: 484.1672s\n",
            "\titers: 1200, epoch: 45 | loss: 0.0681615\n",
            "\tspeed: 0.0411s/iter; left time: 480.9717s\n",
            "\titers: 1300, epoch: 45 | loss: 0.0324884\n",
            "\tspeed: 0.0412s/iter; left time: 478.5229s\n",
            "\titers: 1400, epoch: 45 | loss: 0.0019704\n",
            "\tspeed: 0.0409s/iter; left time: 471.2342s\n",
            "\titers: 1500, epoch: 45 | loss: 0.7224681\n",
            "\tspeed: 0.0411s/iter; left time: 468.6443s\n",
            "\titers: 1600, epoch: 45 | loss: 0.0022387\n",
            "\tspeed: 0.0411s/iter; left time: 465.0458s\n",
            "\titers: 1700, epoch: 45 | loss: 0.0021423\n",
            "\tspeed: 0.0409s/iter; left time: 459.0314s\n",
            "\titers: 1800, epoch: 45 | loss: 0.0019212\n",
            "\tspeed: 0.0408s/iter; left time: 453.6860s\n",
            "\titers: 1900, epoch: 45 | loss: 0.0018486\n",
            "\tspeed: 0.0413s/iter; left time: 454.7522s\n",
            "\titers: 2000, epoch: 45 | loss: 0.0083448\n",
            "\tspeed: 0.0414s/iter; left time: 451.8217s\n",
            "\titers: 2100, epoch: 45 | loss: 0.0292424\n",
            "\tspeed: 0.0417s/iter; left time: 450.6759s\n",
            "Epoch: 45 cost time: 88.73695516586304\n",
            "Epoch: 45, Steps: 2152 | Train Loss: 0.0308661 Vali Loss: 0.0138215 Test Loss: 1.1005199\n",
            "EarlyStopping counter: 41 out of 50\n",
            "Updating learning rate to 5.684341886080802e-18\n",
            "\titers: 100, epoch: 46 | loss: 0.0186772\n",
            "\tspeed: 0.2790s/iter; left time: 2974.4289s\n",
            "\titers: 200, epoch: 46 | loss: 0.0728776\n",
            "\tspeed: 0.0412s/iter; left time: 434.6553s\n",
            "\titers: 300, epoch: 46 | loss: 0.0810741\n",
            "\tspeed: 0.0413s/iter; left time: 431.9240s\n",
            "\titers: 400, epoch: 46 | loss: 0.0017937\n",
            "\tspeed: 0.0409s/iter; left time: 424.0701s\n",
            "\titers: 500, epoch: 46 | loss: 0.0014448\n",
            "\tspeed: 0.0411s/iter; left time: 421.7494s\n",
            "\titers: 600, epoch: 46 | loss: 0.0330303\n",
            "\tspeed: 0.0412s/iter; left time: 418.8958s\n",
            "\titers: 700, epoch: 46 | loss: 0.0055938\n",
            "\tspeed: 0.0410s/iter; left time: 412.3459s\n",
            "\titers: 800, epoch: 46 | loss: 0.0016662\n",
            "\tspeed: 0.0408s/iter; left time: 406.3520s\n",
            "\titers: 900, epoch: 46 | loss: 0.0044788\n",
            "\tspeed: 0.0416s/iter; left time: 410.1923s\n",
            "\titers: 1000, epoch: 46 | loss: 0.0316943\n",
            "\tspeed: 0.0415s/iter; left time: 405.3047s\n",
            "\titers: 1100, epoch: 46 | loss: 0.0023354\n",
            "\tspeed: 0.0415s/iter; left time: 401.2899s\n",
            "\titers: 1200, epoch: 46 | loss: 0.0011418\n",
            "\tspeed: 0.0416s/iter; left time: 397.6053s\n",
            "\titers: 1300, epoch: 46 | loss: 0.0016825\n",
            "\tspeed: 0.0415s/iter; left time: 393.0512s\n",
            "\titers: 1400, epoch: 46 | loss: 0.0208168\n",
            "\tspeed: 0.0414s/iter; left time: 387.5203s\n",
            "\titers: 1500, epoch: 46 | loss: 0.0013464\n",
            "\tspeed: 0.0411s/iter; left time: 381.0316s\n",
            "\titers: 1600, epoch: 46 | loss: 0.0023480\n",
            "\tspeed: 0.0409s/iter; left time: 375.0156s\n",
            "\titers: 1700, epoch: 46 | loss: 0.0253587\n",
            "\tspeed: 0.0413s/iter; left time: 374.3386s\n",
            "\titers: 1800, epoch: 46 | loss: 0.0748655\n",
            "\tspeed: 0.0411s/iter; left time: 368.2999s\n",
            "\titers: 1900, epoch: 46 | loss: 0.0021219\n",
            "\tspeed: 0.0413s/iter; left time: 366.0079s\n",
            "\titers: 2000, epoch: 46 | loss: 0.0017129\n",
            "\tspeed: 0.0409s/iter; left time: 358.7439s\n",
            "\titers: 2100, epoch: 46 | loss: 0.0260517\n",
            "\tspeed: 0.0410s/iter; left time: 354.7519s\n",
            "Epoch: 46 cost time: 88.68729734420776\n",
            "Epoch: 46, Steps: 2152 | Train Loss: 0.0303529 Vali Loss: 0.0140574 Test Loss: 1.1000519\n",
            "EarlyStopping counter: 42 out of 50\n",
            "Updating learning rate to 2.842170943040401e-18\n",
            "\titers: 100, epoch: 47 | loss: 0.0289549\n",
            "\tspeed: 0.2786s/iter; left time: 2370.7640s\n",
            "\titers: 200, epoch: 47 | loss: 0.0020405\n",
            "\tspeed: 0.0415s/iter; left time: 348.9133s\n",
            "\titers: 300, epoch: 47 | loss: 0.0010464\n",
            "\tspeed: 0.0415s/iter; left time: 344.6039s\n",
            "\titers: 400, epoch: 47 | loss: 0.0025528\n",
            "\tspeed: 0.0413s/iter; left time: 339.1012s\n",
            "\titers: 500, epoch: 47 | loss: 0.0937585\n",
            "\tspeed: 0.0411s/iter; left time: 333.6541s\n",
            "\titers: 600, epoch: 47 | loss: 0.0334275\n",
            "\tspeed: 0.0409s/iter; left time: 327.8859s\n",
            "\titers: 700, epoch: 47 | loss: 0.0014994\n",
            "\tspeed: 0.0410s/iter; left time: 324.1714s\n",
            "\titers: 800, epoch: 47 | loss: 0.0064254\n",
            "\tspeed: 0.0409s/iter; left time: 319.4573s\n",
            "\titers: 900, epoch: 47 | loss: 0.0365462\n",
            "\tspeed: 0.0408s/iter; left time: 314.3958s\n",
            "\titers: 1000, epoch: 47 | loss: 0.0051548\n",
            "\tspeed: 0.0411s/iter; left time: 313.0012s\n",
            "\titers: 1100, epoch: 47 | loss: 0.0009231\n",
            "\tspeed: 0.0413s/iter; left time: 310.4129s\n",
            "\titers: 1200, epoch: 47 | loss: 0.0021888\n",
            "\tspeed: 0.0412s/iter; left time: 305.3964s\n",
            "\titers: 1300, epoch: 47 | loss: 0.0135374\n",
            "\tspeed: 0.0412s/iter; left time: 301.0589s\n",
            "\titers: 1400, epoch: 47 | loss: 0.0018568\n",
            "\tspeed: 0.0412s/iter; left time: 296.8648s\n",
            "\titers: 1500, epoch: 47 | loss: 0.0016484\n",
            "\tspeed: 0.0417s/iter; left time: 296.7787s\n",
            "\titers: 1600, epoch: 47 | loss: 2.1799166\n",
            "\tspeed: 0.0415s/iter; left time: 291.1930s\n",
            "\titers: 1700, epoch: 47 | loss: 0.0020494\n",
            "\tspeed: 0.0415s/iter; left time: 286.6318s\n",
            "\titers: 1800, epoch: 47 | loss: 0.0076837\n",
            "\tspeed: 0.0413s/iter; left time: 281.2906s\n",
            "\titers: 1900, epoch: 47 | loss: 0.0020469\n",
            "\tspeed: 0.0413s/iter; left time: 276.7948s\n",
            "\titers: 2000, epoch: 47 | loss: 0.0013549\n",
            "\tspeed: 0.0411s/iter; left time: 271.6711s\n",
            "\titers: 2100, epoch: 47 | loss: 0.0014436\n",
            "\tspeed: 0.0407s/iter; left time: 265.1316s\n",
            "Epoch: 47 cost time: 88.68492865562439\n",
            "Epoch: 47, Steps: 2152 | Train Loss: 0.0298393 Vali Loss: 0.0134181 Test Loss: 1.0966812\n",
            "EarlyStopping counter: 43 out of 50\n",
            "Updating learning rate to 1.4210854715202004e-18\n",
            "\titers: 100, epoch: 48 | loss: 0.1164267\n",
            "\tspeed: 0.2793s/iter; left time: 1775.3383s\n",
            "\titers: 200, epoch: 48 | loss: 0.0028624\n",
            "\tspeed: 0.0412s/iter; left time: 257.6392s\n",
            "\titers: 300, epoch: 48 | loss: 0.0013070\n",
            "\tspeed: 0.0414s/iter; left time: 254.8105s\n",
            "\titers: 400, epoch: 48 | loss: 0.0029175\n",
            "\tspeed: 0.0412s/iter; left time: 249.3581s\n",
            "\titers: 500, epoch: 48 | loss: 0.0023249\n",
            "\tspeed: 0.0412s/iter; left time: 245.3122s\n",
            "\titers: 600, epoch: 48 | loss: 0.0012214\n",
            "\tspeed: 0.0411s/iter; left time: 240.5707s\n",
            "\titers: 700, epoch: 48 | loss: 0.1889901\n",
            "\tspeed: 0.0412s/iter; left time: 237.4392s\n",
            "\titers: 800, epoch: 48 | loss: 0.0023652\n",
            "\tspeed: 0.0412s/iter; left time: 232.8875s\n",
            "\titers: 900, epoch: 48 | loss: 0.0025394\n",
            "\tspeed: 0.0409s/iter; left time: 227.4701s\n",
            "\titers: 1000, epoch: 48 | loss: 0.0037719\n",
            "\tspeed: 0.0410s/iter; left time: 223.8806s\n",
            "\titers: 1100, epoch: 48 | loss: 0.0024648\n",
            "\tspeed: 0.0413s/iter; left time: 221.1050s\n",
            "\titers: 1200, epoch: 48 | loss: 0.0011909\n",
            "\tspeed: 0.0416s/iter; left time: 218.4750s\n",
            "\titers: 1300, epoch: 48 | loss: 0.0305458\n",
            "\tspeed: 0.0415s/iter; left time: 213.9151s\n",
            "\titers: 1400, epoch: 48 | loss: 0.0212652\n",
            "\tspeed: 0.0414s/iter; left time: 209.3753s\n",
            "\titers: 1500, epoch: 48 | loss: 0.5260651\n",
            "\tspeed: 0.0413s/iter; left time: 204.9497s\n",
            "\titers: 1600, epoch: 48 | loss: 0.0155363\n",
            "\tspeed: 0.0414s/iter; left time: 200.9429s\n",
            "\titers: 1700, epoch: 48 | loss: 0.0433692\n",
            "\tspeed: 0.0416s/iter; left time: 197.6887s\n",
            "\titers: 1800, epoch: 48 | loss: 0.0118533\n",
            "\tspeed: 0.0408s/iter; left time: 189.8945s\n",
            "\titers: 1900, epoch: 48 | loss: 0.0137424\n",
            "\tspeed: 0.0406s/iter; left time: 184.9043s\n",
            "\titers: 2000, epoch: 48 | loss: 0.0830523\n",
            "\tspeed: 0.0408s/iter; left time: 181.7946s\n",
            "\titers: 2100, epoch: 48 | loss: 0.0028673\n",
            "\tspeed: 0.0410s/iter; left time: 178.5125s\n",
            "Epoch: 48 cost time: 88.64268064498901\n",
            "Epoch: 48, Steps: 2152 | Train Loss: 0.0299249 Vali Loss: 0.0139404 Test Loss: 1.0967922\n",
            "EarlyStopping counter: 44 out of 50\n",
            "Updating learning rate to 7.105427357601002e-19\n",
            "\titers: 100, epoch: 49 | loss: 0.0287434\n",
            "\tspeed: 0.2787s/iter; left time: 1171.9260s\n",
            "\titers: 200, epoch: 49 | loss: 0.0023371\n",
            "\tspeed: 0.0414s/iter; left time: 169.7794s\n",
            "\titers: 300, epoch: 49 | loss: 0.0022890\n",
            "\tspeed: 0.0415s/iter; left time: 166.2536s\n",
            "\titers: 400, epoch: 49 | loss: 0.0107437\n",
            "\tspeed: 0.0413s/iter; left time: 161.4137s\n",
            "\titers: 500, epoch: 49 | loss: 0.1132445\n",
            "\tspeed: 0.0417s/iter; left time: 158.7292s\n",
            "\titers: 600, epoch: 49 | loss: 0.0153470\n",
            "\tspeed: 0.0412s/iter; left time: 152.6126s\n",
            "\titers: 700, epoch: 49 | loss: 0.0012925\n",
            "\tspeed: 0.0411s/iter; left time: 148.2420s\n",
            "\titers: 800, epoch: 49 | loss: 0.0016958\n",
            "\tspeed: 0.0407s/iter; left time: 142.6777s\n",
            "\titers: 900, epoch: 49 | loss: 0.0556758\n",
            "\tspeed: 0.0411s/iter; left time: 139.7790s\n",
            "\titers: 1000, epoch: 49 | loss: 0.0023746\n",
            "\tspeed: 0.0411s/iter; left time: 135.7815s\n",
            "\titers: 1100, epoch: 49 | loss: 0.0026276\n",
            "\tspeed: 0.0409s/iter; left time: 131.2246s\n",
            "\titers: 1200, epoch: 49 | loss: 0.0023204\n",
            "\tspeed: 0.0409s/iter; left time: 127.0028s\n",
            "\titers: 1300, epoch: 49 | loss: 0.0158018\n",
            "\tspeed: 0.0410s/iter; left time: 123.2749s\n",
            "\titers: 1400, epoch: 49 | loss: 0.0489680\n",
            "\tspeed: 0.0411s/iter; left time: 119.4703s\n",
            "\titers: 1500, epoch: 49 | loss: 0.0688094\n",
            "\tspeed: 0.0411s/iter; left time: 115.1883s\n",
            "\titers: 1600, epoch: 49 | loss: 0.0016358\n",
            "\tspeed: 0.0410s/iter; left time: 110.9969s\n",
            "\titers: 1700, epoch: 49 | loss: 0.0022112\n",
            "\tspeed: 0.0417s/iter; left time: 108.6512s\n",
            "\titers: 1800, epoch: 49 | loss: 0.0015901\n",
            "\tspeed: 0.0416s/iter; left time: 104.2826s\n",
            "\titers: 1900, epoch: 49 | loss: 0.0039282\n",
            "\tspeed: 0.0416s/iter; left time: 99.9839s\n",
            "\titers: 2000, epoch: 49 | loss: 0.0038304\n",
            "\tspeed: 0.0417s/iter; left time: 96.0593s\n",
            "\titers: 2100, epoch: 49 | loss: 0.0923202\n",
            "\tspeed: 0.0417s/iter; left time: 91.9959s\n",
            "Epoch: 49 cost time: 88.88098096847534\n",
            "Epoch: 49, Steps: 2152 | Train Loss: 0.0307773 Vali Loss: 0.0137698 Test Loss: 1.0976024\n",
            "EarlyStopping counter: 45 out of 50\n",
            "Updating learning rate to 3.552713678800501e-19\n",
            "\titers: 100, epoch: 50 | loss: 0.0008459\n",
            "\tspeed: 0.2781s/iter; left time: 571.0250s\n",
            "\titers: 200, epoch: 50 | loss: 0.0022126\n",
            "\tspeed: 0.0409s/iter; left time: 79.9020s\n",
            "\titers: 300, epoch: 50 | loss: 0.0306440\n",
            "\tspeed: 0.0409s/iter; left time: 75.8383s\n",
            "\titers: 400, epoch: 50 | loss: 0.0023912\n",
            "\tspeed: 0.0409s/iter; left time: 71.7171s\n",
            "\titers: 500, epoch: 50 | loss: 0.0027316\n",
            "\tspeed: 0.0412s/iter; left time: 68.0531s\n",
            "\titers: 600, epoch: 50 | loss: 0.0037295\n",
            "\tspeed: 0.0413s/iter; left time: 64.1998s\n",
            "\titers: 700, epoch: 50 | loss: 0.0020035\n",
            "\tspeed: 0.0413s/iter; left time: 60.0559s\n",
            "\titers: 800, epoch: 50 | loss: 0.0018253\n",
            "\tspeed: 0.0416s/iter; left time: 56.3354s\n",
            "\titers: 900, epoch: 50 | loss: 0.0533862\n",
            "\tspeed: 0.0416s/iter; left time: 52.1465s\n",
            "\titers: 1000, epoch: 50 | loss: 0.0848792\n",
            "\tspeed: 0.0414s/iter; left time: 47.7618s\n",
            "\titers: 1100, epoch: 50 | loss: 0.0022616\n",
            "\tspeed: 0.0415s/iter; left time: 43.7170s\n",
            "\titers: 1200, epoch: 50 | loss: 0.0165130\n",
            "\tspeed: 0.0412s/iter; left time: 39.2172s\n",
            "\titers: 1300, epoch: 50 | loss: 0.0018417\n",
            "\tspeed: 0.0412s/iter; left time: 35.1354s\n",
            "\titers: 1400, epoch: 50 | loss: 0.0014131\n",
            "\tspeed: 0.0414s/iter; left time: 31.1812s\n",
            "\titers: 1500, epoch: 50 | loss: 0.0558693\n",
            "\tspeed: 0.0416s/iter; left time: 27.1677s\n",
            "\titers: 1600, epoch: 50 | loss: 0.0012126\n",
            "\tspeed: 0.0416s/iter; left time: 23.0013s\n",
            "\titers: 1700, epoch: 50 | loss: 0.0010250\n",
            "\tspeed: 0.0416s/iter; left time: 18.8316s\n",
            "\titers: 1800, epoch: 50 | loss: 0.0021196\n",
            "\tspeed: 0.0417s/iter; left time: 14.7229s\n",
            "\titers: 1900, epoch: 50 | loss: 0.0387760\n",
            "\tspeed: 0.0415s/iter; left time: 10.4943s\n",
            "\titers: 2000, epoch: 50 | loss: 0.0006398\n",
            "\tspeed: 0.0414s/iter; left time: 6.3274s\n",
            "\titers: 2100, epoch: 50 | loss: 0.0032273\n",
            "\tspeed: 0.0411s/iter; left time: 2.1806s\n",
            "Epoch: 50 cost time: 88.92450618743896\n",
            "Epoch: 50, Steps: 2152 | Train Loss: 0.0297945 Vali Loss: 0.0148545 Test Loss: 1.0999591\n",
            "EarlyStopping counter: 46 out of 50\n",
            "Updating learning rate to 1.7763568394002505e-19\n",
            ">>>>>>>Initiating model testing : informer_ETTm2_ftMS_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_exp_electr1day<<<<<<<<<<<<<<<<<\n",
            "test 11497\n",
            "test shape: (718, 16, 24, 1) (718, 16, 24, 1)\n",
            "test shape: (11488, 24, 1) (11488, 24, 1)\n",
            "mse:1.0888679027557373, mae:0.2725820541381836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "718LCc94zg2I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}